{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJ-best/Challenge_to_the_Competition/blob/main/%5B%EC%97%98%EB%A6%AC%EC%8A%A4MINI%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C_16%EB%93%B1%5Dtime_series_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00d0bfce-bb00-4c27-9ad9-edea7de19015",
      "metadata": {
        "id": "00d0bfce-bb00-4c27-9ad9-edea7de19015"
      },
      "outputs": [],
      "source": [
        "# 필수 라이브러리\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# 추가를 원하는 라이브러리가 있다면 자유롭게 설치 후 추가하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb26182b",
      "metadata": {
        "id": "cb26182b"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f80c538",
      "metadata": {
        "id": "4f80c538"
      },
      "source": [
        "## 학습용 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c962bee2",
      "metadata": {
        "id": "c962bee2"
      },
      "outputs": [],
      "source": [
        "# 전체 데이터셋\n",
        "raw_df = pd.read_csv('/mnt/elice/dataset/continuous_factory_process.csv', index_col=\"time_stamp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21039481",
      "metadata": {
        "id": "21039481",
        "outputId": "2bdc216d-0c81-484e-fda2-0e570b14bfb4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AmbientConditions.AmbientHumidity.U.Actual</th>\n",
              "      <th>AmbientConditions.AmbientTemperature.U.Actual</th>\n",
              "      <th>Machine1.RawMaterial.Property1</th>\n",
              "      <th>Machine1.RawMaterial.Property2</th>\n",
              "      <th>Machine1.RawMaterial.Property3</th>\n",
              "      <th>Machine1.RawMaterial.Property4</th>\n",
              "      <th>Machine1.RawMaterialFeederParameter.U.Actual</th>\n",
              "      <th>Machine1.Zone1Temperature.C.Actual</th>\n",
              "      <th>Machine1.Zone2Temperature.C.Actual</th>\n",
              "      <th>Machine1.MotorAmperage.U.Actual</th>\n",
              "      <th>Machine1.MotorRPM.C.Actual</th>\n",
              "      <th>Machine1.MaterialPressure.U.Actual</th>\n",
              "      <th>Machine1.MaterialTemperature.U.Actual</th>\n",
              "      <th>Machine1.ExitZoneTemperature.C.Actual</th>\n",
              "      <th>Machine2.RawMaterial.Property1</th>\n",
              "      <th>Machine2.RawMaterial.Property2</th>\n",
              "      <th>Machine2.RawMaterial.Property3</th>\n",
              "      <th>Machine2.RawMaterial.Property4</th>\n",
              "      <th>Machine2.RawMaterialFeederParameter.U.Actual</th>\n",
              "      <th>Machine2.Zone1Temperature.C.Actual</th>\n",
              "      <th>Machine2.Zone2Temperature.C.Actual</th>\n",
              "      <th>Machine2.MotorAmperage.U.Actual</th>\n",
              "      <th>Machine2.MotorRPM.C.Actual</th>\n",
              "      <th>Machine2.MaterialPressure.U.Actual</th>\n",
              "      <th>Machine2.MaterialTemperature.U.Actual</th>\n",
              "      <th>Machine2.ExitZoneTemperature.C.Actual</th>\n",
              "      <th>Machine3.RawMaterial.Property1</th>\n",
              "      <th>Machine3.RawMaterial.Property2</th>\n",
              "      <th>Machine3.RawMaterial.Property3</th>\n",
              "      <th>Machine3.RawMaterial.Property4</th>\n",
              "      <th>Machine3.RawMaterialFeederParameter.U.Actual</th>\n",
              "      <th>Machine3.Zone1Temperature.C.Actual</th>\n",
              "      <th>Machine3.Zone2Temperature.C.Actual</th>\n",
              "      <th>Machine3.MotorAmperage.U.Actual</th>\n",
              "      <th>Machine3.MotorRPM.C.Actual</th>\n",
              "      <th>Machine3.MaterialPressure.U.Actual</th>\n",
              "      <th>Machine3.MaterialTemperature.U.Actual</th>\n",
              "      <th>Machine3.ExitZoneTemperature.C.Actual</th>\n",
              "      <th>FirstStage.CombinerOperation.Temperature1.U.Actual</th>\n",
              "      <th>FirstStage.CombinerOperation.Temperature2.U.Actual</th>\n",
              "      <th>FirstStage.CombinerOperation.Temperature3.C.Actual</th>\n",
              "      <th>Stage1.Output.Measurement0.U.Actual</th>\n",
              "      <th>Stage1.Output.Measurement0.U.Setpoint</th>\n",
              "      <th>Stage1.Output.Measurement1.U.Actual</th>\n",
              "      <th>Stage1.Output.Measurement1.U.Setpoint</th>\n",
              "      <th>Stage1.Output.Measurement2.U.Actual</th>\n",
              "      <th>Stage1.Output.Measurement2.U.Setpoint</th>\n",
              "      <th>Stage1.Output.Measurement3.U.Actual</th>\n",
              "      <th>Stage1.Output.Measurement3.U.Setpoint</th>\n",
              "      <th>Stage1.Output.Measurement4.U.Actual</th>\n",
              "      <th>Stage1.Output.Measurement4.U.Setpoint</th>\n",
              "      <th>Stage1.Output.Measurement5.U.Actual</th>\n",
              "      <th>Stage1.Output.Measurement5.U.Setpoint</th>\n",
              "      <th>Stage1.Output.Measurement6.U.Actual</th>\n",
              "      <th>Stage1.Output.Measurement6.U.Setpoint</th>\n",
              "      <th>Stage1.Output.Measurement7.U.Actual</th>\n",
              "      <th>Stage1.Output.Measurement7.U.Setpoint</th>\n",
              "      <th>Stage1.Output.Measurement8.U.Actual</th>\n",
              "      <th>Stage1.Output.Measurement8.U.Setpoint</th>\n",
              "      <th>Stage1.Output.Measurement9.U.Actual</th>\n",
              "      <th>Stage1.Output.Measurement9.U.Setpoint</th>\n",
              "      <th>Stage1.Output.Measurement10.U.Actual</th>\n",
              "      <th>Stage1.Output.Measurement10.U.Setpoint</th>\n",
              "      <th>Stage1.Output.Measurement11.U.Actual</th>\n",
              "      <th>Stage1.Output.Measurement11.U.Setpoint</th>\n",
              "      <th>Stage1.Output.Measurement12.U.Actual</th>\n",
              "      <th>Stage1.Output.Measurement12.U.Setpoint</th>\n",
              "      <th>Stage1.Output.Measurement13.U.Actual</th>\n",
              "      <th>Stage1.Output.Measurement13.U.Setpoint</th>\n",
              "      <th>Stage1.Output.Measurement14.U.Actual</th>\n",
              "      <th>Stage1.Output.Measurement14.U.Setpoint</th>\n",
              "      <th>Machine4.Temperature1.C.Actual</th>\n",
              "      <th>Machine4.Temperature2.C.Actual</th>\n",
              "      <th>Machine4.Pressure.C.Actual</th>\n",
              "      <th>Machine4.Temperature3.C.Actual</th>\n",
              "      <th>Machine4.Temperature4.C.Actual</th>\n",
              "      <th>Machine4.Temperature5.C.Actual</th>\n",
              "      <th>Machine4.ExitTemperature.U.Actual</th>\n",
              "      <th>Machine5.Temperature1.C.Actual</th>\n",
              "      <th>Machine5.Temperature2.C.Actual</th>\n",
              "      <th>Machine5.Temperature3.C.Actual</th>\n",
              "      <th>Machine5.Temperature4.C.Actual</th>\n",
              "      <th>Machine5.Temperature5.C.Actual</th>\n",
              "      <th>Machine5.Temperature6.C.Actual</th>\n",
              "      <th>Machine5.ExitTemperature.U.Actual</th>\n",
              "      <th>Stage2.Output.Measurement0.U.Actual</th>\n",
              "      <th>Stage2.Output.Measurement0.U.Setpoint</th>\n",
              "      <th>Stage2.Output.Measurement1.U.Actual</th>\n",
              "      <th>Stage2.Output.Measurement1.U.Setpoint</th>\n",
              "      <th>Stage2.Output.Measurement2.U.Actual</th>\n",
              "      <th>Stage2.Output.Measurement2.U.Setpoint</th>\n",
              "      <th>Stage2.Output.Measurement3.U.Actual</th>\n",
              "      <th>Stage2.Output.Measurement3.U.Setpoint</th>\n",
              "      <th>Stage2.Output.Measurement4.U.Actual</th>\n",
              "      <th>Stage2.Output.Measurement4.U.Setpoint</th>\n",
              "      <th>Stage2.Output.Measurement5.U.Actual</th>\n",
              "      <th>Stage2.Output.Measurement5.U.Setpoint</th>\n",
              "      <th>Stage2.Output.Measurement6.U.Actual</th>\n",
              "      <th>Stage2.Output.Measurement6.U.Setpoint</th>\n",
              "      <th>Stage2.Output.Measurement7.U.Actual</th>\n",
              "      <th>Stage2.Output.Measurement7.U.Setpoint</th>\n",
              "      <th>Stage2.Output.Measurement8.U.Actual</th>\n",
              "      <th>Stage2.Output.Measurement8.U.Setpoint</th>\n",
              "      <th>Stage2.Output.Measurement9.U.Actual</th>\n",
              "      <th>Stage2.Output.Measurement9.U.Setpoint</th>\n",
              "      <th>Stage2.Output.Measurement10.U.Actual</th>\n",
              "      <th>Stage2.Output.Measurement10.U.Setpoint</th>\n",
              "      <th>Stage2.Output.Measurement11.U.Actual</th>\n",
              "      <th>Stage2.Output.Measurement11.U.Setpoint</th>\n",
              "      <th>Stage2.Output.Measurement12.U.Actual</th>\n",
              "      <th>Stage2.Output.Measurement12.U.Setpoint</th>\n",
              "      <th>Stage2.Output.Measurement13.U.Actual</th>\n",
              "      <th>Stage2.Output.Measurement13.U.Setpoint</th>\n",
              "      <th>Stage2.Output.Measurement14.U.Actual</th>\n",
              "      <th>Stage2.Output.Measurement14.U.Setpoint</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time_stamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-03-06 10:52:33</th>\n",
              "      <td>17.24</td>\n",
              "      <td>23.53</td>\n",
              "      <td>11.54</td>\n",
              "      <td>200</td>\n",
              "      <td>963.0</td>\n",
              "      <td>247</td>\n",
              "      <td>1241.26</td>\n",
              "      <td>72.0</td>\n",
              "      <td>72.3</td>\n",
              "      <td>48.03</td>\n",
              "      <td>10.48</td>\n",
              "      <td>436.76</td>\n",
              "      <td>76.3</td>\n",
              "      <td>75.1</td>\n",
              "      <td>12.59</td>\n",
              "      <td>236</td>\n",
              "      <td>601.11</td>\n",
              "      <td>257</td>\n",
              "      <td>200.75</td>\n",
              "      <td>69.37</td>\n",
              "      <td>69.06</td>\n",
              "      <td>73.25</td>\n",
              "      <td>13.89</td>\n",
              "      <td>246.68</td>\n",
              "      <td>68.8</td>\n",
              "      <td>60.1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>186</td>\n",
              "      <td>421.16</td>\n",
              "      <td>200</td>\n",
              "      <td>203.95</td>\n",
              "      <td>78.2</td>\n",
              "      <td>78.4</td>\n",
              "      <td>337.40</td>\n",
              "      <td>13.50</td>\n",
              "      <td>263.71</td>\n",
              "      <td>65.3</td>\n",
              "      <td>65.0</td>\n",
              "      <td>99.1</td>\n",
              "      <td>108.2</td>\n",
              "      <td>80.0</td>\n",
              "      <td>12.72</td>\n",
              "      <td>13.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.74</td>\n",
              "      <td>12.16</td>\n",
              "      <td>13.02</td>\n",
              "      <td>21.97</td>\n",
              "      <td>21.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>32.55</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.74</td>\n",
              "      <td>3.82</td>\n",
              "      <td>4.25</td>\n",
              "      <td>2.94</td>\n",
              "      <td>2.97</td>\n",
              "      <td>20.82</td>\n",
              "      <td>21.3</td>\n",
              "      <td>17.30</td>\n",
              "      <td>19.52</td>\n",
              "      <td>8.06</td>\n",
              "      <td>8.65</td>\n",
              "      <td>5.54</td>\n",
              "      <td>6.16</td>\n",
              "      <td>1.66</td>\n",
              "      <td>2.02</td>\n",
              "      <td>2.69</td>\n",
              "      <td>3.16</td>\n",
              "      <td>14.51</td>\n",
              "      <td>17.72</td>\n",
              "      <td>298.0</td>\n",
              "      <td>284.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>268.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>309.8</td>\n",
              "      <td>289.9</td>\n",
              "      <td>263.9</td>\n",
              "      <td>238.6</td>\n",
              "      <td>245.0</td>\n",
              "      <td>66.1</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.73</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 10:52:38</th>\n",
              "      <td>17.24</td>\n",
              "      <td>23.53</td>\n",
              "      <td>11.54</td>\n",
              "      <td>200</td>\n",
              "      <td>963.0</td>\n",
              "      <td>247</td>\n",
              "      <td>1262.73</td>\n",
              "      <td>72.1</td>\n",
              "      <td>72.4</td>\n",
              "      <td>48.70</td>\n",
              "      <td>10.48</td>\n",
              "      <td>435.23</td>\n",
              "      <td>76.4</td>\n",
              "      <td>75.1</td>\n",
              "      <td>12.59</td>\n",
              "      <td>236</td>\n",
              "      <td>601.11</td>\n",
              "      <td>257</td>\n",
              "      <td>224.17</td>\n",
              "      <td>69.27</td>\n",
              "      <td>69.06</td>\n",
              "      <td>73.19</td>\n",
              "      <td>13.87</td>\n",
              "      <td>247.33</td>\n",
              "      <td>69.2</td>\n",
              "      <td>59.8</td>\n",
              "      <td>9.02</td>\n",
              "      <td>186</td>\n",
              "      <td>421.16</td>\n",
              "      <td>200</td>\n",
              "      <td>208.78</td>\n",
              "      <td>78.0</td>\n",
              "      <td>78.5</td>\n",
              "      <td>350.49</td>\n",
              "      <td>13.76</td>\n",
              "      <td>261.39</td>\n",
              "      <td>65.4</td>\n",
              "      <td>65.0</td>\n",
              "      <td>99.6</td>\n",
              "      <td>109.9</td>\n",
              "      <td>80.0</td>\n",
              "      <td>12.29</td>\n",
              "      <td>13.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.74</td>\n",
              "      <td>0.00</td>\n",
              "      <td>13.02</td>\n",
              "      <td>17.83</td>\n",
              "      <td>21.88</td>\n",
              "      <td>31.44</td>\n",
              "      <td>32.55</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.74</td>\n",
              "      <td>3.87</td>\n",
              "      <td>4.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.97</td>\n",
              "      <td>0.00</td>\n",
              "      <td>21.3</td>\n",
              "      <td>17.30</td>\n",
              "      <td>19.52</td>\n",
              "      <td>7.54</td>\n",
              "      <td>8.65</td>\n",
              "      <td>5.15</td>\n",
              "      <td>6.16</td>\n",
              "      <td>1.15</td>\n",
              "      <td>2.02</td>\n",
              "      <td>2.72</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.00</td>\n",
              "      <td>17.72</td>\n",
              "      <td>317.0</td>\n",
              "      <td>299.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>275.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>309.8</td>\n",
              "      <td>289.8</td>\n",
              "      <td>263.9</td>\n",
              "      <td>238.6</td>\n",
              "      <td>245.0</td>\n",
              "      <td>66.1</td>\n",
              "      <td>49.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.73</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 10:52:40</th>\n",
              "      <td>17.24</td>\n",
              "      <td>23.53</td>\n",
              "      <td>11.54</td>\n",
              "      <td>200</td>\n",
              "      <td>963.0</td>\n",
              "      <td>247</td>\n",
              "      <td>1296.13</td>\n",
              "      <td>72.1</td>\n",
              "      <td>72.4</td>\n",
              "      <td>49.78</td>\n",
              "      <td>10.48</td>\n",
              "      <td>439.68</td>\n",
              "      <td>76.4</td>\n",
              "      <td>75.0</td>\n",
              "      <td>12.59</td>\n",
              "      <td>236</td>\n",
              "      <td>601.11</td>\n",
              "      <td>257</td>\n",
              "      <td>210.21</td>\n",
              "      <td>69.25</td>\n",
              "      <td>68.94</td>\n",
              "      <td>73.19</td>\n",
              "      <td>13.93</td>\n",
              "      <td>248.85</td>\n",
              "      <td>69.0</td>\n",
              "      <td>59.8</td>\n",
              "      <td>9.02</td>\n",
              "      <td>186</td>\n",
              "      <td>421.16</td>\n",
              "      <td>200</td>\n",
              "      <td>220.17</td>\n",
              "      <td>77.9</td>\n",
              "      <td>78.5</td>\n",
              "      <td>351.83</td>\n",
              "      <td>13.49</td>\n",
              "      <td>260.61</td>\n",
              "      <td>65.4</td>\n",
              "      <td>65.0</td>\n",
              "      <td>99.6</td>\n",
              "      <td>109.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>12.54</td>\n",
              "      <td>13.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.74</td>\n",
              "      <td>11.89</td>\n",
              "      <td>13.02</td>\n",
              "      <td>21.96</td>\n",
              "      <td>21.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>32.55</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.74</td>\n",
              "      <td>3.68</td>\n",
              "      <td>4.25</td>\n",
              "      <td>2.92</td>\n",
              "      <td>2.97</td>\n",
              "      <td>20.65</td>\n",
              "      <td>21.3</td>\n",
              "      <td>17.31</td>\n",
              "      <td>19.52</td>\n",
              "      <td>7.97</td>\n",
              "      <td>8.65</td>\n",
              "      <td>5.34</td>\n",
              "      <td>6.16</td>\n",
              "      <td>1.62</td>\n",
              "      <td>2.02</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.16</td>\n",
              "      <td>14.60</td>\n",
              "      <td>17.72</td>\n",
              "      <td>321.0</td>\n",
              "      <td>302.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>284.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>283.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>309.7</td>\n",
              "      <td>289.8</td>\n",
              "      <td>263.9</td>\n",
              "      <td>238.6</td>\n",
              "      <td>245.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>49.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.73</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 10:52:42</th>\n",
              "      <td>17.24</td>\n",
              "      <td>23.53</td>\n",
              "      <td>11.54</td>\n",
              "      <td>200</td>\n",
              "      <td>963.0</td>\n",
              "      <td>247</td>\n",
              "      <td>1202.16</td>\n",
              "      <td>72.1</td>\n",
              "      <td>72.4</td>\n",
              "      <td>49.64</td>\n",
              "      <td>10.52</td>\n",
              "      <td>431.83</td>\n",
              "      <td>76.5</td>\n",
              "      <td>75.0</td>\n",
              "      <td>12.59</td>\n",
              "      <td>236</td>\n",
              "      <td>601.11</td>\n",
              "      <td>257</td>\n",
              "      <td>211.53</td>\n",
              "      <td>69.25</td>\n",
              "      <td>69.04</td>\n",
              "      <td>73.06</td>\n",
              "      <td>13.92</td>\n",
              "      <td>244.42</td>\n",
              "      <td>69.1</td>\n",
              "      <td>59.9</td>\n",
              "      <td>9.02</td>\n",
              "      <td>186</td>\n",
              "      <td>421.16</td>\n",
              "      <td>200</td>\n",
              "      <td>220.74</td>\n",
              "      <td>77.8</td>\n",
              "      <td>78.5</td>\n",
              "      <td>339.50</td>\n",
              "      <td>13.60</td>\n",
              "      <td>260.58</td>\n",
              "      <td>65.4</td>\n",
              "      <td>65.0</td>\n",
              "      <td>99.3</td>\n",
              "      <td>109.9</td>\n",
              "      <td>80.0</td>\n",
              "      <td>12.35</td>\n",
              "      <td>13.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.74</td>\n",
              "      <td>0.00</td>\n",
              "      <td>13.02</td>\n",
              "      <td>18.10</td>\n",
              "      <td>21.88</td>\n",
              "      <td>31.83</td>\n",
              "      <td>32.55</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.74</td>\n",
              "      <td>1.67</td>\n",
              "      <td>4.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.97</td>\n",
              "      <td>0.00</td>\n",
              "      <td>21.3</td>\n",
              "      <td>17.34</td>\n",
              "      <td>19.52</td>\n",
              "      <td>0.00</td>\n",
              "      <td>8.65</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.16</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.02</td>\n",
              "      <td>1.77</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.00</td>\n",
              "      <td>17.72</td>\n",
              "      <td>327.0</td>\n",
              "      <td>308.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>309.5</td>\n",
              "      <td>289.8</td>\n",
              "      <td>263.9</td>\n",
              "      <td>238.6</td>\n",
              "      <td>245.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>49.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.73</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 10:52:43</th>\n",
              "      <td>17.24</td>\n",
              "      <td>23.53</td>\n",
              "      <td>11.54</td>\n",
              "      <td>200</td>\n",
              "      <td>963.0</td>\n",
              "      <td>247</td>\n",
              "      <td>1202.57</td>\n",
              "      <td>72.1</td>\n",
              "      <td>72.4</td>\n",
              "      <td>49.37</td>\n",
              "      <td>10.48</td>\n",
              "      <td>430.50</td>\n",
              "      <td>76.5</td>\n",
              "      <td>75.1</td>\n",
              "      <td>12.59</td>\n",
              "      <td>236</td>\n",
              "      <td>601.11</td>\n",
              "      <td>257</td>\n",
              "      <td>225.95</td>\n",
              "      <td>69.26</td>\n",
              "      <td>69.06</td>\n",
              "      <td>73.00</td>\n",
              "      <td>13.89</td>\n",
              "      <td>242.33</td>\n",
              "      <td>69.1</td>\n",
              "      <td>59.9</td>\n",
              "      <td>9.02</td>\n",
              "      <td>186</td>\n",
              "      <td>421.16</td>\n",
              "      <td>200</td>\n",
              "      <td>222.18</td>\n",
              "      <td>77.8</td>\n",
              "      <td>78.5</td>\n",
              "      <td>354.74</td>\n",
              "      <td>13.99</td>\n",
              "      <td>259.89</td>\n",
              "      <td>65.4</td>\n",
              "      <td>65.0</td>\n",
              "      <td>99.3</td>\n",
              "      <td>110.1</td>\n",
              "      <td>80.0</td>\n",
              "      <td>12.10</td>\n",
              "      <td>13.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.74</td>\n",
              "      <td>0.00</td>\n",
              "      <td>13.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>21.88</td>\n",
              "      <td>32.81</td>\n",
              "      <td>32.55</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.74</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.97</td>\n",
              "      <td>0.00</td>\n",
              "      <td>21.3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>19.52</td>\n",
              "      <td>0.00</td>\n",
              "      <td>8.65</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.16</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.02</td>\n",
              "      <td>6.91</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.00</td>\n",
              "      <td>17.72</td>\n",
              "      <td>330.0</td>\n",
              "      <td>311.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>291.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>309.4</td>\n",
              "      <td>289.8</td>\n",
              "      <td>263.9</td>\n",
              "      <td>238.6</td>\n",
              "      <td>245.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>48.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.73</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.71</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     AmbientConditions.AmbientHumidity.U.Actual  \\\n",
              "time_stamp                                                        \n",
              "2019-03-06 10:52:33                                       17.24   \n",
              "2019-03-06 10:52:38                                       17.24   \n",
              "2019-03-06 10:52:40                                       17.24   \n",
              "2019-03-06 10:52:42                                       17.24   \n",
              "2019-03-06 10:52:43                                       17.24   \n",
              "\n",
              "                     AmbientConditions.AmbientTemperature.U.Actual  \\\n",
              "time_stamp                                                           \n",
              "2019-03-06 10:52:33                                          23.53   \n",
              "2019-03-06 10:52:38                                          23.53   \n",
              "2019-03-06 10:52:40                                          23.53   \n",
              "2019-03-06 10:52:42                                          23.53   \n",
              "2019-03-06 10:52:43                                          23.53   \n",
              "\n",
              "                     Machine1.RawMaterial.Property1  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                           11.54   \n",
              "2019-03-06 10:52:38                           11.54   \n",
              "2019-03-06 10:52:40                           11.54   \n",
              "2019-03-06 10:52:42                           11.54   \n",
              "2019-03-06 10:52:43                           11.54   \n",
              "\n",
              "                     Machine1.RawMaterial.Property2  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                             200   \n",
              "2019-03-06 10:52:38                             200   \n",
              "2019-03-06 10:52:40                             200   \n",
              "2019-03-06 10:52:42                             200   \n",
              "2019-03-06 10:52:43                             200   \n",
              "\n",
              "                     Machine1.RawMaterial.Property3  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                           963.0   \n",
              "2019-03-06 10:52:38                           963.0   \n",
              "2019-03-06 10:52:40                           963.0   \n",
              "2019-03-06 10:52:42                           963.0   \n",
              "2019-03-06 10:52:43                           963.0   \n",
              "\n",
              "                     Machine1.RawMaterial.Property4  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                             247   \n",
              "2019-03-06 10:52:38                             247   \n",
              "2019-03-06 10:52:40                             247   \n",
              "2019-03-06 10:52:42                             247   \n",
              "2019-03-06 10:52:43                             247   \n",
              "\n",
              "                     Machine1.RawMaterialFeederParameter.U.Actual  \\\n",
              "time_stamp                                                          \n",
              "2019-03-06 10:52:33                                       1241.26   \n",
              "2019-03-06 10:52:38                                       1262.73   \n",
              "2019-03-06 10:52:40                                       1296.13   \n",
              "2019-03-06 10:52:42                                       1202.16   \n",
              "2019-03-06 10:52:43                                       1202.57   \n",
              "\n",
              "                     Machine1.Zone1Temperature.C.Actual  \\\n",
              "time_stamp                                                \n",
              "2019-03-06 10:52:33                                72.0   \n",
              "2019-03-06 10:52:38                                72.1   \n",
              "2019-03-06 10:52:40                                72.1   \n",
              "2019-03-06 10:52:42                                72.1   \n",
              "2019-03-06 10:52:43                                72.1   \n",
              "\n",
              "                     Machine1.Zone2Temperature.C.Actual  \\\n",
              "time_stamp                                                \n",
              "2019-03-06 10:52:33                                72.3   \n",
              "2019-03-06 10:52:38                                72.4   \n",
              "2019-03-06 10:52:40                                72.4   \n",
              "2019-03-06 10:52:42                                72.4   \n",
              "2019-03-06 10:52:43                                72.4   \n",
              "\n",
              "                     Machine1.MotorAmperage.U.Actual  \\\n",
              "time_stamp                                             \n",
              "2019-03-06 10:52:33                            48.03   \n",
              "2019-03-06 10:52:38                            48.70   \n",
              "2019-03-06 10:52:40                            49.78   \n",
              "2019-03-06 10:52:42                            49.64   \n",
              "2019-03-06 10:52:43                            49.37   \n",
              "\n",
              "                     Machine1.MotorRPM.C.Actual  \\\n",
              "time_stamp                                        \n",
              "2019-03-06 10:52:33                       10.48   \n",
              "2019-03-06 10:52:38                       10.48   \n",
              "2019-03-06 10:52:40                       10.48   \n",
              "2019-03-06 10:52:42                       10.52   \n",
              "2019-03-06 10:52:43                       10.48   \n",
              "\n",
              "                     Machine1.MaterialPressure.U.Actual  \\\n",
              "time_stamp                                                \n",
              "2019-03-06 10:52:33                              436.76   \n",
              "2019-03-06 10:52:38                              435.23   \n",
              "2019-03-06 10:52:40                              439.68   \n",
              "2019-03-06 10:52:42                              431.83   \n",
              "2019-03-06 10:52:43                              430.50   \n",
              "\n",
              "                     Machine1.MaterialTemperature.U.Actual  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                   76.3   \n",
              "2019-03-06 10:52:38                                   76.4   \n",
              "2019-03-06 10:52:40                                   76.4   \n",
              "2019-03-06 10:52:42                                   76.5   \n",
              "2019-03-06 10:52:43                                   76.5   \n",
              "\n",
              "                     Machine1.ExitZoneTemperature.C.Actual  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                   75.1   \n",
              "2019-03-06 10:52:38                                   75.1   \n",
              "2019-03-06 10:52:40                                   75.0   \n",
              "2019-03-06 10:52:42                                   75.0   \n",
              "2019-03-06 10:52:43                                   75.1   \n",
              "\n",
              "                     Machine2.RawMaterial.Property1  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                           12.59   \n",
              "2019-03-06 10:52:38                           12.59   \n",
              "2019-03-06 10:52:40                           12.59   \n",
              "2019-03-06 10:52:42                           12.59   \n",
              "2019-03-06 10:52:43                           12.59   \n",
              "\n",
              "                     Machine2.RawMaterial.Property2  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                             236   \n",
              "2019-03-06 10:52:38                             236   \n",
              "2019-03-06 10:52:40                             236   \n",
              "2019-03-06 10:52:42                             236   \n",
              "2019-03-06 10:52:43                             236   \n",
              "\n",
              "                     Machine2.RawMaterial.Property3  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                          601.11   \n",
              "2019-03-06 10:52:38                          601.11   \n",
              "2019-03-06 10:52:40                          601.11   \n",
              "2019-03-06 10:52:42                          601.11   \n",
              "2019-03-06 10:52:43                          601.11   \n",
              "\n",
              "                     Machine2.RawMaterial.Property4  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                             257   \n",
              "2019-03-06 10:52:38                             257   \n",
              "2019-03-06 10:52:40                             257   \n",
              "2019-03-06 10:52:42                             257   \n",
              "2019-03-06 10:52:43                             257   \n",
              "\n",
              "                     Machine2.RawMaterialFeederParameter.U.Actual  \\\n",
              "time_stamp                                                          \n",
              "2019-03-06 10:52:33                                        200.75   \n",
              "2019-03-06 10:52:38                                        224.17   \n",
              "2019-03-06 10:52:40                                        210.21   \n",
              "2019-03-06 10:52:42                                        211.53   \n",
              "2019-03-06 10:52:43                                        225.95   \n",
              "\n",
              "                     Machine2.Zone1Temperature.C.Actual  \\\n",
              "time_stamp                                                \n",
              "2019-03-06 10:52:33                               69.37   \n",
              "2019-03-06 10:52:38                               69.27   \n",
              "2019-03-06 10:52:40                               69.25   \n",
              "2019-03-06 10:52:42                               69.25   \n",
              "2019-03-06 10:52:43                               69.26   \n",
              "\n",
              "                     Machine2.Zone2Temperature.C.Actual  \\\n",
              "time_stamp                                                \n",
              "2019-03-06 10:52:33                               69.06   \n",
              "2019-03-06 10:52:38                               69.06   \n",
              "2019-03-06 10:52:40                               68.94   \n",
              "2019-03-06 10:52:42                               69.04   \n",
              "2019-03-06 10:52:43                               69.06   \n",
              "\n",
              "                     Machine2.MotorAmperage.U.Actual  \\\n",
              "time_stamp                                             \n",
              "2019-03-06 10:52:33                            73.25   \n",
              "2019-03-06 10:52:38                            73.19   \n",
              "2019-03-06 10:52:40                            73.19   \n",
              "2019-03-06 10:52:42                            73.06   \n",
              "2019-03-06 10:52:43                            73.00   \n",
              "\n",
              "                     Machine2.MotorRPM.C.Actual  \\\n",
              "time_stamp                                        \n",
              "2019-03-06 10:52:33                       13.89   \n",
              "2019-03-06 10:52:38                       13.87   \n",
              "2019-03-06 10:52:40                       13.93   \n",
              "2019-03-06 10:52:42                       13.92   \n",
              "2019-03-06 10:52:43                       13.89   \n",
              "\n",
              "                     Machine2.MaterialPressure.U.Actual  \\\n",
              "time_stamp                                                \n",
              "2019-03-06 10:52:33                              246.68   \n",
              "2019-03-06 10:52:38                              247.33   \n",
              "2019-03-06 10:52:40                              248.85   \n",
              "2019-03-06 10:52:42                              244.42   \n",
              "2019-03-06 10:52:43                              242.33   \n",
              "\n",
              "                     Machine2.MaterialTemperature.U.Actual  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                   68.8   \n",
              "2019-03-06 10:52:38                                   69.2   \n",
              "2019-03-06 10:52:40                                   69.0   \n",
              "2019-03-06 10:52:42                                   69.1   \n",
              "2019-03-06 10:52:43                                   69.1   \n",
              "\n",
              "                     Machine2.ExitZoneTemperature.C.Actual  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                   60.1   \n",
              "2019-03-06 10:52:38                                   59.8   \n",
              "2019-03-06 10:52:40                                   59.8   \n",
              "2019-03-06 10:52:42                                   59.9   \n",
              "2019-03-06 10:52:43                                   59.9   \n",
              "\n",
              "                     Machine3.RawMaterial.Property1  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                            9.02   \n",
              "2019-03-06 10:52:38                            9.02   \n",
              "2019-03-06 10:52:40                            9.02   \n",
              "2019-03-06 10:52:42                            9.02   \n",
              "2019-03-06 10:52:43                            9.02   \n",
              "\n",
              "                     Machine3.RawMaterial.Property2  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                             186   \n",
              "2019-03-06 10:52:38                             186   \n",
              "2019-03-06 10:52:40                             186   \n",
              "2019-03-06 10:52:42                             186   \n",
              "2019-03-06 10:52:43                             186   \n",
              "\n",
              "                     Machine3.RawMaterial.Property3  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                          421.16   \n",
              "2019-03-06 10:52:38                          421.16   \n",
              "2019-03-06 10:52:40                          421.16   \n",
              "2019-03-06 10:52:42                          421.16   \n",
              "2019-03-06 10:52:43                          421.16   \n",
              "\n",
              "                     Machine3.RawMaterial.Property4  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                             200   \n",
              "2019-03-06 10:52:38                             200   \n",
              "2019-03-06 10:52:40                             200   \n",
              "2019-03-06 10:52:42                             200   \n",
              "2019-03-06 10:52:43                             200   \n",
              "\n",
              "                     Machine3.RawMaterialFeederParameter.U.Actual  \\\n",
              "time_stamp                                                          \n",
              "2019-03-06 10:52:33                                        203.95   \n",
              "2019-03-06 10:52:38                                        208.78   \n",
              "2019-03-06 10:52:40                                        220.17   \n",
              "2019-03-06 10:52:42                                        220.74   \n",
              "2019-03-06 10:52:43                                        222.18   \n",
              "\n",
              "                     Machine3.Zone1Temperature.C.Actual  \\\n",
              "time_stamp                                                \n",
              "2019-03-06 10:52:33                                78.2   \n",
              "2019-03-06 10:52:38                                78.0   \n",
              "2019-03-06 10:52:40                                77.9   \n",
              "2019-03-06 10:52:42                                77.8   \n",
              "2019-03-06 10:52:43                                77.8   \n",
              "\n",
              "                     Machine3.Zone2Temperature.C.Actual  \\\n",
              "time_stamp                                                \n",
              "2019-03-06 10:52:33                                78.4   \n",
              "2019-03-06 10:52:38                                78.5   \n",
              "2019-03-06 10:52:40                                78.5   \n",
              "2019-03-06 10:52:42                                78.5   \n",
              "2019-03-06 10:52:43                                78.5   \n",
              "\n",
              "                     Machine3.MotorAmperage.U.Actual  \\\n",
              "time_stamp                                             \n",
              "2019-03-06 10:52:33                           337.40   \n",
              "2019-03-06 10:52:38                           350.49   \n",
              "2019-03-06 10:52:40                           351.83   \n",
              "2019-03-06 10:52:42                           339.50   \n",
              "2019-03-06 10:52:43                           354.74   \n",
              "\n",
              "                     Machine3.MotorRPM.C.Actual  \\\n",
              "time_stamp                                        \n",
              "2019-03-06 10:52:33                       13.50   \n",
              "2019-03-06 10:52:38                       13.76   \n",
              "2019-03-06 10:52:40                       13.49   \n",
              "2019-03-06 10:52:42                       13.60   \n",
              "2019-03-06 10:52:43                       13.99   \n",
              "\n",
              "                     Machine3.MaterialPressure.U.Actual  \\\n",
              "time_stamp                                                \n",
              "2019-03-06 10:52:33                              263.71   \n",
              "2019-03-06 10:52:38                              261.39   \n",
              "2019-03-06 10:52:40                              260.61   \n",
              "2019-03-06 10:52:42                              260.58   \n",
              "2019-03-06 10:52:43                              259.89   \n",
              "\n",
              "                     Machine3.MaterialTemperature.U.Actual  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                   65.3   \n",
              "2019-03-06 10:52:38                                   65.4   \n",
              "2019-03-06 10:52:40                                   65.4   \n",
              "2019-03-06 10:52:42                                   65.4   \n",
              "2019-03-06 10:52:43                                   65.4   \n",
              "\n",
              "                     Machine3.ExitZoneTemperature.C.Actual  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                   65.0   \n",
              "2019-03-06 10:52:38                                   65.0   \n",
              "2019-03-06 10:52:40                                   65.0   \n",
              "2019-03-06 10:52:42                                   65.0   \n",
              "2019-03-06 10:52:43                                   65.0   \n",
              "\n",
              "                     FirstStage.CombinerOperation.Temperature1.U.Actual  \\\n",
              "time_stamp                                                                \n",
              "2019-03-06 10:52:33                                               99.1    \n",
              "2019-03-06 10:52:38                                               99.6    \n",
              "2019-03-06 10:52:40                                               99.6    \n",
              "2019-03-06 10:52:42                                               99.3    \n",
              "2019-03-06 10:52:43                                               99.3    \n",
              "\n",
              "                     FirstStage.CombinerOperation.Temperature2.U.Actual  \\\n",
              "time_stamp                                                                \n",
              "2019-03-06 10:52:33                                              108.2    \n",
              "2019-03-06 10:52:38                                              109.9    \n",
              "2019-03-06 10:52:40                                              109.0    \n",
              "2019-03-06 10:52:42                                              109.9    \n",
              "2019-03-06 10:52:43                                              110.1    \n",
              "\n",
              "                     FirstStage.CombinerOperation.Temperature3.C.Actual  \\\n",
              "time_stamp                                                                \n",
              "2019-03-06 10:52:33                                               80.0    \n",
              "2019-03-06 10:52:38                                               80.0    \n",
              "2019-03-06 10:52:40                                               80.0    \n",
              "2019-03-06 10:52:42                                               80.0    \n",
              "2019-03-06 10:52:43                                               80.0    \n",
              "\n",
              "                     Stage1.Output.Measurement0.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                12.72   \n",
              "2019-03-06 10:52:38                                12.29   \n",
              "2019-03-06 10:52:40                                12.54   \n",
              "2019-03-06 10:52:42                                12.35   \n",
              "2019-03-06 10:52:43                                12.10   \n",
              "\n",
              "                     Stage1.Output.Measurement0.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                  13.75   \n",
              "2019-03-06 10:52:38                                  13.75   \n",
              "2019-03-06 10:52:40                                  13.75   \n",
              "2019-03-06 10:52:42                                  13.75   \n",
              "2019-03-06 10:52:43                                  13.75   \n",
              "\n",
              "                     Stage1.Output.Measurement1.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                  0.0   \n",
              "2019-03-06 10:52:38                                  0.0   \n",
              "2019-03-06 10:52:40                                  0.0   \n",
              "2019-03-06 10:52:42                                  0.0   \n",
              "2019-03-06 10:52:43                                  0.0   \n",
              "\n",
              "                     Stage1.Output.Measurement1.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                  22.74   \n",
              "2019-03-06 10:52:38                                  22.74   \n",
              "2019-03-06 10:52:40                                  22.74   \n",
              "2019-03-06 10:52:42                                  22.74   \n",
              "2019-03-06 10:52:43                                  22.74   \n",
              "\n",
              "                     Stage1.Output.Measurement2.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                12.16   \n",
              "2019-03-06 10:52:38                                 0.00   \n",
              "2019-03-06 10:52:40                                11.89   \n",
              "2019-03-06 10:52:42                                 0.00   \n",
              "2019-03-06 10:52:43                                 0.00   \n",
              "\n",
              "                     Stage1.Output.Measurement2.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                  13.02   \n",
              "2019-03-06 10:52:38                                  13.02   \n",
              "2019-03-06 10:52:40                                  13.02   \n",
              "2019-03-06 10:52:42                                  13.02   \n",
              "2019-03-06 10:52:43                                  13.02   \n",
              "\n",
              "                     Stage1.Output.Measurement3.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                21.97   \n",
              "2019-03-06 10:52:38                                17.83   \n",
              "2019-03-06 10:52:40                                21.96   \n",
              "2019-03-06 10:52:42                                18.10   \n",
              "2019-03-06 10:52:43                                 0.00   \n",
              "\n",
              "                     Stage1.Output.Measurement3.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                  21.88   \n",
              "2019-03-06 10:52:38                                  21.88   \n",
              "2019-03-06 10:52:40                                  21.88   \n",
              "2019-03-06 10:52:42                                  21.88   \n",
              "2019-03-06 10:52:43                                  21.88   \n",
              "\n",
              "                     Stage1.Output.Measurement4.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                 0.00   \n",
              "2019-03-06 10:52:38                                31.44   \n",
              "2019-03-06 10:52:40                                 0.00   \n",
              "2019-03-06 10:52:42                                31.83   \n",
              "2019-03-06 10:52:43                                32.81   \n",
              "\n",
              "                     Stage1.Output.Measurement4.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                  32.55   \n",
              "2019-03-06 10:52:38                                  32.55   \n",
              "2019-03-06 10:52:40                                  32.55   \n",
              "2019-03-06 10:52:42                                  32.55   \n",
              "2019-03-06 10:52:43                                  32.55   \n",
              "\n",
              "                     Stage1.Output.Measurement5.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                  0.0   \n",
              "2019-03-06 10:52:38                                  0.0   \n",
              "2019-03-06 10:52:40                                  0.0   \n",
              "2019-03-06 10:52:42                                  0.0   \n",
              "2019-03-06 10:52:43                                  0.0   \n",
              "\n",
              "                     Stage1.Output.Measurement5.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                   2.74   \n",
              "2019-03-06 10:52:38                                   2.74   \n",
              "2019-03-06 10:52:40                                   2.74   \n",
              "2019-03-06 10:52:42                                   2.74   \n",
              "2019-03-06 10:52:43                                   2.74   \n",
              "\n",
              "                     Stage1.Output.Measurement6.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                 3.82   \n",
              "2019-03-06 10:52:38                                 3.87   \n",
              "2019-03-06 10:52:40                                 3.68   \n",
              "2019-03-06 10:52:42                                 1.67   \n",
              "2019-03-06 10:52:43                                 3.00   \n",
              "\n",
              "                     Stage1.Output.Measurement6.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                   4.25   \n",
              "2019-03-06 10:52:38                                   4.25   \n",
              "2019-03-06 10:52:40                                   4.25   \n",
              "2019-03-06 10:52:42                                   4.25   \n",
              "2019-03-06 10:52:43                                   4.25   \n",
              "\n",
              "                     Stage1.Output.Measurement7.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                 2.94   \n",
              "2019-03-06 10:52:38                                 0.00   \n",
              "2019-03-06 10:52:40                                 2.92   \n",
              "2019-03-06 10:52:42                                 0.00   \n",
              "2019-03-06 10:52:43                                 0.00   \n",
              "\n",
              "                     Stage1.Output.Measurement7.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                   2.97   \n",
              "2019-03-06 10:52:38                                   2.97   \n",
              "2019-03-06 10:52:40                                   2.97   \n",
              "2019-03-06 10:52:42                                   2.97   \n",
              "2019-03-06 10:52:43                                   2.97   \n",
              "\n",
              "                     Stage1.Output.Measurement8.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                20.82   \n",
              "2019-03-06 10:52:38                                 0.00   \n",
              "2019-03-06 10:52:40                                20.65   \n",
              "2019-03-06 10:52:42                                 0.00   \n",
              "2019-03-06 10:52:43                                 0.00   \n",
              "\n",
              "                     Stage1.Output.Measurement8.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                   21.3   \n",
              "2019-03-06 10:52:38                                   21.3   \n",
              "2019-03-06 10:52:40                                   21.3   \n",
              "2019-03-06 10:52:42                                   21.3   \n",
              "2019-03-06 10:52:43                                   21.3   \n",
              "\n",
              "                     Stage1.Output.Measurement9.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                17.30   \n",
              "2019-03-06 10:52:38                                17.30   \n",
              "2019-03-06 10:52:40                                17.31   \n",
              "2019-03-06 10:52:42                                17.34   \n",
              "2019-03-06 10:52:43                                 0.00   \n",
              "\n",
              "                     Stage1.Output.Measurement9.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                  19.52   \n",
              "2019-03-06 10:52:38                                  19.52   \n",
              "2019-03-06 10:52:40                                  19.52   \n",
              "2019-03-06 10:52:42                                  19.52   \n",
              "2019-03-06 10:52:43                                  19.52   \n",
              "\n",
              "                     Stage1.Output.Measurement10.U.Actual  \\\n",
              "time_stamp                                                  \n",
              "2019-03-06 10:52:33                                  8.06   \n",
              "2019-03-06 10:52:38                                  7.54   \n",
              "2019-03-06 10:52:40                                  7.97   \n",
              "2019-03-06 10:52:42                                  0.00   \n",
              "2019-03-06 10:52:43                                  0.00   \n",
              "\n",
              "                     Stage1.Output.Measurement10.U.Setpoint  \\\n",
              "time_stamp                                                    \n",
              "2019-03-06 10:52:33                                    8.65   \n",
              "2019-03-06 10:52:38                                    8.65   \n",
              "2019-03-06 10:52:40                                    8.65   \n",
              "2019-03-06 10:52:42                                    8.65   \n",
              "2019-03-06 10:52:43                                    8.65   \n",
              "\n",
              "                     Stage1.Output.Measurement11.U.Actual  \\\n",
              "time_stamp                                                  \n",
              "2019-03-06 10:52:33                                  5.54   \n",
              "2019-03-06 10:52:38                                  5.15   \n",
              "2019-03-06 10:52:40                                  5.34   \n",
              "2019-03-06 10:52:42                                  0.00   \n",
              "2019-03-06 10:52:43                                  0.00   \n",
              "\n",
              "                     Stage1.Output.Measurement11.U.Setpoint  \\\n",
              "time_stamp                                                    \n",
              "2019-03-06 10:52:33                                    6.16   \n",
              "2019-03-06 10:52:38                                    6.16   \n",
              "2019-03-06 10:52:40                                    6.16   \n",
              "2019-03-06 10:52:42                                    6.16   \n",
              "2019-03-06 10:52:43                                    6.16   \n",
              "\n",
              "                     Stage1.Output.Measurement12.U.Actual  \\\n",
              "time_stamp                                                  \n",
              "2019-03-06 10:52:33                                  1.66   \n",
              "2019-03-06 10:52:38                                  1.15   \n",
              "2019-03-06 10:52:40                                  1.62   \n",
              "2019-03-06 10:52:42                                  0.00   \n",
              "2019-03-06 10:52:43                                  0.00   \n",
              "\n",
              "                     Stage1.Output.Measurement12.U.Setpoint  \\\n",
              "time_stamp                                                    \n",
              "2019-03-06 10:52:33                                    2.02   \n",
              "2019-03-06 10:52:38                                    2.02   \n",
              "2019-03-06 10:52:40                                    2.02   \n",
              "2019-03-06 10:52:42                                    2.02   \n",
              "2019-03-06 10:52:43                                    2.02   \n",
              "\n",
              "                     Stage1.Output.Measurement13.U.Actual  \\\n",
              "time_stamp                                                  \n",
              "2019-03-06 10:52:33                                  2.69   \n",
              "2019-03-06 10:52:38                                  2.72   \n",
              "2019-03-06 10:52:40                                  2.65   \n",
              "2019-03-06 10:52:42                                  1.77   \n",
              "2019-03-06 10:52:43                                  6.91   \n",
              "\n",
              "                     Stage1.Output.Measurement13.U.Setpoint  \\\n",
              "time_stamp                                                    \n",
              "2019-03-06 10:52:33                                    3.16   \n",
              "2019-03-06 10:52:38                                    3.16   \n",
              "2019-03-06 10:52:40                                    3.16   \n",
              "2019-03-06 10:52:42                                    3.16   \n",
              "2019-03-06 10:52:43                                    3.16   \n",
              "\n",
              "                     Stage1.Output.Measurement14.U.Actual  \\\n",
              "time_stamp                                                  \n",
              "2019-03-06 10:52:33                                 14.51   \n",
              "2019-03-06 10:52:38                                  0.00   \n",
              "2019-03-06 10:52:40                                 14.60   \n",
              "2019-03-06 10:52:42                                  0.00   \n",
              "2019-03-06 10:52:43                                  0.00   \n",
              "\n",
              "                     Stage1.Output.Measurement14.U.Setpoint  \\\n",
              "time_stamp                                                    \n",
              "2019-03-06 10:52:33                                   17.72   \n",
              "2019-03-06 10:52:38                                   17.72   \n",
              "2019-03-06 10:52:40                                   17.72   \n",
              "2019-03-06 10:52:42                                   17.72   \n",
              "2019-03-06 10:52:43                                   17.72   \n",
              "\n",
              "                     Machine4.Temperature1.C.Actual  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                           298.0   \n",
              "2019-03-06 10:52:38                           317.0   \n",
              "2019-03-06 10:52:40                           321.0   \n",
              "2019-03-06 10:52:42                           327.0   \n",
              "2019-03-06 10:52:43                           330.0   \n",
              "\n",
              "                     Machine4.Temperature2.C.Actual  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                           284.0   \n",
              "2019-03-06 10:52:38                           299.0   \n",
              "2019-03-06 10:52:40                           302.0   \n",
              "2019-03-06 10:52:42                           308.0   \n",
              "2019-03-06 10:52:43                           311.0   \n",
              "\n",
              "                     Machine4.Pressure.C.Actual  \\\n",
              "time_stamp                                        \n",
              "2019-03-06 10:52:33                        21.0   \n",
              "2019-03-06 10:52:38                        22.0   \n",
              "2019-03-06 10:52:40                        25.0   \n",
              "2019-03-06 10:52:42                        25.0   \n",
              "2019-03-06 10:52:43                        24.0   \n",
              "\n",
              "                     Machine4.Temperature3.C.Actual  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                           268.0   \n",
              "2019-03-06 10:52:38                           280.0   \n",
              "2019-03-06 10:52:40                           284.0   \n",
              "2019-03-06 10:52:42                           288.0   \n",
              "2019-03-06 10:52:43                           291.0   \n",
              "\n",
              "                     Machine4.Temperature4.C.Actual  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                            21.0   \n",
              "2019-03-06 10:52:38                            22.0   \n",
              "2019-03-06 10:52:40                            25.0   \n",
              "2019-03-06 10:52:42                            25.0   \n",
              "2019-03-06 10:52:43                            24.0   \n",
              "\n",
              "                     Machine4.Temperature5.C.Actual  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                           260.0   \n",
              "2019-03-06 10:52:38                           275.0   \n",
              "2019-03-06 10:52:40                           283.0   \n",
              "2019-03-06 10:52:42                           288.0   \n",
              "2019-03-06 10:52:43                           290.0   \n",
              "\n",
              "                     Machine4.ExitTemperature.U.Actual  \\\n",
              "time_stamp                                               \n",
              "2019-03-06 10:52:33                               35.0   \n",
              "2019-03-06 10:52:38                               35.0   \n",
              "2019-03-06 10:52:40                               35.0   \n",
              "2019-03-06 10:52:42                               36.0   \n",
              "2019-03-06 10:52:43                               37.0   \n",
              "\n",
              "                     Machine5.Temperature1.C.Actual  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                           309.8   \n",
              "2019-03-06 10:52:38                           309.8   \n",
              "2019-03-06 10:52:40                           309.7   \n",
              "2019-03-06 10:52:42                           309.5   \n",
              "2019-03-06 10:52:43                           309.4   \n",
              "\n",
              "                     Machine5.Temperature2.C.Actual  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                           289.9   \n",
              "2019-03-06 10:52:38                           289.8   \n",
              "2019-03-06 10:52:40                           289.8   \n",
              "2019-03-06 10:52:42                           289.8   \n",
              "2019-03-06 10:52:43                           289.8   \n",
              "\n",
              "                     Machine5.Temperature3.C.Actual  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                           263.9   \n",
              "2019-03-06 10:52:38                           263.9   \n",
              "2019-03-06 10:52:40                           263.9   \n",
              "2019-03-06 10:52:42                           263.9   \n",
              "2019-03-06 10:52:43                           263.9   \n",
              "\n",
              "                     Machine5.Temperature4.C.Actual  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                           238.6   \n",
              "2019-03-06 10:52:38                           238.6   \n",
              "2019-03-06 10:52:40                           238.6   \n",
              "2019-03-06 10:52:42                           238.6   \n",
              "2019-03-06 10:52:43                           238.6   \n",
              "\n",
              "                     Machine5.Temperature5.C.Actual  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                           245.0   \n",
              "2019-03-06 10:52:38                           245.0   \n",
              "2019-03-06 10:52:40                           245.0   \n",
              "2019-03-06 10:52:42                           245.0   \n",
              "2019-03-06 10:52:43                           245.0   \n",
              "\n",
              "                     Machine5.Temperature6.C.Actual  \\\n",
              "time_stamp                                            \n",
              "2019-03-06 10:52:33                            66.1   \n",
              "2019-03-06 10:52:38                            66.1   \n",
              "2019-03-06 10:52:40                            66.0   \n",
              "2019-03-06 10:52:42                            66.0   \n",
              "2019-03-06 10:52:43                            66.0   \n",
              "\n",
              "                     Machine5.ExitTemperature.U.Actual  \\\n",
              "time_stamp                                               \n",
              "2019-03-06 10:52:33                               50.0   \n",
              "2019-03-06 10:52:38                               49.1   \n",
              "2019-03-06 10:52:40                               49.4   \n",
              "2019-03-06 10:52:42                               49.4   \n",
              "2019-03-06 10:52:43                               48.5   \n",
              "\n",
              "                     Stage2.Output.Measurement0.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                  0.0   \n",
              "2019-03-06 10:52:38                                  0.0   \n",
              "2019-03-06 10:52:40                                  0.0   \n",
              "2019-03-06 10:52:42                                  0.0   \n",
              "2019-03-06 10:52:43                                  0.0   \n",
              "\n",
              "                     Stage2.Output.Measurement0.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                  12.05   \n",
              "2019-03-06 10:52:38                                  12.05   \n",
              "2019-03-06 10:52:40                                  12.05   \n",
              "2019-03-06 10:52:42                                  12.05   \n",
              "2019-03-06 10:52:43                                  12.05   \n",
              "\n",
              "                     Stage2.Output.Measurement1.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                  0.0   \n",
              "2019-03-06 10:52:38                                  0.0   \n",
              "2019-03-06 10:52:40                                  0.0   \n",
              "2019-03-06 10:52:42                                  0.0   \n",
              "2019-03-06 10:52:43                                  0.0   \n",
              "\n",
              "                     Stage2.Output.Measurement1.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                  11.71   \n",
              "2019-03-06 10:52:38                                  11.71   \n",
              "2019-03-06 10:52:40                                  11.71   \n",
              "2019-03-06 10:52:42                                  11.71   \n",
              "2019-03-06 10:52:43                                  11.71   \n",
              "\n",
              "                     Stage2.Output.Measurement2.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                  0.0   \n",
              "2019-03-06 10:52:38                                  0.0   \n",
              "2019-03-06 10:52:40                                  0.0   \n",
              "2019-03-06 10:52:42                                  0.0   \n",
              "2019-03-06 10:52:43                                  0.0   \n",
              "\n",
              "                     Stage2.Output.Measurement2.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                     11   \n",
              "2019-03-06 10:52:38                                     11   \n",
              "2019-03-06 10:52:40                                     11   \n",
              "2019-03-06 10:52:42                                     11   \n",
              "2019-03-06 10:52:43                                     11   \n",
              "\n",
              "                     Stage2.Output.Measurement3.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                  0.0   \n",
              "2019-03-06 10:52:38                                  0.0   \n",
              "2019-03-06 10:52:40                                  0.0   \n",
              "2019-03-06 10:52:42                                  0.0   \n",
              "2019-03-06 10:52:43                                  0.0   \n",
              "\n",
              "                     Stage2.Output.Measurement3.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                  20.73   \n",
              "2019-03-06 10:52:38                                  20.73   \n",
              "2019-03-06 10:52:40                                  20.73   \n",
              "2019-03-06 10:52:42                                  20.73   \n",
              "2019-03-06 10:52:43                                  20.73   \n",
              "\n",
              "                     Stage2.Output.Measurement4.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                  0.0   \n",
              "2019-03-06 10:52:38                                  0.0   \n",
              "2019-03-06 10:52:40                                  0.0   \n",
              "2019-03-06 10:52:42                                  0.0   \n",
              "2019-03-06 10:52:43                                  0.0   \n",
              "\n",
              "                     Stage2.Output.Measurement4.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                  31.36   \n",
              "2019-03-06 10:52:38                                  31.36   \n",
              "2019-03-06 10:52:40                                  31.36   \n",
              "2019-03-06 10:52:42                                  31.36   \n",
              "2019-03-06 10:52:43                                  31.36   \n",
              "\n",
              "                     Stage2.Output.Measurement5.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                  0.0   \n",
              "2019-03-06 10:52:38                                  0.0   \n",
              "2019-03-06 10:52:40                                  0.0   \n",
              "2019-03-06 10:52:42                                  0.0   \n",
              "2019-03-06 10:52:43                                  0.0   \n",
              "\n",
              "                     Stage2.Output.Measurement5.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                   2.71   \n",
              "2019-03-06 10:52:38                                   2.71   \n",
              "2019-03-06 10:52:40                                   2.71   \n",
              "2019-03-06 10:52:42                                   2.71   \n",
              "2019-03-06 10:52:43                                   2.71   \n",
              "\n",
              "                     Stage2.Output.Measurement6.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                  0.0   \n",
              "2019-03-06 10:52:38                                  0.0   \n",
              "2019-03-06 10:52:40                                  0.0   \n",
              "2019-03-06 10:52:42                                  0.0   \n",
              "2019-03-06 10:52:43                                  0.0   \n",
              "\n",
              "                     Stage2.Output.Measurement6.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                   0.01   \n",
              "2019-03-06 10:52:38                                   0.01   \n",
              "2019-03-06 10:52:40                                   0.01   \n",
              "2019-03-06 10:52:42                                   0.01   \n",
              "2019-03-06 10:52:43                                   0.01   \n",
              "\n",
              "                     Stage2.Output.Measurement7.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                  0.0   \n",
              "2019-03-06 10:52:38                                  0.0   \n",
              "2019-03-06 10:52:40                                  0.0   \n",
              "2019-03-06 10:52:42                                  0.0   \n",
              "2019-03-06 10:52:43                                  0.0   \n",
              "\n",
              "                     Stage2.Output.Measurement7.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                   2.75   \n",
              "2019-03-06 10:52:38                                   2.75   \n",
              "2019-03-06 10:52:40                                   2.75   \n",
              "2019-03-06 10:52:42                                   2.75   \n",
              "2019-03-06 10:52:43                                   2.75   \n",
              "\n",
              "                     Stage2.Output.Measurement8.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                  0.0   \n",
              "2019-03-06 10:52:38                                  0.0   \n",
              "2019-03-06 10:52:40                                  0.0   \n",
              "2019-03-06 10:52:42                                  0.0   \n",
              "2019-03-06 10:52:43                                  0.0   \n",
              "\n",
              "                     Stage2.Output.Measurement8.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                  19.39   \n",
              "2019-03-06 10:52:38                                  19.39   \n",
              "2019-03-06 10:52:40                                  19.39   \n",
              "2019-03-06 10:52:42                                  19.39   \n",
              "2019-03-06 10:52:43                                  19.39   \n",
              "\n",
              "                     Stage2.Output.Measurement9.U.Actual  \\\n",
              "time_stamp                                                 \n",
              "2019-03-06 10:52:33                                  0.0   \n",
              "2019-03-06 10:52:38                                  0.0   \n",
              "2019-03-06 10:52:40                                  0.0   \n",
              "2019-03-06 10:52:42                                  0.0   \n",
              "2019-03-06 10:52:43                                  0.0   \n",
              "\n",
              "                     Stage2.Output.Measurement9.U.Setpoint  \\\n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                  16.47   \n",
              "2019-03-06 10:52:38                                  16.47   \n",
              "2019-03-06 10:52:40                                  16.47   \n",
              "2019-03-06 10:52:42                                  16.47   \n",
              "2019-03-06 10:52:43                                  16.47   \n",
              "\n",
              "                     Stage2.Output.Measurement10.U.Actual  \\\n",
              "time_stamp                                                  \n",
              "2019-03-06 10:52:33                                   0.0   \n",
              "2019-03-06 10:52:38                                   0.0   \n",
              "2019-03-06 10:52:40                                   0.0   \n",
              "2019-03-06 10:52:42                                   0.0   \n",
              "2019-03-06 10:52:43                                   0.0   \n",
              "\n",
              "                     Stage2.Output.Measurement10.U.Setpoint  \\\n",
              "time_stamp                                                    \n",
              "2019-03-06 10:52:33                                    7.93   \n",
              "2019-03-06 10:52:38                                    7.93   \n",
              "2019-03-06 10:52:40                                    7.93   \n",
              "2019-03-06 10:52:42                                    7.93   \n",
              "2019-03-06 10:52:43                                    7.93   \n",
              "\n",
              "                     Stage2.Output.Measurement11.U.Actual  \\\n",
              "time_stamp                                                  \n",
              "2019-03-06 10:52:33                                   0.0   \n",
              "2019-03-06 10:52:38                                   0.0   \n",
              "2019-03-06 10:52:40                                   0.0   \n",
              "2019-03-06 10:52:42                                   0.0   \n",
              "2019-03-06 10:52:43                                   0.0   \n",
              "\n",
              "                     Stage2.Output.Measurement11.U.Setpoint  \\\n",
              "time_stamp                                                    \n",
              "2019-03-06 10:52:33                                    5.65   \n",
              "2019-03-06 10:52:38                                    5.65   \n",
              "2019-03-06 10:52:40                                    5.65   \n",
              "2019-03-06 10:52:42                                    5.65   \n",
              "2019-03-06 10:52:43                                    5.65   \n",
              "\n",
              "                     Stage2.Output.Measurement12.U.Actual  \\\n",
              "time_stamp                                                  \n",
              "2019-03-06 10:52:33                                   0.0   \n",
              "2019-03-06 10:52:38                                   0.0   \n",
              "2019-03-06 10:52:40                                   0.0   \n",
              "2019-03-06 10:52:42                                   0.0   \n",
              "2019-03-06 10:52:43                                   0.0   \n",
              "\n",
              "                     Stage2.Output.Measurement12.U.Setpoint  \\\n",
              "time_stamp                                                    \n",
              "2019-03-06 10:52:33                                    1.85   \n",
              "2019-03-06 10:52:38                                    1.85   \n",
              "2019-03-06 10:52:40                                    1.85   \n",
              "2019-03-06 10:52:42                                    1.85   \n",
              "2019-03-06 10:52:43                                    1.85   \n",
              "\n",
              "                     Stage2.Output.Measurement13.U.Actual  \\\n",
              "time_stamp                                                  \n",
              "2019-03-06 10:52:33                                   0.0   \n",
              "2019-03-06 10:52:38                                   0.0   \n",
              "2019-03-06 10:52:40                                   0.0   \n",
              "2019-03-06 10:52:42                                   0.0   \n",
              "2019-03-06 10:52:43                                   0.0   \n",
              "\n",
              "                     Stage2.Output.Measurement13.U.Setpoint  \\\n",
              "time_stamp                                                    \n",
              "2019-03-06 10:52:33                                    2.89   \n",
              "2019-03-06 10:52:38                                    2.89   \n",
              "2019-03-06 10:52:40                                    2.89   \n",
              "2019-03-06 10:52:42                                    2.89   \n",
              "2019-03-06 10:52:43                                    2.89   \n",
              "\n",
              "                     Stage2.Output.Measurement14.U.Actual  \\\n",
              "time_stamp                                                  \n",
              "2019-03-06 10:52:33                                   0.0   \n",
              "2019-03-06 10:52:38                                   0.0   \n",
              "2019-03-06 10:52:40                                   0.0   \n",
              "2019-03-06 10:52:42                                   0.0   \n",
              "2019-03-06 10:52:43                                   0.0   \n",
              "\n",
              "                     Stage2.Output.Measurement14.U.Setpoint  \n",
              "time_stamp                                                   \n",
              "2019-03-06 10:52:33                                   11.71  \n",
              "2019-03-06 10:52:38                                   11.71  \n",
              "2019-03-06 10:52:40                                   11.71  \n",
              "2019-03-06 10:52:42                                   11.71  \n",
              "2019-03-06 10:52:43                                   11.71  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c1093b2",
      "metadata": {
        "id": "3c1093b2"
      },
      "source": [
        "## 데이터 전처리\n",
        "- setpoint라는 문자열이 들어간 열을 모두 제거\n",
        "- time_stamp 시계열 Date로 바꿔서 저장\n",
        "- 머신1, 머신2, 머신3, 컴바이너 데이터 ---> X1\n",
        "- 스테이지1에서의 출력값 ---> y1\n",
        "- 머신4, 머신5 데이터 ---> X2\n",
        "- 스테이지2에서의 출력값 ---> y2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74bff75d",
      "metadata": {
        "id": "74bff75d"
      },
      "outputs": [],
      "source": [
        "def data_processing(df):\n",
        "    \n",
        "    #time_stamp를 타임스템프 데이터 형으로 변환해준다\n",
        "    df.reset_index(drop=False, inplace=True)\n",
        "    df['Date'] = pd.to_datetime(df['time_stamp'])\n",
        "    df.drop('time_stamp', axis = 1, inplace=True)\n",
        "    df.set_index('Date', inplace=True)\n",
        "    \n",
        "    del_col = []\n",
        "    for str in df.columns:\n",
        "        if str.find(\"Setpoint\") != -1:\n",
        "            del_col.append(str)\n",
        "    df.drop(columns = del_col, inplace = True)\n",
        "    \n",
        "    stage1_col = []\n",
        "\n",
        "    for str in df.columns:\n",
        "        if str.find(\"Stage1\") != -1:\n",
        "            stage1_col.append(str)\n",
        "    #stage1에서 예측값이 될 y1\n",
        "    y1 = df[stage1_col]\n",
        "    \n",
        "    stage2_col = []\n",
        "\n",
        "    for str in df.columns:\n",
        "        if str.find(\"Stage2\") != -1:\n",
        "            stage2_col.append(str)\n",
        "    #stage2에서 예측값이 될 y2\n",
        "    y2 = df[stage2_col]\n",
        "    \n",
        "    data = df.drop(stage1_col+stage2_col,axis=1)\n",
        "    \n",
        "    machin4_col = []\n",
        "\n",
        "    for str in data.columns:\n",
        "        if str.find(\"Machine4\") != -1:\n",
        "            machin4_col.append(str)\n",
        "\n",
        "    machin5_col = []\n",
        "\n",
        "    for str in data.columns:\n",
        "        if str.find(\"Machine5\") != -1:\n",
        "            machin5_col.append(str)\n",
        "\n",
        "    X1 = data.drop(machin4_col+machin5_col, axis=1)       \n",
        "\n",
        "    X2 = data[machin4_col+machin5_col]\n",
        "    \n",
        "    return X1, X2, y1, y2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "085ad946",
      "metadata": {
        "id": "085ad946"
      },
      "outputs": [],
      "source": [
        "X1, X2, y1, y2 = data_processing(raw_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "490ebf03",
      "metadata": {
        "id": "490ebf03"
      },
      "outputs": [],
      "source": [
        "X1_train = X1.iloc[:9016, :]\n",
        "X1_test = X1.iloc[9016:, :]\n",
        "X2_train = X2.iloc[:9016, :]\n",
        "X2_test = X2.iloc[9016:, :]\n",
        "y1_train = y1.iloc[:9016, :]\n",
        "y1_test = y1.iloc[9016:, :]\n",
        "y2_train = y2.iloc[:9016, :]\n",
        "y2_test = y2.iloc[9016:, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d07d3cad",
      "metadata": {
        "id": "d07d3cad"
      },
      "source": [
        "## MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c779da3",
      "metadata": {
        "id": "1c779da3"
      },
      "outputs": [],
      "source": [
        "# MinMaxScaler적용을 위해 2차원으로 데이터를 변형 시켜준다\n",
        "X1_train_ = X1_train.values.reshape(-1,len(X1_train.columns))\n",
        "X2_train_ = X2_train.values.reshape(-1,len(X2_train.columns))\n",
        "X1_test_ = X1_test.values.reshape(-1,len(X1_test.columns))\n",
        "X2_test_ = X2_test.values.reshape(-1,len(X2_test.columns))\n",
        "\n",
        "y1_train_ = y1_train.values.reshape(-1,len(y1_train.columns))\n",
        "y2_train_ = y2_train.values.reshape(-1,len(y2_train.columns))\n",
        "y1_test_ = y1_test.values.reshape(-1,len(y1_test.columns))\n",
        "y2_test_ = y2_test.values.reshape(-1,len(y2_test.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13a2b7f2",
      "metadata": {
        "id": "13a2b7f2"
      },
      "outputs": [],
      "source": [
        "#Scaler 정의\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X1scaler = MinMaxScaler()\n",
        "X2scaler = MinMaxScaler()\n",
        "\n",
        "y1scaler = MinMaxScaler()\n",
        "y2scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7219902",
      "metadata": {
        "id": "f7219902"
      },
      "outputs": [],
      "source": [
        "#데이터 정규화\n",
        "\n",
        "X1scaler.fit(X1_train_)\n",
        "X2scaler.fit(X2_train_)\n",
        "y1scaler.fit(y1_train_)\n",
        "y2scaler.fit(y2_train_)\n",
        "\n",
        "X1_train_scaled = X1scaler.transform(X1_train_)\n",
        "X2_train_scaled = X2scaler.transform(X2_train_)\n",
        "\n",
        "y1_train_scaled = y1scaler.transform(y1_train_)\n",
        "y2_train_scaled = y2scaler.transform(y2_train_)\n",
        "\n",
        "X1_test_scaled = X1scaler.transform(X1_test_)\n",
        "X2_test_scaled = X2scaler.transform(X2_test_)\n",
        "\n",
        "y1_test_scaled = y1scaler.transform(y1_test_)\n",
        "y2_test_scaled = y2scaler.transform(y2_test_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7b183e3",
      "metadata": {
        "id": "c7b183e3"
      },
      "outputs": [],
      "source": [
        "X1_train_scaled_df = pd.DataFrame(data = X1_train_scaled, columns = X1_train.columns)\n",
        "X2_train_scaled_df = pd.DataFrame(data = X2_train_scaled, columns = X2_train.columns)\n",
        "X1_test_scaled_df = pd.DataFrame(data = X1_test_scaled, columns = X1_test.columns)\n",
        "X2_test_scaled_df = pd.DataFrame(data = X2_test_scaled, columns = X2_test.columns)\n",
        "\n",
        "y1_train_scaled_df = pd.DataFrame(data = y1_train_scaled, columns = y1_train.columns)\n",
        "y2_train_scaled_df = pd.DataFrame(data = y2_train_scaled, columns = y2_train.columns)\n",
        "y1_test_scaled_df = pd.DataFrame(data = y1_test_scaled, columns = y1_test.columns)\n",
        "y2_test_scaled_df = pd.DataFrame(data = y2_test_scaled, columns = y2_test.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eecea9f0",
      "metadata": {
        "id": "eecea9f0"
      },
      "source": [
        "## 분산을 기준으로 분산이 낮은 특성(정보의 변화가 거의 없는 의미없는 특성)을 제거한다/\n",
        "- 의미없는 데이터 컬럼을 제거\n",
        "- 주어진 기준 값보다 높은 분산을 가진 특성을 선택합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "753632d8",
      "metadata": {
        "id": "753632d8",
        "outputId": "a2db5fef-7867-4908-88f5-900adb96f37b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.10212623, 0.07634414, 0.14850347, 0.09087394, 0.06949497,\n",
              "       0.08965471, 0.01119462, 0.01310467, 0.08994234, 0.0181292 ,\n",
              "       0.07639655, 0.02505957, 0.00948239, 0.00462042, 0.19860345,\n",
              "       0.19860345, 0.19860345, 0.19860345, 0.0030264 , 0.00276209,\n",
              "       0.00260405, 0.02000503, 0.04308107, 0.01123182, 0.01164637,\n",
              "       0.04028651, 0.16542033, 0.21150074, 0.15931933, 0.18893357,\n",
              "       0.00344834, 0.00369257, 0.01678782, 0.03937111, 0.04019865,\n",
              "       0.05599431, 0.04861255, 0.02383631, 0.00477485, 0.08090691,\n",
              "       0.02894687])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# X1에서 각 특성이 가지는 분산을 확인\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "X1_th = VarianceThreshold()\n",
        "X1_th.fit(X1_train_scaled_df).variances_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04680341",
      "metadata": {
        "id": "04680341"
      },
      "source": [
        "- X1에서의 분산을 확인해보면 0.08 이상의 분산을 가져야 의미가 있다고 볼 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab86f4fe",
      "metadata": {
        "id": "ab86f4fe",
        "outputId": "6b6af26c-7bfe-4724-d56a-ed12f47cd111"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.00057879, 0.00072539, 0.00692063, 0.00407967, 0.00692063,\n",
              "       0.00196862, 0.02109589, 0.0020704 , 0.00753475, 0.03373575,\n",
              "       0.04407286, 0.00188314, 0.01509776, 0.01011232])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# X2에서 각 특성이 가지는 분산을 확인\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "X2_th = VarianceThreshold()\n",
        "X2_th.fit(X2_train_scaled_df).variances_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "177959f0",
      "metadata": {
        "id": "177959f0"
      },
      "source": [
        "- X2에서의 분산을 살펴보면 0.007 이상의 분산을 가져야 의미가 있다고 볼 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4db0e140",
      "metadata": {
        "id": "4db0e140"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "X1_thresholder = VarianceThreshold(threshold=0.08)\n",
        "X1_thresholder.fit(X1_train_scaled)\n",
        "\n",
        "X1_train_scaled = X1_thresholder.transform(X1_train_scaled)\n",
        "X1_test_scaled = X1_thresholder.transform(X1_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b394ffbf",
      "metadata": {
        "id": "b394ffbf"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "X2_thresholder = VarianceThreshold(threshold=0.007)\n",
        "X2_thresholder.fit(X2_train_scaled)\n",
        "\n",
        "X2_train_scaled = X2_thresholder.transform(X2_train_scaled)\n",
        "X2_test_scaled = X2_thresholder.transform(X2_test_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f081a4f",
      "metadata": {
        "id": "4f081a4f"
      },
      "source": [
        "## 정규화해준 데이터를 데이터프레임에 넣어줌"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89c387da",
      "metadata": {
        "id": "89c387da"
      },
      "outputs": [],
      "source": [
        "X1_train_scaled_df = X1_train_scaled_df[X1_train_scaled_df.columns[X1_thresholder.get_support(indices=True)]]\n",
        "X1_test_scaled_df = X1_test_scaled_df[X1_test_scaled_df.columns[X1_thresholder.get_support(indices=True)]]\n",
        "X2_train_scaled_df = X2_train_scaled_df[X2_train_scaled_df.columns[X2_thresholder.get_support(indices=True)]]\n",
        "X2_test_scaled_df = X2_test_scaled_df[X2_test_scaled_df.columns[X2_thresholder.get_support(indices=True)]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f54889c8",
      "metadata": {
        "id": "f54889c8"
      },
      "outputs": [],
      "source": [
        "X1_test_scaled_df = X1_test_scaled_df[X1_test_scaled_df.columns[X1_thresholder.get_support(indices=True)]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02bf8ec7",
      "metadata": {
        "id": "02bf8ec7"
      },
      "outputs": [],
      "source": [
        "X2_train_scaled_df = X2_train_scaled_df[X2_train_scaled_df.columns[X2_thresholder.get_support(indices=True)]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65026842",
      "metadata": {
        "id": "65026842"
      },
      "outputs": [],
      "source": [
        "X2_test_scaled_df = X2_test_scaled_df[X2_test_scaled_df.columns[X2_thresholder.get_support(indices=True)]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc887291",
      "metadata": {
        "id": "dc887291"
      },
      "outputs": [],
      "source": [
        "#시계열 정보를 넣어줌\n",
        "X1_train_scaled_df.index = X1_train.index\n",
        "X1_test_scaled_df.index = X1_test.index\n",
        "X2_train_scaled_df.index = X2_train.index\n",
        "X2_test_scaled_df.index = X2_test.index\n",
        "y1_train_scaled_df.index = y1_train.index\n",
        "y1_test_scaled_df.index = y1_test.index\n",
        "y1_train_scaled_df.index = y1_train.index\n",
        "y1_test_scaled_df.index = y1_test.index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f02a6d05",
      "metadata": {
        "id": "f02a6d05"
      },
      "source": [
        "## 모델훈련"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c05d715b",
      "metadata": {
        "id": "c05d715b"
      },
      "source": [
        "- 미래를 예측하는 시계열이 아니라 비어있는 데이터 프레임에 들어갈 데이터를 찾는 게 과제!\n",
        "- 즉 결측치 NaN을 계산하는 문제다!\n",
        "- 외삽하는 문제가 아니므로 트리계열 회귀를 사용해도 괜찮을 것이다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bbc3cc7",
      "metadata": {
        "id": "8bbc3cc7"
      },
      "outputs": [],
      "source": [
        "# 결정트리를 이용해서 훈련\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "dt_reg_1 = DecisionTreeRegressor(random_state = 0, criterion = 'absolute_error')\n",
        "dt_reg_2 = DecisionTreeRegressor(random_state = 0, criterion = 'absolute_error')\n",
        "\n",
        "dtmodel_1 = dt_reg_1.fit(X1_train_scaled_df.values, y1_train_scaled_df.values)\n",
        "dtmodel_2 = dt_reg_2.fit(X2_train_scaled_df.values, y2_train_scaled_df.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeed01a6",
      "metadata": {
        "id": "aeed01a6"
      },
      "outputs": [],
      "source": [
        "train1_pred = dtmodel_1.predict(X1_train_scaled_df.values)\n",
        "train2_pred = dtmodel_2.predict(X2_train_scaled_df.values)\n",
        "\n",
        "test1_pred = dtmodel_1.predict(X1_test_scaled_df.values)\n",
        "test2_pred = dtmodel_2.predict(X2_test_scaled_df.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0769876b",
      "metadata": {
        "scrolled": true,
        "id": "0769876b",
        "outputId": "c09c986b-4844-4dae-9742-5eedd26fdce2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "결정트리 모델 R2 score\n",
            "y1 훈련 세트 점수 : 0.79\n",
            "y1 테스트 세트 점수 : -0.72\n",
            "y2 훈련 세트 점수 : 0.95\n",
            "y2 테스트 세트 점수 : -2.52\n"
          ]
        }
      ],
      "source": [
        "print(\"결정트리 모델 R2 score\")\n",
        "print(\"y1 훈련 세트 점수 : {:.2f}\".format(dtmodel_1.score(X1_train_scaled_df.values, y1_train_scaled_df.values)))\n",
        "print(\"y1 테스트 세트 점수 : {:.2f}\".format(dtmodel_1.score(X1_test_scaled_df.values, y1_test_scaled_df.values)))\n",
        "print(\"y2 훈련 세트 점수 : {:.2f}\".format(dtmodel_2.score(X2_train_scaled_df.values, y2_train_scaled_df.values)))\n",
        "print(\"y2 테스트 세트 점수 : {:.2f}\".format(dtmodel_2.score(X2_test_scaled_df.values, y2_test_scaled_df.values)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55fce2d3",
      "metadata": {
        "id": "55fce2d3"
      },
      "outputs": [],
      "source": [
        "#랜덤포레스트를 이용한 회귀\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf_reg_1 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "rf_reg_2 = RandomForestRegressor(n_estimators = 500,  random_state=0)\n",
        "\n",
        "rfmodel_1 = rf_reg_1.fit(X1_train_scaled_df.values, y1_train_scaled_df.values)\n",
        "rfmodel_2 = rf_reg_2.fit(X2_train_scaled_df.values, y2_train_scaled_df.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a973f59a",
      "metadata": {
        "id": "a973f59a"
      },
      "outputs": [],
      "source": [
        "train1_pred = rfmodel_1.predict(X1_train_scaled_df.values)\n",
        "train2_pred = rfmodel_2.predict(X2_train_scaled_df.values)\n",
        "\n",
        "test1_pred = rfmodel_1.predict(X1_test_scaled_df.values)\n",
        "test2_pred = rfmodel_2.predict(X2_test_scaled_df.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2f866b5",
      "metadata": {
        "id": "b2f866b5",
        "outputId": "98de94e4-7339-4eb4-e20c-8760c6568283"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "랜덤포레스트 R2 score\n",
            "y1 훈련 세트 점수 : 0.81\n",
            "y1 테스트 세트 점수 : -113.11\n",
            "y2 훈련 세트 점수 : 0.93\n",
            "y2 테스트 세트 점수 : -2.42\n"
          ]
        }
      ],
      "source": [
        "print(\"랜덤포레스트 R2 score\")\n",
        "print(\"y1 훈련 세트 점수 : {:.2f}\".format(rfmodel_1.score(X1_train_scaled_df.values, y1_train_scaled_df.values)))\n",
        "print(\"y1 테스트 세트 점수 : {:.2f}\".format(rfmodel_1.score(X1_test_scaled_df.values, y1_test_scaled_df.values)))\n",
        "print(\"y2 훈련 세트 점수 : {:.2f}\".format(rfmodel_2.score(X2_train_scaled_df.values, y2_train_scaled_df.values)))\n",
        "print(\"y2 테스트 세트 점수 : {:.2f}\".format(rfmodel_2.score(X2_test_scaled_df.values, y2_test_scaled_df.values)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40164855",
      "metadata": {
        "id": "40164855"
      },
      "source": [
        "## 트리계열은 시계열 예측에 너무 않좋은거 같다\n",
        "## 딥러닝 회귀모델 사용해보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6675cb5",
      "metadata": {
        "id": "a6675cb5",
        "outputId": "98767051-fcc4-459f-a612-76602be4b3cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip -q install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "307fe995",
      "metadata": {
        "id": "307fe995"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "reg_model1 = Sequential()\n",
        "reg_model1.add(Dense(32, activation=\"relu\", input_shape=[X1_train_scaled_df.shape[1],]))\n",
        "reg_model1.add(Dense(32, activation=\"relu\"))\n",
        "reg_model1.add(Dense(15))\n",
        "\n",
        "reg_model1.compile(optimizer='adam', loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a048808f",
      "metadata": {
        "id": "a048808f",
        "outputId": "6ece5ea2-66a0-4b2d-a0f0-bbb30af5935d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_25 (Dense)            (None, 32)                480       \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 15)                495       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,031\n",
            "Trainable params: 2,031\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "reg_model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1fada90",
      "metadata": {
        "id": "e1fada90",
        "outputId": "018ddd1c-cffd-4f3c-b12e-99e5fecb9bd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "256/282 [==========================>...] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 991us/step - loss: 0.0104\n",
            "Epoch 2/100\n",
            "247/282 [=========================>....] - ETA: 0s - loss: 0.0106WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0105\n",
            "Epoch 3/100\n",
            "256/282 [==========================>...] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 991us/step - loss: 0.0104\n",
            "Epoch 4/100\n",
            "250/282 [=========================>....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0105\n",
            "Epoch 5/100\n",
            "272/282 [===========================>..] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 941us/step - loss: 0.0104\n",
            "Epoch 6/100\n",
            "274/282 [============================>.] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 940us/step - loss: 0.0104\n",
            "Epoch 7/100\n",
            "252/282 [=========================>....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0105\n",
            "Epoch 8/100\n",
            "248/282 [=========================>....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 9/100\n",
            "258/282 [==========================>...] - ETA: 0s - loss: 0.0106WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 997us/step - loss: 0.0105\n",
            "Epoch 10/100\n",
            "248/282 [=========================>....] - ETA: 0s - loss: 0.0106WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0105\n",
            "Epoch 11/100\n",
            "247/282 [=========================>....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 12/100\n",
            "253/282 [=========================>....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 13/100\n",
            "247/282 [=========================>....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0105\n",
            "Epoch 14/100\n",
            "252/282 [=========================>....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 15/100\n",
            "245/282 [=========================>....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 16/100\n",
            "241/282 [========================>.....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 17/100\n",
            "250/282 [=========================>....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0105\n",
            "Epoch 18/100\n",
            "244/282 [========================>.....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0105\n",
            "Epoch 19/100\n",
            "236/282 [========================>.....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 864us/step - loss: 0.0104\n",
            "Epoch 20/100\n",
            "238/282 [========================>.....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 853us/step - loss: 0.0104\n",
            "Epoch 21/100\n",
            "246/282 [=========================>....] - ETA: 0s - loss: 0.0102WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 832us/step - loss: 0.0102\n",
            "Epoch 22/100\n",
            "245/282 [=========================>....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 836us/step - loss: 0.0104\n",
            "Epoch 23/100\n",
            "241/282 [========================>.....] - ETA: 0s - loss: 0.0106WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 846us/step - loss: 0.0104\n",
            "Epoch 24/100\n",
            "241/282 [========================>.....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 845us/step - loss: 0.0104\n",
            "Epoch 25/100\n",
            "249/282 [=========================>....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 813us/step - loss: 0.0104\n",
            "Epoch 26/100\n",
            "249/282 [=========================>....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 825us/step - loss: 0.0105\n",
            "Epoch 27/100\n",
            "249/282 [=========================>....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 818us/step - loss: 0.0104\n",
            "Epoch 28/100\n",
            "243/282 [========================>.....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 839us/step - loss: 0.0105\n",
            "Epoch 29/100\n",
            "250/282 [=========================>....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 820us/step - loss: 0.0104\n",
            "Epoch 30/100\n",
            "240/282 [========================>.....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 850us/step - loss: 0.0104\n",
            "Epoch 31/100\n",
            "236/282 [========================>.....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 895us/step - loss: 0.0104\n",
            "Epoch 32/100\n",
            "240/282 [========================>.....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 33/100\n",
            "252/282 [=========================>....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0105\n",
            "Epoch 34/100\n",
            "252/282 [=========================>....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 35/100\n",
            "240/282 [========================>.....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 36/100\n",
            "246/282 [=========================>....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 37/100\n",
            "245/282 [=========================>....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 38/100\n",
            "253/282 [=========================>....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0105\n",
            "Epoch 39/100\n",
            "252/282 [=========================>....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 40/100\n",
            "245/282 [=========================>....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 41/100\n",
            "237/282 [========================>.....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0105\n",
            "Epoch 42/100\n",
            "244/282 [========================>.....] - ETA: 0s - loss: 0.0106WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 43/100\n",
            "254/282 [==========================>...] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0105\n",
            "Epoch 44/100\n",
            "249/282 [=========================>....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 45/100\n",
            "254/282 [==========================>...] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 46/100\n",
            "246/282 [=========================>....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 47/100\n",
            "254/282 [==========================>...] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 48/100\n",
            "259/282 [==========================>...] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 984us/step - loss: 0.0104\n",
            "Epoch 49/100\n",
            "244/282 [========================>.....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 50/100\n",
            "245/282 [=========================>....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 51/100\n",
            "247/282 [=========================>....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 52/100\n",
            "242/282 [========================>.....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 53/100\n",
            "249/282 [=========================>....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 54/100\n",
            "247/282 [=========================>....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 55/100\n",
            "256/282 [==========================>...] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 995us/step - loss: 0.0104\n",
            "Epoch 56/100\n",
            "239/282 [========================>.....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 57/100\n",
            "243/282 [========================>.....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 58/100\n",
            "250/282 [=========================>....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 59/100\n",
            "245/282 [=========================>....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 60/100\n",
            "252/282 [=========================>....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 61/100\n",
            "247/282 [=========================>....] - ETA: 0s - loss: 0.0102WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 62/100\n",
            "251/282 [=========================>....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 63/100\n",
            "246/282 [=========================>....] - ETA: 0s - loss: 0.0102WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 64/100\n",
            "247/282 [=========================>....] - ETA: 0s - loss: 0.0102WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 65/100\n",
            "230/282 [=======================>......] - ETA: 0s - loss: 0.0102WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 877us/step - loss: 0.0103\n",
            "Epoch 66/100\n",
            "266/282 [===========================>..] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 958us/step - loss: 0.0104\n",
            "Epoch 67/100\n",
            "248/282 [=========================>....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 68/100\n",
            "255/282 [==========================>...] - ETA: 0s - loss: 0.0102WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 990us/step - loss: 0.0103\n",
            "Epoch 69/100\n",
            "250/282 [=========================>....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 70/100\n",
            "250/282 [=========================>....] - ETA: 0s - loss: 0.0102WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 71/100\n",
            "252/282 [=========================>....] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 72/100\n",
            "254/282 [==========================>...] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 73/100\n",
            "252/282 [=========================>....] - ETA: 0s - loss: 0.0106WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 74/100\n",
            "247/282 [=========================>....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 75/100\n",
            "261/282 [==========================>...] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 979us/step - loss: 0.0103\n",
            "Epoch 76/100\n",
            "246/282 [=========================>....] - ETA: 0s - loss: 0.0101WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 77/100\n",
            "258/282 [==========================>...] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 989us/step - loss: 0.0103\n",
            "Epoch 78/100\n",
            "254/282 [==========================>...] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 981us/step - loss: 0.0102\n",
            "Epoch 79/100\n",
            "239/282 [========================>.....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 849us/step - loss: 0.0103\n",
            "Epoch 80/100\n",
            "255/282 [==========================>...] - ETA: 0s - loss: 0.0105WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 803us/step - loss: 0.0104\n",
            "Epoch 81/100\n",
            "246/282 [=========================>....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 830us/step - loss: 0.0102\n",
            "Epoch 82/100\n",
            "245/282 [=========================>....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 836us/step - loss: 0.0102\n",
            "Epoch 83/100\n",
            "245/282 [=========================>....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 833us/step - loss: 0.0103\n",
            "Epoch 84/100\n",
            "249/282 [=========================>....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 818us/step - loss: 0.0103\n",
            "Epoch 85/100\n",
            "246/282 [=========================>....] - ETA: 0s - loss: 0.0102WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 821us/step - loss: 0.0102\n",
            "Epoch 86/100\n",
            "242/282 [========================>.....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 837us/step - loss: 0.0104\n",
            "Epoch 87/100\n",
            "248/282 [=========================>....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 822us/step - loss: 0.0103\n",
            "Epoch 88/100\n",
            "253/282 [=========================>....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 809us/step - loss: 0.0103\n",
            "Epoch 89/100\n",
            "251/282 [=========================>....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 822us/step - loss: 0.0102\n",
            "Epoch 90/100\n",
            "244/282 [========================>.....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 832us/step - loss: 0.0103\n",
            "Epoch 91/100\n",
            "246/282 [=========================>....] - ETA: 0s - loss: 0.0102WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 92/100\n",
            "269/282 [===========================>..] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 93/100\n",
            "244/282 [========================>.....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0104\n",
            "Epoch 94/100\n",
            "249/282 [=========================>....] - ETA: 0s - loss: 0.0102WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 95/100\n",
            "258/282 [==========================>...] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 986us/step - loss: 0.0103\n",
            "Epoch 96/100\n",
            "252/282 [=========================>....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 97/100\n",
            "249/282 [=========================>....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 98/100\n",
            "236/282 [========================>.....] - ETA: 0s - loss: 0.0104WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 99/100\n",
            "248/282 [=========================>....] - ETA: 0s - loss: 0.0102WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 100/100\n",
            "251/282 [=========================>....] - ETA: 0s - loss: 0.0103WARNING:tensorflow:Early stopping conditioned on metric `mse` which is not available. Available metrics are: loss\n",
            "282/282 [==============================] - 0s 1ms/step - loss: 0.0102\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping \n",
        "early_stopping = EarlyStopping(monitor = 'mse', min_delta = 0, patience = 0, mode = 'auto')\n",
        "\n",
        "history = reg_model1.fit(X1_train_scaled, y1_train_scaled, epochs=100, callbacks = [early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a521720",
      "metadata": {
        "id": "9a521720",
        "outputId": "367688ea-6440-46c1-9925-45a49dd88642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 665us/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = reg_model1.predict(X1_test_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97fe4ca1",
      "metadata": {
        "id": "97fe4ca1"
      },
      "source": [
        "## 제출을 위한 최종 예측값\n",
        "\n",
        "- 반드시 numpy array로 저장해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cc826b7-3ddb-4ff9-acd0-fc2a5750fed3",
      "metadata": {
        "id": "2cc826b7-3ddb-4ff9-acd0-fc2a5750fed3"
      },
      "outputs": [],
      "source": [
        "# 전체 데이터셋\n",
        "raw_df = pd.read_csv('/mnt/elice/dataset/continuous_factory_process.csv', index_col=\"time_stamp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f24e1cb6",
      "metadata": {
        "id": "f24e1cb6"
      },
      "outputs": [],
      "source": [
        "# 제출용 데이터\n",
        "submission_df = pd.read_csv('/mnt/elice/dataset/submission_data.csv', index_col='time_stamp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72eefc0a",
      "metadata": {
        "id": "72eefc0a"
      },
      "outputs": [],
      "source": [
        "X1_train, X2_train, y1_train, y2_train = data_processing(raw_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbbbdb12",
      "metadata": {
        "id": "fbbbdb12"
      },
      "outputs": [],
      "source": [
        "X1_test, X2_test, y1_test, y2_test = data_processing(submission_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b81e0da0",
      "metadata": {
        "id": "b81e0da0"
      },
      "source": [
        "## 트리계열 머신러닝 모델을 사용한 시도 --> 실패"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1572ee1",
      "metadata": {
        "id": "b1572ee1"
      },
      "outputs": [],
      "source": [
        "# MinMaxScaler적용을 위해 2차원으로 데이터를 변형 시켜준다\n",
        "X1_train_ = X1_train.values.reshape(-1,len(X1_train.columns))\n",
        "X2_train_ = X2_train.values.reshape(-1,len(X2_train.columns))\n",
        "\n",
        "y1_train_1 = y1_train.iloc[:,0].values.reshape(-1,1)\n",
        "y1_train_2 = y1_train.iloc[:,1].values.reshape(-1,1)\n",
        "y1_train_3 = y1_train.iloc[:,2].values.reshape(-1,1)\n",
        "y1_train_4 = y1_train.iloc[:,3].values.reshape(-1,1)\n",
        "y1_train_5 = y1_train.iloc[:,4].values.reshape(-1,1)\n",
        "y1_train_6 = y1_train.iloc[:,5].values.reshape(-1,1)\n",
        "y1_train_7 = y1_train.iloc[:,6].values.reshape(-1,1)\n",
        "y1_train_8 = y1_train.iloc[:,7].values.reshape(-1,1)\n",
        "y1_train_9 = y1_train.iloc[:,8].values.reshape(-1,1)\n",
        "y1_train_10 = y1_train.iloc[:,9].values.reshape(-1,1)\n",
        "y1_train_11 = y1_train.iloc[:,10].values.reshape(-1,1)\n",
        "y1_train_12 = y1_train.iloc[:,11].values.reshape(-1,1)\n",
        "y1_train_13 = y1_train.iloc[:,12].values.reshape(-1,1)\n",
        "y1_train_14 = y1_train.iloc[:,13].values.reshape(-1,1)\n",
        "y1_train_15 = y1_train.iloc[:,14].values.reshape(-1,1)\n",
        "\n",
        "y2_train_1 = y2_train.iloc[:,0].values.reshape(-1,1)\n",
        "y2_train_2 = y2_train.iloc[:,1].values.reshape(-1,1)\n",
        "y2_train_3 = y2_train.iloc[:,2].values.reshape(-1,1)\n",
        "y2_train_4 = y2_train.iloc[:,3].values.reshape(-1,1)\n",
        "y2_train_5 = y2_train.iloc[:,4].values.reshape(-1,1)\n",
        "y2_train_6 = y2_train.iloc[:,5].values.reshape(-1,1)\n",
        "y2_train_7 = y2_train.iloc[:,6].values.reshape(-1,1)\n",
        "y2_train_8 = y2_train.iloc[:,7].values.reshape(-1,1)\n",
        "y2_train_9 = y2_train.iloc[:,8].values.reshape(-1,1)\n",
        "y2_train_10 = y2_train.iloc[:,9].values.reshape(-1,1)\n",
        "y2_train_11 = y2_train.iloc[:,10].values.reshape(-1,1)\n",
        "y2_train_12 = y2_train.iloc[:,11].values.reshape(-1,1)\n",
        "y2_train_13 = y2_train.iloc[:,12].values.reshape(-1,1)\n",
        "y2_train_14 = y2_train.iloc[:,13].values.reshape(-1,1)\n",
        "y2_train_15 = y2_train.iloc[:,14].values.reshape(-1,1)\n",
        "\n",
        "\n",
        "X1_test_ = X1_test.values.reshape(-1,len(X1_test.columns))\n",
        "X2_test_ = X2_test.values.reshape(-1,len(X2_test.columns))\n",
        "\n",
        "y1_test_1 = y1_test.iloc[:,0].values.reshape(-1,1)\n",
        "y1_test_2 = y1_test.iloc[:,1].values.reshape(-1,1)\n",
        "y1_test_3 = y1_test.iloc[:,2].values.reshape(-1,1)\n",
        "y1_test_4 = y1_test.iloc[:,3].values.reshape(-1,1)\n",
        "y1_test_5 = y1_test.iloc[:,4].values.reshape(-1,1)\n",
        "y1_test_6 = y1_test.iloc[:,5].values.reshape(-1,1)\n",
        "y1_test_7 = y1_test.iloc[:,6].values.reshape(-1,1)\n",
        "y1_test_8 = y1_test.iloc[:,7].values.reshape(-1,1)\n",
        "y1_test_9 = y1_test.iloc[:,8].values.reshape(-1,1)\n",
        "y1_test_10 = y1_test.iloc[:,9].values.reshape(-1,1)\n",
        "y1_test_11 = y1_test.iloc[:,10].values.reshape(-1,1)\n",
        "y1_test_12 = y1_test.iloc[:,11].values.reshape(-1,1)\n",
        "y1_test_13 = y1_test.iloc[:,12].values.reshape(-1,1)\n",
        "y1_test_14 = y1_test.iloc[:,13].values.reshape(-1,1)\n",
        "y1_test_15 = y1_test.iloc[:,14].values.reshape(-1,1)\n",
        "\n",
        "y2_test_1 = y2_test.iloc[:,0].values.reshape(-1,1)\n",
        "y2_test_2 = y2_test.iloc[:,1].values.reshape(-1,1)\n",
        "y2_test_3 = y2_test.iloc[:,2].values.reshape(-1,1)\n",
        "y2_test_4 = y2_test.iloc[:,3].values.reshape(-1,1)\n",
        "y2_test_5 = y2_test.iloc[:,4].values.reshape(-1,1)\n",
        "y2_test_6 = y2_test.iloc[:,5].values.reshape(-1,1)\n",
        "y2_test_7 = y2_test.iloc[:,6].values.reshape(-1,1)\n",
        "y2_test_8 = y2_test.iloc[:,7].values.reshape(-1,1)\n",
        "y2_test_9 = y2_test.iloc[:,8].values.reshape(-1,1)\n",
        "y2_test_10 = y2_test.iloc[:,9].values.reshape(-1,1)\n",
        "y2_test_11 = y2_test.iloc[:,10].values.reshape(-1,1)\n",
        "y2_test_12 = y2_test.iloc[:,11].values.reshape(-1,1)\n",
        "y2_test_13 = y2_test.iloc[:,12].values.reshape(-1,1)\n",
        "y2_test_14 = y2_test.iloc[:,13].values.reshape(-1,1)\n",
        "y2_test_15 = y2_test.iloc[:,14].values.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9388574",
      "metadata": {
        "id": "b9388574"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X1scaler = MinMaxScaler()\n",
        "X2scaler = MinMaxScaler()\n",
        "\n",
        "y1_1scaler = MinMaxScaler()\n",
        "y1_2scaler = MinMaxScaler()\n",
        "y1_3scaler = MinMaxScaler()\n",
        "y1_4scaler = MinMaxScaler()\n",
        "y1_5scaler = MinMaxScaler()\n",
        "y1_6scaler = MinMaxScaler()\n",
        "y1_7scaler = MinMaxScaler()\n",
        "y1_8scaler = MinMaxScaler()\n",
        "y1_9scaler = MinMaxScaler()\n",
        "y1_10scaler = MinMaxScaler()\n",
        "y1_11scaler = MinMaxScaler()\n",
        "y1_12scaler = MinMaxScaler()\n",
        "y1_13scaler = MinMaxScaler()\n",
        "y1_14scaler = MinMaxScaler()\n",
        "y1_15scaler = MinMaxScaler()\n",
        "\n",
        "y2_1scaler = MinMaxScaler()\n",
        "y2_2scaler = MinMaxScaler()\n",
        "y2_3scaler = MinMaxScaler()\n",
        "y2_4scaler = MinMaxScaler()\n",
        "y2_5scaler = MinMaxScaler()\n",
        "y2_6scaler = MinMaxScaler()\n",
        "y2_7scaler = MinMaxScaler()\n",
        "y2_8scaler = MinMaxScaler()\n",
        "y2_9scaler = MinMaxScaler()\n",
        "y2_10scaler = MinMaxScaler()\n",
        "y2_11scaler = MinMaxScaler()\n",
        "y2_12scaler = MinMaxScaler()\n",
        "y2_13scaler = MinMaxScaler()\n",
        "y2_14scaler = MinMaxScaler()\n",
        "y2_15scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f69fef9c",
      "metadata": {
        "id": "f69fef9c"
      },
      "outputs": [],
      "source": [
        "#데이터 정규화\n",
        "\n",
        "X1scaler.fit(X1_train_)\n",
        "X2scaler.fit(X2_train_)\n",
        "\n",
        "y1_1scaler.fit(y1_train_1)\n",
        "y1_2scaler.fit(y1_train_2)\n",
        "y1_3scaler.fit(y1_train_3)\n",
        "y1_4scaler.fit(y1_train_4)\n",
        "y1_5scaler.fit(y1_train_5)\n",
        "y1_6scaler.fit(y1_train_6)\n",
        "y1_7scaler.fit(y1_train_7)\n",
        "y1_8scaler.fit(y1_train_8)\n",
        "y1_9scaler.fit(y1_train_9)\n",
        "y1_10scaler.fit(y1_train_10)\n",
        "y1_11scaler.fit(y1_train_11)\n",
        "y1_12scaler.fit(y1_train_12)\n",
        "y1_13scaler.fit(y1_train_13)\n",
        "y1_14scaler.fit(y1_train_14)\n",
        "y1_15scaler.fit(y1_train_15)\n",
        "\n",
        "y2_1scaler.fit(y2_train_1)\n",
        "y2_2scaler.fit(y2_train_2)\n",
        "y2_3scaler.fit(y2_train_3)\n",
        "y2_4scaler.fit(y2_train_4)\n",
        "y2_5scaler.fit(y2_train_5)\n",
        "y2_6scaler.fit(y2_train_6)\n",
        "y2_7scaler.fit(y2_train_7)\n",
        "y2_8scaler.fit(y2_train_8)\n",
        "y2_9scaler.fit(y2_train_9)\n",
        "y2_10scaler.fit(y2_train_10)\n",
        "y2_11scaler.fit(y2_train_11)\n",
        "y2_12scaler.fit(y2_train_12)\n",
        "y2_13scaler.fit(y2_train_13)\n",
        "y2_14scaler.fit(y2_train_14)\n",
        "y2_15scaler.fit(y2_train_15)\n",
        "\n",
        "X1_train_scaled = X1scaler.transform(X1_train_)\n",
        "X2_train_scaled = X2scaler.transform(X2_train_)\n",
        "\n",
        "y1_1train_scaled = y1_1scaler.transform(y1_train_1)\n",
        "y1_2train_scaled = y1_2scaler.transform(y1_train_2)\n",
        "y1_3train_scaled = y1_3scaler.transform(y1_train_3)\n",
        "y1_4train_scaled = y1_4scaler.transform(y1_train_4)\n",
        "y1_5train_scaled = y1_5scaler.transform(y1_train_5)\n",
        "y1_6train_scaled = y1_6scaler.transform(y1_train_6)\n",
        "y1_7train_scaled = y1_7scaler.transform(y1_train_7)\n",
        "y1_8train_scaled = y1_8scaler.transform(y1_train_8)\n",
        "y1_9train_scaled = y1_9scaler.transform(y1_train_9)\n",
        "y1_10train_scaled = y1_10scaler.transform(y1_train_10)\n",
        "y1_11train_scaled = y1_11scaler.transform(y1_train_11)\n",
        "y1_12train_scaled = y1_12scaler.transform(y1_train_12)\n",
        "y1_13train_scaled = y1_13scaler.transform(y1_train_13)\n",
        "y1_14train_scaled = y1_14scaler.transform(y1_train_14)\n",
        "y1_15train_scaled = y1_15scaler.transform(y1_train_15)\n",
        "\n",
        "y2_1train_scaled = y2_1scaler.transform(y2_train_1)\n",
        "y2_2train_scaled = y2_2scaler.transform(y2_train_2)\n",
        "y2_3train_scaled = y2_3scaler.transform(y2_train_3)\n",
        "y2_4train_scaled = y2_4scaler.transform(y2_train_4)\n",
        "y2_5train_scaled = y2_5scaler.transform(y2_train_5)\n",
        "y2_6train_scaled = y2_6scaler.transform(y2_train_6)\n",
        "y2_7train_scaled = y2_7scaler.transform(y2_train_7)\n",
        "y2_8train_scaled = y2_8scaler.transform(y2_train_8)\n",
        "y2_9train_scaled = y2_9scaler.transform(y2_train_9)\n",
        "y2_10train_scaled = y2_10scaler.transform(y2_train_10)\n",
        "y2_11train_scaled = y2_11scaler.transform(y2_train_11)\n",
        "y2_12train_scaled = y2_12scaler.transform(y2_train_12)\n",
        "y2_13train_scaled = y2_13scaler.transform(y2_train_13)\n",
        "y2_14train_scaled = y2_14scaler.transform(y2_train_14)\n",
        "y2_15train_scaled = y2_15scaler.transform(y2_train_15)\n",
        "\n",
        "X1_test_scaled = X1scaler.transform(X1_test_)\n",
        "X2_test_scaled = X2scaler.transform(X2_test_)\n",
        "\n",
        "y1_1test_scaled = y1_1scaler.transform(y1_test_1)\n",
        "y1_2test_scaled = y1_2scaler.transform(y1_test_2)\n",
        "y1_3test_scaled = y1_3scaler.transform(y1_test_3)\n",
        "y1_4test_scaled = y1_4scaler.transform(y1_test_4)\n",
        "y1_5test_scaled = y1_5scaler.transform(y1_test_5)\n",
        "y1_6test_scaled = y1_6scaler.transform(y1_test_6)\n",
        "y1_7test_scaled = y1_7scaler.transform(y1_test_7)\n",
        "y1_8test_scaled = y1_8scaler.transform(y1_test_8)\n",
        "y1_9test_scaled = y1_9scaler.transform(y1_test_9)\n",
        "y1_10test_scaled = y1_10scaler.transform(y1_test_10)\n",
        "y1_11test_scaled = y1_11scaler.transform(y1_test_11)\n",
        "y1_12test_scaled = y1_12scaler.transform(y1_test_12)\n",
        "y1_13test_scaled = y1_13scaler.transform(y1_test_13)\n",
        "y1_14test_scaled = y1_14scaler.transform(y1_test_14)\n",
        "y1_15test_scaled = y1_15scaler.transform(y1_test_15)\n",
        "\n",
        "y2_1test_scaled = y2_1scaler.transform(y2_test_1)\n",
        "y2_2test_scaled = y2_2scaler.transform(y2_test_2)\n",
        "y2_3test_scaled = y2_3scaler.transform(y2_test_3)\n",
        "y2_4test_scaled = y2_4scaler.transform(y2_test_4)\n",
        "y2_5test_scaled = y2_5scaler.transform(y2_test_5)\n",
        "y2_6test_scaled = y2_6scaler.transform(y2_test_6)\n",
        "y2_7test_scaled = y2_7scaler.transform(y2_test_7)\n",
        "y2_8test_scaled = y2_8scaler.transform(y2_test_8)\n",
        "y2_9test_scaled = y2_9scaler.transform(y2_test_9)\n",
        "y2_10test_scaled = y2_10scaler.transform(y2_test_10)\n",
        "y2_11test_scaled = y2_11scaler.transform(y2_test_11)\n",
        "y2_12test_scaled = y2_12scaler.transform(y2_test_12)\n",
        "y2_13test_scaled = y2_13scaler.transform(y2_test_13)\n",
        "y2_14test_scaled = y2_14scaler.transform(y2_test_14)\n",
        "y2_15test_scaled = y2_15scaler.transform(y2_test_15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64253acf",
      "metadata": {
        "id": "64253acf"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "X1_thresholder = VarianceThreshold(threshold=0.1)\n",
        "X1_thresholder.fit(X1_train_scaled)\n",
        "\n",
        "X1_train_scaled = X1_thresholder.transform(X1_train_scaled)\n",
        "X1_test_scaled = X1_thresholder.transform(X1_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38893b25",
      "metadata": {
        "id": "38893b25"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "X2_thresholder = VarianceThreshold(threshold=0.007)\n",
        "X2_thresholder.fit(X2_train_scaled)\n",
        "\n",
        "X2_train_scaled = X2_thresholder.transform(X2_train_scaled)\n",
        "X2_test_scaled = X2_thresholder.transform(X2_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cc4be96",
      "metadata": {
        "id": "7cc4be96"
      },
      "outputs": [],
      "source": [
        "#랜덤포레스트를 이용한 회귀\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf_reg_1 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "rf_reg_2 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "rf_reg_3 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "rf_reg_4 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "rf_reg_5 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "rf_reg_6 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "rf_reg_7 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "rf_reg_8 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "rf_reg_9 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "rf_reg_10 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "rf_reg_11 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "rf_reg_12 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "rf_reg_13 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "rf_reg_14 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "rf_reg_15 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "\n",
        "model_1 = rf_reg_1.fit(X1_train_scaled, y1_1train_scaled[:,0])\n",
        "model_2 = rf_reg_2.fit(X1_train_scaled, y1_2train_scaled[:,0])\n",
        "model_3 = rf_reg_3.fit(X1_train_scaled, y1_3train_scaled[:,0])\n",
        "model_4 = rf_reg_4.fit(X1_train_scaled, y1_4train_scaled[:,0])\n",
        "model_5 = rf_reg_5.fit(X1_train_scaled, y1_5train_scaled[:,0])\n",
        "model_6 = rf_reg_6.fit(X1_train_scaled, y1_6train_scaled[:,0])\n",
        "model_7 = rf_reg_7.fit(X1_train_scaled, y1_7train_scaled[:,0])\n",
        "model_8 = rf_reg_8.fit(X1_train_scaled, y1_8train_scaled[:,0])\n",
        "model_9 = rf_reg_9.fit(X1_train_scaled, y1_9train_scaled[:,0])\n",
        "model_10 = rf_reg_10.fit(X1_train_scaled, y1_10train_scaled[:,0])\n",
        "model_11 = rf_reg_11.fit(X1_train_scaled, y1_11train_scaled[:,0])\n",
        "model_12 = rf_reg_12.fit(X1_train_scaled, y1_12train_scaled[:,0])\n",
        "model_13 = rf_reg_13.fit(X1_train_scaled, y1_13train_scaled[:,0])\n",
        "model_14 = rf_reg_14.fit(X1_train_scaled, y1_14train_scaled[:,0])\n",
        "model_15 = rf_reg_15.fit(X1_train_scaled, y1_15train_scaled[:,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30ce06f4",
      "metadata": {
        "id": "30ce06f4"
      },
      "outputs": [],
      "source": [
        "#변수별 중요도를 이용해 특성행렬 선택후 학습\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "selector_1 = SelectFromModel(model_1, threshold = 'median')\n",
        "selector_2 = SelectFromModel(model_2, threshold = 'median')\n",
        "selector_3 = SelectFromModel(model_3, threshold = 'median')\n",
        "selector_4 = SelectFromModel(model_4, threshold = 'median')\n",
        "selector_5 = SelectFromModel(model_5, threshold = 'median')\n",
        "selector_6 = SelectFromModel(model_6, threshold = 'median')\n",
        "selector_7 = SelectFromModel(model_7, threshold = 'median')\n",
        "selector_8 = SelectFromModel(model_8, threshold = 'median')\n",
        "selector_9 = SelectFromModel(model_9, threshold = 'median')\n",
        "selector_10 = SelectFromModel(model_10, threshold = 'median')\n",
        "selector_11= SelectFromModel(model_11, threshold = 'median')\n",
        "selector_12 = SelectFromModel(model_12, threshold = 'median')\n",
        "selector_13 = SelectFromModel(model_13, threshold = 'median')\n",
        "selector_14 = SelectFromModel(model_14, threshold = 'median')\n",
        "selector_15 = SelectFromModel(model_15, threshold = 'median')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4326d6f8",
      "metadata": {
        "id": "4326d6f8"
      },
      "outputs": [],
      "source": [
        "#주요한 열만 뽑아서 학습하는 X1 데이터셋\n",
        "train_feature_important_1 = selector_1.fit_transform(X1_train_scaled, y1_1train_scaled[:,0])\n",
        "train_feature_important_2 = selector_2.fit_transform(X1_train_scaled, y1_2train_scaled[:,0])\n",
        "train_feature_important_3 = selector_3.fit_transform(X1_train_scaled, y1_3train_scaled[:,0])\n",
        "train_feature_important_4 = selector_4.fit_transform(X1_train_scaled, y1_4train_scaled[:,0])\n",
        "train_feature_important_5 = selector_5.fit_transform(X1_train_scaled, y1_5train_scaled[:,0])\n",
        "train_feature_important_6 = selector_6.fit_transform(X1_train_scaled, y1_6train_scaled[:,0])\n",
        "train_feature_important_7 = selector_7.fit_transform(X1_train_scaled, y1_7train_scaled[:,0])\n",
        "train_feature_important_8 = selector_8.fit_transform(X1_train_scaled, y1_8train_scaled[:,0])\n",
        "train_feature_important_9 = selector_9.fit_transform(X1_train_scaled, y1_9train_scaled[:,0])\n",
        "train_feature_important_10 = selector_10.fit_transform(X1_train_scaled, y1_10train_scaled[:,0])\n",
        "train_feature_important_11 = selector_11.fit_transform(X1_train_scaled, y1_11train_scaled[:,0])\n",
        "train_feature_important_12 = selector_12.fit_transform(X1_train_scaled, y1_12train_scaled[:,0])\n",
        "train_feature_important_13 = selector_13.fit_transform(X1_train_scaled, y1_13train_scaled[:,0])\n",
        "train_feature_important_14 = selector_14.fit_transform(X1_train_scaled, y1_14train_scaled[:,0])\n",
        "train_feature_important_15 = selector_15.fit_transform(X1_train_scaled, y1_15train_scaled[:,0])\n",
        "\n",
        "test_feature_important_1 = selector_1.transform(X1_test_scaled)\n",
        "test_feature_important_2 = selector_2.transform(X1_test_scaled)\n",
        "test_feature_important_3 = selector_3.transform(X1_test_scaled)\n",
        "test_feature_important_4 = selector_4.transform(X1_test_scaled)\n",
        "test_feature_important_5 = selector_5.transform(X1_test_scaled)\n",
        "test_feature_important_6 = selector_6.transform(X1_test_scaled)\n",
        "test_feature_important_7 = selector_7.transform(X1_test_scaled)\n",
        "test_feature_important_8 = selector_8.transform(X1_test_scaled)\n",
        "test_feature_important_9 = selector_9.transform(X1_test_scaled)\n",
        "test_feature_important_10 = selector_10.transform(X1_test_scaled)\n",
        "test_feature_important_11 = selector_11.transform(X1_test_scaled)\n",
        "test_feature_important_12 = selector_12.transform(X1_test_scaled)\n",
        "test_feature_important_13 = selector_13.transform(X1_test_scaled)\n",
        "test_feature_important_14 = selector_14.transform(X1_test_scaled)\n",
        "test_feature_important_15 = selector_15.transform(X1_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3240684b",
      "metadata": {
        "id": "3240684b"
      },
      "outputs": [],
      "source": [
        "# 배깅모델\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "bag_reg_1 = BaggingRegressor(\n",
        "    DecisionTreeRegressor(random_state = 0, criterion = \"mae\"),\n",
        "    n_estimators = 500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1)\n",
        "bag_reg_2 = BaggingRegressor(\n",
        "    DecisionTreeRegressor(random_state = 0, criterion = \"mae\"),\n",
        "    n_estimators = 500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1)\n",
        "bag_reg_3 = BaggingRegressor(\n",
        "    DecisionTreeRegressor(random_state = 0, criterion = \"mae\"),\n",
        "    n_estimators = 500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1)\n",
        "bag_reg_4 = BaggingRegressor(\n",
        "    DecisionTreeRegressor(random_state = 0, criterion = \"mae\"),\n",
        "    n_estimators = 500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1)\n",
        "bag_reg_5 = BaggingRegressor(\n",
        "    DecisionTreeRegressor(random_state = 0, criterion = \"mae\"),\n",
        "    n_estimators = 500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1)\n",
        "bag_reg_6 = BaggingRegressor(\n",
        "    DecisionTreeRegressor(random_state = 0, criterion = \"mae\"),\n",
        "    n_estimators = 500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1)\n",
        "bag_reg_7 = BaggingRegressor(\n",
        "    DecisionTreeRegressor(random_state = 0, criterion = \"mae\"),\n",
        "    n_estimators = 500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1)\n",
        "bag_reg_8 = BaggingRegressor(\n",
        "    DecisionTreeRegressor(random_state = 0, criterion = \"mae\"),\n",
        "    n_estimators = 500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1)\n",
        "bag_reg_9 = BaggingRegressor(\n",
        "    DecisionTreeRegressor(random_state = 0, criterion = \"mae\"),\n",
        "    n_estimators = 500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1)\n",
        "bag_reg_10 = BaggingRegressor(\n",
        "    DecisionTreeRegressor(random_state = 0, criterion = \"mae\"),\n",
        "    n_estimators = 500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1)\n",
        "bag_reg_11 = BaggingRegressor(\n",
        "    DecisionTreeRegressor(random_state = 0, criterion = \"mae\"),\n",
        "    n_estimators = 500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1)\n",
        "bag_reg_12 = BaggingRegressor(\n",
        "    DecisionTreeRegressor(random_state = 0, criterion = \"mae\"),\n",
        "    n_estimators = 500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1)\n",
        "bag_reg_13 = BaggingRegressor(\n",
        "    DecisionTreeRegressor(random_state = 0, criterion = \"mae\"),\n",
        "    n_estimators = 500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1)\n",
        "bag_reg_14 = BaggingRegressor(\n",
        "    DecisionTreeRegressor(random_state = 0, criterion = \"mae\"),\n",
        "    n_estimators = 500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1)\n",
        "bag_reg_15 = BaggingRegressor(\n",
        "    DecisionTreeRegressor(random_state = 0, criterion = \"mae\"),\n",
        "    n_estimators = 500,\n",
        "    max_samples=100,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d84d0667",
      "metadata": {
        "id": "d84d0667"
      },
      "outputs": [],
      "source": [
        "#그레디언트 부스팅모델\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gbrt_1 = GradientBoostingRegressor(max_depth=3, learning_rate = 0.1, max_features = 'auto' ,warm_start = True)\n",
        "gbrt_2 = GradientBoostingRegressor(max_depth=3, learning_rate = 0.1, max_features = 'auto' ,warm_start = True)\n",
        "gbrt_3 = GradientBoostingRegressor(max_depth=3, learning_rate = 0.1, max_features = 'auto' ,warm_start = True)\n",
        "gbrt_4 = GradientBoostingRegressor(max_depth=3, learning_rate = 0.1, max_features = 'auto' ,warm_start = True)\n",
        "gbrt_5 = GradientBoostingRegressor(max_depth=3, learning_rate = 0.1, max_features = 'auto' ,warm_start = True)\n",
        "gbrt_6 = GradientBoostingRegressor(max_depth=3, learning_rate = 0.1, max_features = 'auto' ,warm_start = True)\n",
        "gbrt_7 = GradientBoostingRegressor(max_depth=3, learning_rate = 0.1, max_features = 'auto' ,warm_start = True)\n",
        "gbrt_8 = GradientBoostingRegressor(max_depth=3, learning_rate = 0.1, max_features = 'auto' ,warm_start = True)\n",
        "gbrt_9 = GradientBoostingRegressor(max_depth=3, learning_rate = 0.1, max_features = 'auto' ,warm_start = True)\n",
        "gbrt_10 = GradientBoostingRegressor(max_depth=3, learning_rate = 0.1, max_features = 'auto' ,warm_start = True)\n",
        "gbrt_11 = GradientBoostingRegressor(max_depth=3, learning_rate = 0.1, max_features = 'auto' ,warm_start = True)\n",
        "gbrt_12 = GradientBoostingRegressor(max_depth=3, learning_rate = 0.1, max_features = 'auto' ,warm_start = True)\n",
        "gbrt_13 = GradientBoostingRegressor(max_depth=3, learning_rate = 0.1, max_features = 'auto' ,warm_start = True)\n",
        "gbrt_14 = GradientBoostingRegressor(max_depth=3, learning_rate = 0.1, max_features = 'auto' ,warm_start = True)\n",
        "gbrt_15 = GradientBoostingRegressor(max_depth=3, learning_rate = 0.1, max_features = 'auto' ,warm_start = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbe0a331",
      "metadata": {
        "id": "cbe0a331",
        "outputId": "e8dc665a-cf26-4916-e941-71db1989bbe8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n",
            "/home/elicer/.local/lib/python3.9/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#알고리즘별 최선의 값을 뽑아서 모델 형성\n",
        "model_1 = rf_reg_1.fit(train_feature_important_1, y1_1train_scaled[:,0])\n",
        "model_2 = rf_reg_2.fit(train_feature_important_2, y1_2train_scaled[:,0])\n",
        "model_3 = bag_reg_3.fit(train_feature_important_3, y1_1train_scaled[:,0])\n",
        "model_4 = bag_reg_4.fit(train_feature_important_4, y1_1train_scaled[:,0])\n",
        "model_5 = gbrt_5.fit(train_feature_important_5, y1_5train_scaled[:,0])\n",
        "model_6 = bag_reg_6.fit(train_feature_important_6, y1_1train_scaled[:,0])\n",
        "model_7 = rf_reg_7.fit(train_feature_important_7, y1_7train_scaled[:,0])\n",
        "model_8 = rf_reg_8.fit(train_feature_important_8, y1_8train_scaled[:,0])\n",
        "model_9 = bag_reg_9.fit(train_feature_important_9, y1_1train_scaled[:,0])\n",
        "model_10 = rf_reg_10.fit(train_feature_important_10, y1_10train_scaled[:,0])\n",
        "model_11 = rf_reg_11.fit(train_feature_important_11, y1_11train_scaled[:,0])\n",
        "model_12 = rf_reg_12.fit(train_feature_important_12, y1_12train_scaled[:,0])\n",
        "model_13 = rf_reg_13.fit(train_feature_important_13, y1_13train_scaled[:,0])\n",
        "model_14 = rf_reg_14.fit(train_feature_important_14, y1_14train_scaled[:,0])\n",
        "model_15 = rf_reg_15.fit(train_feature_important_15, y1_15train_scaled[:,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49f430df",
      "metadata": {
        "id": "49f430df"
      },
      "outputs": [],
      "source": [
        "#test 데이터셋으로 stage1의 예측값 계산\n",
        "# MinMaxScaler decode해줘야함\n",
        "\n",
        "y1_1 = model_1.predict(test_feature_important_1)\n",
        "y1_2 = model_2.predict(test_feature_important_2)\n",
        "y1_3 = model_3.predict(test_feature_important_3)\n",
        "y1_4 = model_4.predict(test_feature_important_4)\n",
        "y1_5 = model_5.predict(test_feature_important_5)\n",
        "y1_6 = model_6.predict(test_feature_important_6)\n",
        "y1_7 = model_7.predict(test_feature_important_7)\n",
        "y1_8 = model_8.predict(test_feature_important_8)\n",
        "y1_9 = model_9.predict(test_feature_important_9)\n",
        "y1_10 = model_10.predict(test_feature_important_10)\n",
        "y1_11 = model_11.predict(test_feature_important_11)\n",
        "y1_12 = model_12.predict(test_feature_important_12)\n",
        "y1_13 = model_13.predict(test_feature_important_13)\n",
        "y1_14 = model_14.predict(test_feature_important_14)\n",
        "y1_15 = model_15.predict(test_feature_important_15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "576f4f63",
      "metadata": {
        "id": "576f4f63"
      },
      "outputs": [],
      "source": [
        "#MinMaxScaler inverse transform으로 예측값을 만들어준다.\n",
        "\n",
        "real_y1_1 = y1_1scaler.inverse_transform(y1_1.reshape(-1,1))\n",
        "real_y1_2 = y1_2scaler.inverse_transform(y1_2.reshape(-1,1))\n",
        "real_y1_3 = y1_3scaler.inverse_transform(y1_3.reshape(-1,1))\n",
        "real_y1_4 = y1_4scaler.inverse_transform(y1_4.reshape(-1,1))\n",
        "real_y1_5 = y1_5scaler.inverse_transform(y1_5.reshape(-1,1))\n",
        "real_y1_6 = y1_6scaler.inverse_transform(y1_6.reshape(-1,1))\n",
        "real_y1_7 = y1_7scaler.inverse_transform(y1_7.reshape(-1,1))\n",
        "real_y1_8 = y1_8scaler.inverse_transform(y1_8.reshape(-1,1))\n",
        "real_y1_9 = y1_9scaler.inverse_transform(y1_9.reshape(-1,1))\n",
        "real_y1_10 = y1_10scaler.inverse_transform(y1_10.reshape(-1,1))\n",
        "real_y1_11 = y1_11scaler.inverse_transform(y1_11.reshape(-1,1))\n",
        "real_y1_12 = y1_12scaler.inverse_transform(y1_12.reshape(-1,1))\n",
        "real_y1_13 = y1_13scaler.inverse_transform(y1_13.reshape(-1,1))\n",
        "real_y1_14 = y1_14scaler.inverse_transform(y1_14.reshape(-1,1))\n",
        "real_y1_15 = y1_15scaler.inverse_transform(y1_15.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8233953e",
      "metadata": {
        "id": "8233953e"
      },
      "outputs": [],
      "source": [
        "# 데이터프레임으로 확인\n",
        "stage1 = pd.DataFrame()\n",
        "\n",
        "stage1['1'] = pd.DataFrame(real_y1_1)\n",
        "stage1['2'] = pd.DataFrame(real_y1_2)\n",
        "stage1['3'] = pd.DataFrame(real_y1_3)\n",
        "stage1['4'] = pd.DataFrame(real_y1_4)\n",
        "stage1['5'] = pd.DataFrame(real_y1_5)\n",
        "stage1['6'] = pd.DataFrame(real_y1_6)\n",
        "stage1['7'] = pd.DataFrame(real_y1_7)\n",
        "stage1['8'] = pd.DataFrame(real_y1_8)\n",
        "stage1['9'] = pd.DataFrame(real_y1_9)\n",
        "stage1['10'] = pd.DataFrame(real_y1_10)\n",
        "stage1['11'] = pd.DataFrame(real_y1_11)\n",
        "stage1['12'] = pd.DataFrame(real_y1_12)\n",
        "stage1['13'] = pd.DataFrame(real_y1_13)\n",
        "stage1['14'] = pd.DataFrame(real_y1_14)\n",
        "stage1['15'] = pd.DataFrame(real_y1_15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e3279c4",
      "metadata": {
        "id": "6e3279c4",
        "outputId": "94f82410-9a02-4614-a48b-4af57415a793"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot: >"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "stage1.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa6520fb",
      "metadata": {
        "id": "aa6520fb"
      },
      "outputs": [],
      "source": [
        "# X1 train데이터로 예측한 y1 측정값을 학습데이터로 만들어준다.\n",
        "X2_train = pd.DataFrame(data = X2_train_scaled, columns = [['data1','data2','data3','data4','data5','data6','data7','data8']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0771c34",
      "metadata": {
        "id": "e0771c34"
      },
      "outputs": [],
      "source": [
        "X2_train['y1_1'] = pd.DataFrame(data = model_1.predict(train_feature_important_1))\n",
        "X2_train['y1_2'] = pd.DataFrame(data = model_2.predict(train_feature_important_2))\n",
        "X2_train['y1_3'] = pd.DataFrame(data = model_3.predict(train_feature_important_3))\n",
        "X2_train['y1_4'] = pd.DataFrame(data = model_4.predict(train_feature_important_4))\n",
        "X2_train['y1_5'] = pd.DataFrame(data = model_5.predict(train_feature_important_5))\n",
        "X2_train['y1_6'] = pd.DataFrame(data = model_6.predict(train_feature_important_6))\n",
        "X2_train['y1_7'] = pd.DataFrame(data = model_7.predict(train_feature_important_7))\n",
        "X2_train['y1_8'] = pd.DataFrame(data = model_8.predict(train_feature_important_8))\n",
        "X2_train['y1_9'] = pd.DataFrame(data = model_9.predict(train_feature_important_9))\n",
        "X2_train['y1_10'] = pd.DataFrame(data = model_10.predict(train_feature_important_10))\n",
        "X2_train['y1_11'] = pd.DataFrame(data = model_11.predict(train_feature_important_11))\n",
        "X2_train['y1_12'] = pd.DataFrame(data = model_12.predict(train_feature_important_12))\n",
        "X2_train['y1_13'] = pd.DataFrame(data = model_13.predict(train_feature_important_13))\n",
        "X2_train['y1_14'] = pd.DataFrame(data = model_14.predict(train_feature_important_14))\n",
        "X2_train['y1_15'] = pd.DataFrame(data = model_15.predict(train_feature_important_15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da8bdd91",
      "metadata": {
        "id": "da8bdd91",
        "outputId": "0e9e5686-90e5-45bb-f6e5-62937affc633"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>data1</th>\n",
              "      <th>data2</th>\n",
              "      <th>data3</th>\n",
              "      <th>data4</th>\n",
              "      <th>data5</th>\n",
              "      <th>data6</th>\n",
              "      <th>data7</th>\n",
              "      <th>data8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.040422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.032513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.035149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.005525</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.035149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.011050</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.027241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11265</th>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.889503</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.964851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11266</th>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.883978</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.966608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11267</th>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.883978</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.963972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11268</th>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.883978</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.963972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11269</th>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.889503</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.964851</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11270 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          data1     data2     data3     data4     data5     data6     data7  \\\n",
              "0      0.636364  0.636364  0.000000  0.333333  0.016129  0.135135  1.000000   \n",
              "1      0.727273  0.727273  0.000000  0.166667  0.016129  0.135135  1.000000   \n",
              "2      1.000000  1.000000  0.000000  0.166667  0.016129  0.135135  0.969697   \n",
              "3      1.000000  1.000000  0.005525  0.166667  0.016129  0.135135  0.969697   \n",
              "4      0.909091  0.909091  0.011050  0.166667  0.016129  0.135135  0.969697   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "11265  0.363636  0.363636  0.889503  0.500000  1.000000  0.959459  0.272727   \n",
              "11266  0.363636  0.363636  0.883978  0.333333  1.000000  0.959459  0.272727   \n",
              "11267  0.454545  0.454545  0.883978  0.333333  1.000000  0.959459  0.272727   \n",
              "11268  0.272727  0.272727  0.883978  0.333333  1.000000  0.959459  0.272727   \n",
              "11269  0.454545  0.454545  0.889503  0.333333  1.000000  0.959459  0.272727   \n",
              "\n",
              "          data8  \n",
              "0      0.040422  \n",
              "1      0.032513  \n",
              "2      0.035149  \n",
              "3      0.035149  \n",
              "4      0.027241  \n",
              "...         ...  \n",
              "11265  0.964851  \n",
              "11266  0.966608  \n",
              "11267  0.963972  \n",
              "11268  0.963972  \n",
              "11269  0.964851  \n",
              "\n",
              "[11270 rows x 8 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X2_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fc9f70e",
      "metadata": {
        "id": "3fc9f70e"
      },
      "outputs": [],
      "source": [
        "#y2 예측을 위한 랜덤포레스트모델\n",
        "yrf_reg_1 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "yrf_reg_2 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "yrf_reg_3 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "yrf_reg_4 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "yrf_reg_5 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "yrf_reg_6 = RandomForestRegressor(n_estimators = 500,  random_state=0)\n",
        "yrf_reg_7 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "yrf_reg_8 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "yrf_reg_9 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "yrf_reg_10 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "yrf_reg_11 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "yrf_reg_12 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "yrf_reg_13 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "yrf_reg_14 = RandomForestRegressor(n_estimators = 500, random_state=0)\n",
        "yrf_reg_15 = RandomForestRegressor(n_estimators = 500,  random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "692c2305",
      "metadata": {
        "scrolled": true,
        "id": "692c2305"
      },
      "outputs": [],
      "source": [
        "ymodel_1 = rf_reg_1.fit(X2_train, y2_1train_scaled[:,0])\n",
        "ymodel_2 = rf_reg_2.fit(X2_train, y2_2train_scaled[:,0])\n",
        "ymodel_3 = rf_reg_3.fit(X2_train, y2_3train_scaled[:,0])\n",
        "ymodel_4 = rf_reg_4.fit(X2_train, y2_4train_scaled[:,0])\n",
        "ymodel_5 = rf_reg_5.fit(X2_train, y2_5train_scaled[:,0])\n",
        "ymodel_6 = rf_reg_6.fit(X2_train, y2_6train_scaled[:,0])\n",
        "ymodel_7 = rf_reg_7.fit(X2_train, y2_7train_scaled[:,0])\n",
        "ymodel_8 = rf_reg_8.fit(X2_train, y2_8train_scaled[:,0])\n",
        "ymodel_9 = rf_reg_9.fit(X2_train, y2_9train_scaled[:,0])\n",
        "ymodel_10 = rf_reg_10.fit(X2_train, y2_10train_scaled[:,0])\n",
        "ymodel_11 = rf_reg_11.fit(X2_train, y2_11train_scaled[:,0])\n",
        "ymodel_12 = rf_reg_12.fit(X2_train, y2_12train_scaled[:,0])\n",
        "ymodel_13 = rf_reg_13.fit(X2_train, y2_13train_scaled[:,0])\n",
        "ymodel_14 = rf_reg_14.fit(X2_train, y2_14train_scaled[:,0])\n",
        "ymodel_15 = rf_reg_15.fit(X2_train, y2_15train_scaled[:,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "071a1841",
      "metadata": {
        "id": "071a1841"
      },
      "outputs": [],
      "source": [
        "X2_test = pd.DataFrame(data = X2_test_scaled, columns = ['data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7', 'data8'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23dbfc62",
      "metadata": {
        "id": "23dbfc62"
      },
      "outputs": [],
      "source": [
        "X2_test['y1_1'] = pd.DataFrame(data = y1_1)\n",
        "X2_test['y1_2'] = pd.DataFrame(data = y1_2)\n",
        "X2_test['y1_3'] = pd.DataFrame(data = y1_3)\n",
        "X2_test['y1_4'] = pd.DataFrame(data = y1_4)\n",
        "X2_test['y1_5'] = pd.DataFrame(data = y1_5)\n",
        "X2_test['y1_6'] = pd.DataFrame(data = y1_6)\n",
        "X2_test['y1_7'] = pd.DataFrame(data = y1_7)\n",
        "X2_test['y1_8'] = pd.DataFrame(data = y1_8)\n",
        "X2_test['y1_9'] = pd.DataFrame(data = y1_9)\n",
        "X2_test['y1_10'] = pd.DataFrame(data = y1_10)\n",
        "X2_test['y1_11'] = pd.DataFrame(data = y1_11)\n",
        "X2_test['y1_12'] = pd.DataFrame(data = y1_12)\n",
        "X2_test['y1_13'] = pd.DataFrame(data = y1_13)\n",
        "X2_test['y1_14'] = pd.DataFrame(data = y1_14)\n",
        "X2_test['y1_15'] = pd.DataFrame(data = y1_15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "015f25d0",
      "metadata": {
        "id": "015f25d0",
        "outputId": "8eb5a38c-72bc-49e3-eac7-0ae649d9ab8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2818 entries, 0 to 2817\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   data1   2818 non-null   float64\n",
            " 1   data2   2818 non-null   float64\n",
            " 2   data3   2818 non-null   float64\n",
            " 3   data4   2818 non-null   float64\n",
            " 4   data5   2818 non-null   float64\n",
            " 5   data6   2818 non-null   float64\n",
            " 6   data7   2818 non-null   float64\n",
            " 7   data8   2818 non-null   float64\n",
            "dtypes: float64(8)\n",
            "memory usage: 176.2 KB\n"
          ]
        }
      ],
      "source": [
        "X2_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d9b65b4",
      "metadata": {
        "id": "2d9b65b4"
      },
      "outputs": [],
      "source": [
        "X2_test_value = X2_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a50b632",
      "metadata": {
        "id": "9a50b632",
        "outputId": "92208233-6bce-44b4-dcc7-abd23a87e3d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2818, 8)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X2_test_value.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "452556da",
      "metadata": {
        "id": "452556da"
      },
      "outputs": [],
      "source": [
        "#test 데이터셋으로 stage2의 예측값 계산\n",
        "# MinMaxScaler decode해줘야함\n",
        "\n",
        "y2_1 = ymodel_1.predict(X2_test_value)\n",
        "y2_2 = ymodel_2.predict(X2_test_value)\n",
        "y2_3 = ymodel_3.predict(X2_test_value)\n",
        "y2_4 = ymodel_4.predict(X2_test_value)\n",
        "y2_5 = ymodel_5.predict(X2_test_value)\n",
        "y2_6 = ymodel_6.predict(X2_test_value)\n",
        "y2_7 = ymodel_7.predict(X2_test_value)\n",
        "y2_8 = ymodel_8.predict(X2_test_value)\n",
        "y2_9 = ymodel_9.predict(X2_test_value)\n",
        "y2_10 = ymodel_10.predict(X2_test_value)\n",
        "y2_11 = ymodel_11.predict(X2_test_value)\n",
        "y2_12 = ymodel_12.predict(X2_test_value)\n",
        "y2_13 = ymodel_13.predict(X2_test_value)\n",
        "y2_14 = ymodel_14.predict(X2_test_value)\n",
        "y2_15 = ymodel_15.predict(X2_test_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fe19eee",
      "metadata": {
        "id": "7fe19eee"
      },
      "outputs": [],
      "source": [
        "#MinMaxScaler inverse transform으로 예측값을 만들어준다.\n",
        "\n",
        "real_y2_1 = y2_1scaler.inverse_transform(y2_1.reshape(-1,1))\n",
        "real_y2_2 = y2_2scaler.inverse_transform(y2_2.reshape(-1,1))\n",
        "real_y2_3 = y2_3scaler.inverse_transform(y2_3.reshape(-1,1))\n",
        "real_y2_4 = y2_4scaler.inverse_transform(y2_4.reshape(-1,1))\n",
        "real_y2_5 = y2_5scaler.inverse_transform(y2_5.reshape(-1,1))\n",
        "real_y2_6 = y2_6scaler.inverse_transform(y2_6.reshape(-1,1))\n",
        "real_y2_7 = y2_7scaler.inverse_transform(y2_7.reshape(-1,1))\n",
        "real_y2_8 = y2_8scaler.inverse_transform(y2_8.reshape(-1,1))\n",
        "real_y2_9 = y2_9scaler.inverse_transform(y2_9.reshape(-1,1))\n",
        "real_y2_10 = y2_10scaler.inverse_transform(y2_10.reshape(-1,1))\n",
        "real_y2_11 = y2_11scaler.inverse_transform(y2_11.reshape(-1,1))\n",
        "real_y2_12 = y2_12scaler.inverse_transform(y2_12.reshape(-1,1))\n",
        "real_y2_13 = y2_13scaler.inverse_transform(y2_13.reshape(-1,1))\n",
        "real_y2_14 = y2_14scaler.inverse_transform(y2_14.reshape(-1,1))\n",
        "real_y2_15 = y2_15scaler.inverse_transform(y2_15.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5711d14",
      "metadata": {
        "id": "c5711d14"
      },
      "outputs": [],
      "source": [
        "# 데이터프레임으로 확인\n",
        "stage2 = pd.DataFrame()\n",
        "\n",
        "stage2['1'] = pd.DataFrame(real_y2_1)\n",
        "stage2['2'] = pd.DataFrame(real_y2_2)\n",
        "stage2['3'] = pd.DataFrame(real_y2_3)\n",
        "stage2['4'] = pd.DataFrame(real_y2_4)\n",
        "stage2['5'] = pd.DataFrame(real_y2_5)\n",
        "stage2['6'] = pd.DataFrame(real_y2_6)\n",
        "stage2['7'] = pd.DataFrame(real_y2_7)\n",
        "stage2['8'] = pd.DataFrame(real_y2_8)\n",
        "stage2['9'] = pd.DataFrame(real_y2_9)\n",
        "stage2['10'] = pd.DataFrame(real_y2_10)\n",
        "stage2['11'] = pd.DataFrame(real_y2_11)\n",
        "stage2['12'] = pd.DataFrame(real_y2_12)\n",
        "stage2['13'] = pd.DataFrame(real_y2_13)\n",
        "stage2['14'] = pd.DataFrame(real_y2_14)\n",
        "stage2['15'] = pd.DataFrame(real_y2_15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ad4a3f8",
      "metadata": {
        "id": "5ad4a3f8",
        "outputId": "6783a19c-305e-4274-f142-b8336384b6dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot: >"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "stage2.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6a75b6b",
      "metadata": {
        "id": "f6a75b6b"
      },
      "source": [
        "## 딥러닝 회귀모델을 사용한 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d46ac8e",
      "metadata": {
        "id": "0d46ac8e"
      },
      "outputs": [],
      "source": [
        "# MinMaxScaler적용을 위해 2차원으로 데이터를 변형 시켜준다\n",
        "X1_train_ = X1_train.values.reshape(-1,len(X1_train.columns))\n",
        "X2_train_ = X2_train.values.reshape(-1,len(X2_train.columns))\n",
        "X1_test_ = X1_test.values.reshape(-1,len(X1_test.columns))\n",
        "X2_test_ = X2_test.values.reshape(-1,len(X2_test.columns))\n",
        "\n",
        "y1_train_ = y1_train.values.reshape(-1,len(y1_train.columns))\n",
        "y2_train_ = y2_train.values.reshape(-1,len(y2_train.columns))\n",
        "y1_test_ = y1_test.values.reshape(-1,len(y1_test.columns))\n",
        "y2_test_ = y2_test.values.reshape(-1,len(y2_test.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5cad8bc",
      "metadata": {
        "id": "b5cad8bc"
      },
      "outputs": [],
      "source": [
        "#Scaler 정의\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X1scaler = MinMaxScaler()\n",
        "X2scaler = MinMaxScaler()\n",
        "\n",
        "y1scaler = MinMaxScaler()\n",
        "y2scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c686efc",
      "metadata": {
        "id": "5c686efc"
      },
      "outputs": [],
      "source": [
        "#데이터 정규화\n",
        "\n",
        "X1scaler.fit(X1_train_)\n",
        "X2scaler.fit(X2_train_)\n",
        "y1scaler.fit(y1_train_)\n",
        "y2scaler.fit(y2_train_)\n",
        "\n",
        "X1_train_scaled = X1scaler.transform(X1_train_)\n",
        "X2_train_scaled = X2scaler.transform(X2_train_)\n",
        "\n",
        "y1_train_scaled = y1scaler.transform(y1_train_)\n",
        "y2_train_scaled = y2scaler.transform(y2_train_)\n",
        "\n",
        "X1_test_scaled = X1scaler.transform(X1_test_)\n",
        "X2_test_scaled = X2scaler.transform(X2_test_)\n",
        "\n",
        "y1_test_scaled = y1scaler.transform(y1_test_)\n",
        "y2_test_scaled = y2scaler.transform(y2_test_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b753cfc",
      "metadata": {
        "id": "3b753cfc"
      },
      "outputs": [],
      "source": [
        "X1_train_scaled_df = pd.DataFrame(data = X1_train_scaled, columns = X1_train.columns)\n",
        "X2_train_scaled_df = pd.DataFrame(data = X2_train_scaled, columns = X2_train.columns)\n",
        "X1_test_scaled_df = pd.DataFrame(data = X1_test_scaled, columns = X1_test.columns)\n",
        "X2_test_scaled_df = pd.DataFrame(data = X2_test_scaled, columns = X2_test.columns)\n",
        "\n",
        "y1_train_scaled_df = pd.DataFrame(data = y1_train_scaled, columns = y1_train.columns)\n",
        "y2_train_scaled_df = pd.DataFrame(data = y2_train_scaled, columns = y2_train.columns)\n",
        "y1_test_scaled_df = pd.DataFrame(data = y1_test_scaled, columns = y1_test.columns)\n",
        "y2_test_scaled_df = pd.DataFrame(data = y2_test_scaled, columns = y2_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7547fe9",
      "metadata": {
        "id": "d7547fe9"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "X1_thresholder = VarianceThreshold(threshold=0.08)\n",
        "X1_thresholder.fit(X1_train_scaled)\n",
        "\n",
        "X1_train_scaled = X1_thresholder.transform(X1_train_scaled)\n",
        "X1_test_scaled = X1_thresholder.transform(X1_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ea3a38e",
      "metadata": {
        "id": "9ea3a38e"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "X2_thresholder = VarianceThreshold(threshold=0.007)\n",
        "X2_thresholder.fit(X2_train_scaled)\n",
        "\n",
        "X2_train_scaled = X2_thresholder.transform(X2_train_scaled)\n",
        "X2_test_scaled = X2_thresholder.transform(X2_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ce0d9fd",
      "metadata": {
        "id": "7ce0d9fd"
      },
      "outputs": [],
      "source": [
        "X1_train_scaled_df = X1_train_scaled_df[X1_train_scaled_df.columns[X1_thresholder.get_support(indices=True)]]\n",
        "X1_test_scaled_df = X1_test_scaled_df[X1_test_scaled_df.columns[X1_thresholder.get_support(indices=True)]]\n",
        "X2_train_scaled_df = X2_train_scaled_df[X2_train_scaled_df.columns[X2_thresholder.get_support(indices=True)]]\n",
        "X2_test_scaled_df = X2_test_scaled_df[X2_test_scaled_df.columns[X2_thresholder.get_support(indices=True)]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f064d1e4",
      "metadata": {
        "id": "f064d1e4"
      },
      "outputs": [],
      "source": [
        "#시계열 정보를 넣어줌\n",
        "X1_train_scaled_df.index = X1_train.index\n",
        "X1_test_scaled_df.index = X1_test.index\n",
        "X2_train_scaled_df.index = X2_train.index\n",
        "X2_test_scaled_df.index = X2_test.index\n",
        "y1_train_scaled_df.index = y1_train.index\n",
        "y1_test_scaled_df.index = y1_test.index\n",
        "y1_train_scaled_df.index = y1_train.index\n",
        "y1_test_scaled_df.index = y1_test.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e97bfc0",
      "metadata": {
        "id": "8e97bfc0"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "reg_model1 = Sequential()\n",
        "reg_model1.add(Dense(120, activation=\"relu\", input_shape=[X1_train_scaled_df.shape[1],]))\n",
        "reg_model1.add(Dense(60, activation=\"relu\"))\n",
        "reg_model1.add(Dense(30, activation=\"relu\"))\n",
        "reg_model1.add(Dense(15))\n",
        "\n",
        "reg_model1.compile(optimizer='adam', loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2544c8ee",
      "metadata": {
        "id": "2544c8ee",
        "outputId": "1f0a4d6f-ef71-47c0-ba40-4fb1bfc32bae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "353/353 [==============================] - 1s 1ms/step - loss: 0.0383\n",
            "Epoch 2/1000\n",
            "353/353 [==============================] - 0s 962us/step - loss: 0.0177\n",
            "Epoch 3/1000\n",
            "353/353 [==============================] - 0s 935us/step - loss: 0.0173\n",
            "Epoch 4/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0171\n",
            "Epoch 5/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0171\n",
            "Epoch 6/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0168\n",
            "Epoch 7/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0166\n",
            "Epoch 8/1000\n",
            "353/353 [==============================] - 0s 958us/step - loss: 0.0163\n",
            "Epoch 9/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0161\n",
            "Epoch 10/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0157\n",
            "Epoch 11/1000\n",
            "353/353 [==============================] - 0s 947us/step - loss: 0.0152\n",
            "Epoch 12/1000\n",
            "353/353 [==============================] - 0s 913us/step - loss: 0.0148\n",
            "Epoch 13/1000\n",
            "353/353 [==============================] - 0s 904us/step - loss: 0.0144\n",
            "Epoch 14/1000\n",
            "353/353 [==============================] - 0s 920us/step - loss: 0.0140\n",
            "Epoch 15/1000\n",
            "353/353 [==============================] - 0s 966us/step - loss: 0.0137\n",
            "Epoch 16/1000\n",
            "353/353 [==============================] - 0s 989us/step - loss: 0.0134\n",
            "Epoch 17/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0132\n",
            "Epoch 18/1000\n",
            "353/353 [==============================] - 0s 911us/step - loss: 0.0130\n",
            "Epoch 19/1000\n",
            "353/353 [==============================] - 0s 891us/step - loss: 0.0128\n",
            "Epoch 20/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0125\n",
            "Epoch 21/1000\n",
            "353/353 [==============================] - 0s 887us/step - loss: 0.0124\n",
            "Epoch 22/1000\n",
            "353/353 [==============================] - 0s 882us/step - loss: 0.0122\n",
            "Epoch 23/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0122\n",
            "Epoch 24/1000\n",
            "353/353 [==============================] - 0s 912us/step - loss: 0.0121\n",
            "Epoch 25/1000\n",
            "353/353 [==============================] - 0s 914us/step - loss: 0.0118\n",
            "Epoch 26/1000\n",
            "353/353 [==============================] - 0s 906us/step - loss: 0.0117\n",
            "Epoch 27/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0117\n",
            "Epoch 28/1000\n",
            "353/353 [==============================] - 0s 918us/step - loss: 0.0115\n",
            "Epoch 29/1000\n",
            "353/353 [==============================] - 0s 919us/step - loss: 0.0113\n",
            "Epoch 30/1000\n",
            "353/353 [==============================] - 0s 919us/step - loss: 0.0113\n",
            "Epoch 31/1000\n",
            "353/353 [==============================] - 0s 902us/step - loss: 0.0113\n",
            "Epoch 32/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0112\n",
            "Epoch 33/1000\n",
            "353/353 [==============================] - 0s 910us/step - loss: 0.0111\n",
            "Epoch 34/1000\n",
            "353/353 [==============================] - 0s 893us/step - loss: 0.0109\n",
            "Epoch 35/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0110\n",
            "Epoch 36/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0110\n",
            "Epoch 37/1000\n",
            "353/353 [==============================] - 0s 910us/step - loss: 0.0109\n",
            "Epoch 38/1000\n",
            "353/353 [==============================] - 0s 918us/step - loss: 0.0108\n",
            "Epoch 39/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0107\n",
            "Epoch 40/1000\n",
            "353/353 [==============================] - 0s 912us/step - loss: 0.0109\n",
            "Epoch 41/1000\n",
            "353/353 [==============================] - 0s 911us/step - loss: 0.0108\n",
            "Epoch 42/1000\n",
            "353/353 [==============================] - 0s 911us/step - loss: 0.0107\n",
            "Epoch 43/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0107\n",
            "Epoch 44/1000\n",
            "353/353 [==============================] - 0s 963us/step - loss: 0.0106\n",
            "Epoch 45/1000\n",
            "353/353 [==============================] - 0s 958us/step - loss: 0.0106\n",
            "Epoch 46/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0104\n",
            "Epoch 47/1000\n",
            "353/353 [==============================] - 0s 951us/step - loss: 0.0106\n",
            "Epoch 48/1000\n",
            "353/353 [==============================] - 0s 907us/step - loss: 0.0106\n",
            "Epoch 49/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0106\n",
            "Epoch 50/1000\n",
            "353/353 [==============================] - 0s 966us/step - loss: 0.0103\n",
            "Epoch 51/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0104\n",
            "Epoch 52/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0104\n",
            "Epoch 53/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0103\n",
            "Epoch 54/1000\n",
            "353/353 [==============================] - 0s 963us/step - loss: 0.0103\n",
            "Epoch 55/1000\n",
            "353/353 [==============================] - 0s 909us/step - loss: 0.0103\n",
            "Epoch 56/1000\n",
            "353/353 [==============================] - 0s 916us/step - loss: 0.0101\n",
            "Epoch 57/1000\n",
            "353/353 [==============================] - 0s 950us/step - loss: 0.0101\n",
            "Epoch 58/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0101\n",
            "Epoch 59/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0103\n",
            "Epoch 60/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0101\n",
            "Epoch 61/1000\n",
            "353/353 [==============================] - 0s 919us/step - loss: 0.0101\n",
            "Epoch 62/1000\n",
            "353/353 [==============================] - 0s 921us/step - loss: 0.0099\n",
            "Epoch 63/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0103\n",
            "Epoch 64/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0101\n",
            "Epoch 65/1000\n",
            "353/353 [==============================] - 0s 939us/step - loss: 0.0100\n",
            "Epoch 66/1000\n",
            "353/353 [==============================] - 0s 946us/step - loss: 0.0100\n",
            "Epoch 67/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0101\n",
            "Epoch 68/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0099\n",
            "Epoch 69/1000\n",
            "353/353 [==============================] - 0s 943us/step - loss: 0.0098\n",
            "Epoch 70/1000\n",
            "353/353 [==============================] - 0s 913us/step - loss: 0.0101\n",
            "Epoch 71/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0098\n",
            "Epoch 72/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0102\n",
            "Epoch 73/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0098\n",
            "Epoch 74/1000\n",
            "353/353 [==============================] - 0s 911us/step - loss: 0.0098\n",
            "Epoch 75/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0098\n",
            "Epoch 76/1000\n",
            "353/353 [==============================] - 0s 935us/step - loss: 0.0100\n",
            "Epoch 77/1000\n",
            "353/353 [==============================] - 0s 920us/step - loss: 0.0099\n",
            "Epoch 78/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0098\n",
            "Epoch 79/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0099\n",
            "Epoch 80/1000\n",
            "353/353 [==============================] - 0s 947us/step - loss: 0.0098\n",
            "Epoch 81/1000\n",
            "353/353 [==============================] - 0s 978us/step - loss: 0.0098\n",
            "Epoch 82/1000\n",
            "353/353 [==============================] - 0s 919us/step - loss: 0.0098\n",
            "Epoch 83/1000\n",
            "353/353 [==============================] - 0s 924us/step - loss: 0.0098\n",
            "Epoch 84/1000\n",
            "353/353 [==============================] - 0s 915us/step - loss: 0.0096\n",
            "Epoch 85/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0098\n",
            "Epoch 86/1000\n",
            "353/353 [==============================] - 0s 903us/step - loss: 0.0097\n",
            "Epoch 87/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0097\n",
            "Epoch 88/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0097\n",
            "Epoch 89/1000\n",
            "353/353 [==============================] - 0s 915us/step - loss: 0.0097\n",
            "Epoch 90/1000\n",
            "353/353 [==============================] - 0s 956us/step - loss: 0.0097\n",
            "Epoch 91/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0096\n",
            "Epoch 92/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0096\n",
            "Epoch 93/1000\n",
            "353/353 [==============================] - 0s 916us/step - loss: 0.0097\n",
            "Epoch 94/1000\n",
            "353/353 [==============================] - 0s 895us/step - loss: 0.0095\n",
            "Epoch 95/1000\n",
            "353/353 [==============================] - 0s 921us/step - loss: 0.0097\n",
            "Epoch 96/1000\n",
            "353/353 [==============================] - 0s 917us/step - loss: 0.0096\n",
            "Epoch 97/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0096\n",
            "Epoch 98/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0097\n",
            "Epoch 99/1000\n",
            "353/353 [==============================] - 0s 957us/step - loss: 0.0097\n",
            "Epoch 100/1000\n",
            "353/353 [==============================] - 0s 915us/step - loss: 0.0096\n",
            "Epoch 101/1000\n",
            "353/353 [==============================] - 0s 985us/step - loss: 0.0096\n",
            "Epoch 102/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0096\n",
            "Epoch 103/1000\n",
            "353/353 [==============================] - 0s 911us/step - loss: 0.0096\n",
            "Epoch 104/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0095\n",
            "Epoch 105/1000\n",
            "353/353 [==============================] - 0s 911us/step - loss: 0.0094\n",
            "Epoch 106/1000\n",
            "353/353 [==============================] - 0s 908us/step - loss: 0.0094\n",
            "Epoch 107/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0094\n",
            "Epoch 108/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0096\n",
            "Epoch 109/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0094\n",
            "Epoch 110/1000\n",
            "353/353 [==============================] - 0s 913us/step - loss: 0.0094\n",
            "Epoch 111/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0093\n",
            "Epoch 112/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0096\n",
            "Epoch 113/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0094\n",
            "Epoch 114/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0095\n",
            "Epoch 115/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0094\n",
            "Epoch 116/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0096\n",
            "Epoch 117/1000\n",
            "353/353 [==============================] - 0s 971us/step - loss: 0.0093\n",
            "Epoch 118/1000\n",
            "353/353 [==============================] - 0s 908us/step - loss: 0.0093\n",
            "Epoch 119/1000\n",
            "353/353 [==============================] - 0s 947us/step - loss: 0.0094\n",
            "Epoch 120/1000\n",
            "353/353 [==============================] - 0s 963us/step - loss: 0.0094\n",
            "Epoch 121/1000\n",
            "353/353 [==============================] - 0s 968us/step - loss: 0.0093\n",
            "Epoch 122/1000\n",
            "353/353 [==============================] - 0s 962us/step - loss: 0.0094\n",
            "Epoch 123/1000\n",
            "353/353 [==============================] - 0s 950us/step - loss: 0.0094\n",
            "Epoch 124/1000\n",
            "353/353 [==============================] - 0s 916us/step - loss: 0.0093\n",
            "Epoch 125/1000\n",
            "353/353 [==============================] - 0s 918us/step - loss: 0.0094\n",
            "Epoch 126/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0094\n",
            "Epoch 127/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0093\n",
            "Epoch 128/1000\n",
            "353/353 [==============================] - 0s 938us/step - loss: 0.0094\n",
            "Epoch 129/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0092\n",
            "Epoch 130/1000\n",
            "353/353 [==============================] - 0s 938us/step - loss: 0.0093\n",
            "Epoch 131/1000\n",
            "353/353 [==============================] - 0s 906us/step - loss: 0.0093\n",
            "Epoch 132/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0093\n",
            "Epoch 133/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0093\n",
            "Epoch 134/1000\n",
            "353/353 [==============================] - 0s 963us/step - loss: 0.0093\n",
            "Epoch 135/1000\n",
            "353/353 [==============================] - 0s 950us/step - loss: 0.0091\n",
            "Epoch 136/1000\n",
            "353/353 [==============================] - 0s 916us/step - loss: 0.0092\n",
            "Epoch 137/1000\n",
            "353/353 [==============================] - 0s 904us/step - loss: 0.0093\n",
            "Epoch 138/1000\n",
            "353/353 [==============================] - 0s 950us/step - loss: 0.0093\n",
            "Epoch 139/1000\n",
            "353/353 [==============================] - 0s 914us/step - loss: 0.0092\n",
            "Epoch 140/1000\n",
            "353/353 [==============================] - 0s 904us/step - loss: 0.0092\n",
            "Epoch 141/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0092\n",
            "Epoch 142/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0094\n",
            "Epoch 143/1000\n",
            "353/353 [==============================] - 0s 915us/step - loss: 0.0092\n",
            "Epoch 144/1000\n",
            "353/353 [==============================] - 0s 915us/step - loss: 0.0092\n",
            "Epoch 145/1000\n",
            "353/353 [==============================] - 0s 948us/step - loss: 0.0092\n",
            "Epoch 146/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0091\n",
            "Epoch 147/1000\n",
            "353/353 [==============================] - 0s 919us/step - loss: 0.0093\n",
            "Epoch 148/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0091\n",
            "Epoch 149/1000\n",
            "353/353 [==============================] - 0s 963us/step - loss: 0.0092\n",
            "Epoch 150/1000\n",
            "353/353 [==============================] - 0s 956us/step - loss: 0.0092\n",
            "Epoch 151/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0093\n",
            "Epoch 152/1000\n",
            "353/353 [==============================] - 0s 975us/step - loss: 0.0092\n",
            "Epoch 153/1000\n",
            "353/353 [==============================] - 0s 974us/step - loss: 0.0092\n",
            "Epoch 154/1000\n",
            "353/353 [==============================] - 0s 927us/step - loss: 0.0091\n",
            "Epoch 155/1000\n",
            "353/353 [==============================] - 0s 958us/step - loss: 0.0092\n",
            "Epoch 156/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0092\n",
            "Epoch 157/1000\n",
            "353/353 [==============================] - 0s 911us/step - loss: 0.0090\n",
            "Epoch 158/1000\n",
            "353/353 [==============================] - 0s 902us/step - loss: 0.0090\n",
            "Epoch 159/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0092\n",
            "Epoch 160/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0092\n",
            "Epoch 161/1000\n",
            "353/353 [==============================] - 0s 989us/step - loss: 0.0092\n",
            "Epoch 162/1000\n",
            "353/353 [==============================] - 0s 959us/step - loss: 0.0091\n",
            "Epoch 163/1000\n",
            "353/353 [==============================] - 0s 921us/step - loss: 0.0091\n",
            "Epoch 164/1000\n",
            "353/353 [==============================] - 0s 920us/step - loss: 0.0092\n",
            "Epoch 165/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0090\n",
            "Epoch 166/1000\n",
            "353/353 [==============================] - 0s 954us/step - loss: 0.0091\n",
            "Epoch 167/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0091\n",
            "Epoch 168/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0091\n",
            "Epoch 169/1000\n",
            "353/353 [==============================] - 0s 919us/step - loss: 0.0091\n",
            "Epoch 170/1000\n",
            "353/353 [==============================] - 0s 918us/step - loss: 0.0090\n",
            "Epoch 171/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0092\n",
            "Epoch 172/1000\n",
            "353/353 [==============================] - 0s 935us/step - loss: 0.0090\n",
            "Epoch 173/1000\n",
            "353/353 [==============================] - 0s 938us/step - loss: 0.0091\n",
            "Epoch 174/1000\n",
            "353/353 [==============================] - 0s 901us/step - loss: 0.0090\n",
            "Epoch 175/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0090\n",
            "Epoch 176/1000\n",
            "353/353 [==============================] - 0s 920us/step - loss: 0.0091\n",
            "Epoch 177/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0090\n",
            "Epoch 178/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0090\n",
            "Epoch 179/1000\n",
            "353/353 [==============================] - 0s 949us/step - loss: 0.0090\n",
            "Epoch 180/1000\n",
            "353/353 [==============================] - 0s 948us/step - loss: 0.0090\n",
            "Epoch 181/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0092\n",
            "Epoch 182/1000\n",
            "353/353 [==============================] - 0s 907us/step - loss: 0.0091\n",
            "Epoch 183/1000\n",
            "353/353 [==============================] - 0s 946us/step - loss: 0.0091\n",
            "Epoch 184/1000\n",
            "353/353 [==============================] - 0s 947us/step - loss: 0.0090\n",
            "Epoch 185/1000\n",
            "353/353 [==============================] - 0s 971us/step - loss: 0.0090\n",
            "Epoch 186/1000\n",
            "353/353 [==============================] - 0s 960us/step - loss: 0.0089\n",
            "Epoch 187/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0089\n",
            "Epoch 188/1000\n",
            "353/353 [==============================] - 0s 909us/step - loss: 0.0089\n",
            "Epoch 189/1000\n",
            "353/353 [==============================] - 0s 896us/step - loss: 0.0091\n",
            "Epoch 190/1000\n",
            "353/353 [==============================] - 0s 913us/step - loss: 0.0090\n",
            "Epoch 191/1000\n",
            "353/353 [==============================] - 0s 906us/step - loss: 0.0090\n",
            "Epoch 192/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0090\n",
            "Epoch 193/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0090\n",
            "Epoch 194/1000\n",
            "353/353 [==============================] - 0s 913us/step - loss: 0.0090\n",
            "Epoch 195/1000\n",
            "353/353 [==============================] - 0s 896us/step - loss: 0.0090\n",
            "Epoch 196/1000\n",
            "353/353 [==============================] - 0s 907us/step - loss: 0.0091\n",
            "Epoch 197/1000\n",
            "353/353 [==============================] - 0s 900us/step - loss: 0.0089\n",
            "Epoch 198/1000\n",
            "353/353 [==============================] - 0s 894us/step - loss: 0.0091\n",
            "Epoch 199/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0090\n",
            "Epoch 200/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0089\n",
            "Epoch 201/1000\n",
            "353/353 [==============================] - 0s 948us/step - loss: 0.0090\n",
            "Epoch 202/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0089\n",
            "Epoch 203/1000\n",
            "353/353 [==============================] - 0s 894us/step - loss: 0.0090\n",
            "Epoch 204/1000\n",
            "353/353 [==============================] - 0s 881us/step - loss: 0.0090\n",
            "Epoch 205/1000\n",
            "353/353 [==============================] - 0s 915us/step - loss: 0.0089\n",
            "Epoch 206/1000\n",
            "353/353 [==============================] - 0s 947us/step - loss: 0.0089\n",
            "Epoch 207/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0090\n",
            "Epoch 208/1000\n",
            "353/353 [==============================] - 0s 894us/step - loss: 0.0089\n",
            "Epoch 209/1000\n",
            "353/353 [==============================] - 0s 914us/step - loss: 0.0090\n",
            "Epoch 210/1000\n",
            "353/353 [==============================] - 0s 916us/step - loss: 0.0089\n",
            "Epoch 211/1000\n",
            "353/353 [==============================] - 0s 938us/step - loss: 0.0089\n",
            "Epoch 212/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0089\n",
            "Epoch 213/1000\n",
            "353/353 [==============================] - 0s 935us/step - loss: 0.0090\n",
            "Epoch 214/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0088\n",
            "Epoch 215/1000\n",
            "353/353 [==============================] - 0s 968us/step - loss: 0.0089\n",
            "Epoch 216/1000\n",
            "353/353 [==============================] - 0s 956us/step - loss: 0.0089\n",
            "Epoch 217/1000\n",
            "353/353 [==============================] - 0s 959us/step - loss: 0.0090\n",
            "Epoch 218/1000\n",
            "353/353 [==============================] - 0s 968us/step - loss: 0.0089\n",
            "Epoch 219/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0091\n",
            "Epoch 220/1000\n",
            "353/353 [==============================] - 0s 977us/step - loss: 0.0089\n",
            "Epoch 221/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0088\n",
            "Epoch 222/1000\n",
            "353/353 [==============================] - 0s 917us/step - loss: 0.0090\n",
            "Epoch 223/1000\n",
            "353/353 [==============================] - 0s 962us/step - loss: 0.0088\n",
            "Epoch 224/1000\n",
            "353/353 [==============================] - 0s 906us/step - loss: 0.0090\n",
            "Epoch 225/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0087\n",
            "Epoch 226/1000\n",
            "353/353 [==============================] - 0s 924us/step - loss: 0.0089\n",
            "Epoch 227/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0088\n",
            "Epoch 228/1000\n",
            "353/353 [==============================] - 0s 899us/step - loss: 0.0089\n",
            "Epoch 229/1000\n",
            "353/353 [==============================] - 0s 909us/step - loss: 0.0090\n",
            "Epoch 230/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0089\n",
            "Epoch 231/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0088\n",
            "Epoch 232/1000\n",
            "353/353 [==============================] - 0s 902us/step - loss: 0.0089\n",
            "Epoch 233/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0088\n",
            "Epoch 234/1000\n",
            "353/353 [==============================] - 0s 918us/step - loss: 0.0089\n",
            "Epoch 235/1000\n",
            "353/353 [==============================] - 0s 957us/step - loss: 0.0088\n",
            "Epoch 236/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0089\n",
            "Epoch 237/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0089\n",
            "Epoch 238/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0089\n",
            "Epoch 239/1000\n",
            "353/353 [==============================] - 0s 935us/step - loss: 0.0089\n",
            "Epoch 240/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0088\n",
            "Epoch 241/1000\n",
            "353/353 [==============================] - 0s 915us/step - loss: 0.0087\n",
            "Epoch 242/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0088\n",
            "Epoch 243/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0088\n",
            "Epoch 244/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0088\n",
            "Epoch 245/1000\n",
            "353/353 [==============================] - 0s 943us/step - loss: 0.0089\n",
            "Epoch 246/1000\n",
            "353/353 [==============================] - 0s 918us/step - loss: 0.0088\n",
            "Epoch 247/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0087\n",
            "Epoch 248/1000\n",
            "353/353 [==============================] - 0s 947us/step - loss: 0.0087\n",
            "Epoch 249/1000\n",
            "353/353 [==============================] - 0s 962us/step - loss: 0.0088\n",
            "Epoch 250/1000\n",
            "353/353 [==============================] - 0s 900us/step - loss: 0.0089\n",
            "Epoch 251/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0089\n",
            "Epoch 252/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0088\n",
            "Epoch 253/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0089\n",
            "Epoch 254/1000\n",
            "353/353 [==============================] - 0s 958us/step - loss: 0.0088\n",
            "Epoch 255/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0086\n",
            "Epoch 256/1000\n",
            "353/353 [==============================] - 0s 935us/step - loss: 0.0089\n",
            "Epoch 257/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0089\n",
            "Epoch 258/1000\n",
            "353/353 [==============================] - 0s 946us/step - loss: 0.0088\n",
            "Epoch 259/1000\n",
            "353/353 [==============================] - 0s 948us/step - loss: 0.0086\n",
            "Epoch 260/1000\n",
            "353/353 [==============================] - 0s 972us/step - loss: 0.0088\n",
            "Epoch 261/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0088\n",
            "Epoch 262/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0088\n",
            "Epoch 263/1000\n",
            "353/353 [==============================] - 0s 950us/step - loss: 0.0090\n",
            "Epoch 264/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0088\n",
            "Epoch 265/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0087\n",
            "Epoch 266/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0087\n",
            "Epoch 267/1000\n",
            "353/353 [==============================] - 0s 907us/step - loss: 0.0087\n",
            "Epoch 268/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0087\n",
            "Epoch 269/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0087\n",
            "Epoch 270/1000\n",
            "353/353 [==============================] - 0s 904us/step - loss: 0.0086\n",
            "Epoch 271/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0088\n",
            "Epoch 272/1000\n",
            "353/353 [==============================] - 0s 946us/step - loss: 0.0086\n",
            "Epoch 273/1000\n",
            "353/353 [==============================] - 0s 985us/step - loss: 0.0086\n",
            "Epoch 274/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0086\n",
            "Epoch 275/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0088\n",
            "Epoch 276/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0088\n",
            "Epoch 277/1000\n",
            "353/353 [==============================] - 0s 954us/step - loss: 0.0088\n",
            "Epoch 278/1000\n",
            "353/353 [==============================] - 0s 970us/step - loss: 0.0089\n",
            "Epoch 279/1000\n",
            "353/353 [==============================] - 0s 909us/step - loss: 0.0086\n",
            "Epoch 280/1000\n",
            "353/353 [==============================] - 0s 885us/step - loss: 0.0088\n",
            "Epoch 281/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0086\n",
            "Epoch 282/1000\n",
            "353/353 [==============================] - 0s 963us/step - loss: 0.0087\n",
            "Epoch 283/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0089\n",
            "Epoch 284/1000\n",
            "353/353 [==============================] - 0s 982us/step - loss: 0.0087\n",
            "Epoch 285/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0086\n",
            "Epoch 286/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0088\n",
            "Epoch 287/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0087\n",
            "Epoch 288/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0087\n",
            "Epoch 289/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0086\n",
            "Epoch 290/1000\n",
            "353/353 [==============================] - 0s 981us/step - loss: 0.0089\n",
            "Epoch 291/1000\n",
            "353/353 [==============================] - 0s 971us/step - loss: 0.0088\n",
            "Epoch 292/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0087\n",
            "Epoch 293/1000\n",
            "353/353 [==============================] - 0s 964us/step - loss: 0.0086\n",
            "Epoch 294/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0086\n",
            "Epoch 295/1000\n",
            "353/353 [==============================] - 0s 959us/step - loss: 0.0086\n",
            "Epoch 296/1000\n",
            "353/353 [==============================] - 0s 953us/step - loss: 0.0087\n",
            "Epoch 297/1000\n",
            "353/353 [==============================] - 0s 918us/step - loss: 0.0086\n",
            "Epoch 298/1000\n",
            "353/353 [==============================] - 0s 949us/step - loss: 0.0087\n",
            "Epoch 299/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0087\n",
            "Epoch 300/1000\n",
            "353/353 [==============================] - 0s 935us/step - loss: 0.0087\n",
            "Epoch 301/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0086\n",
            "Epoch 302/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0088\n",
            "Epoch 303/1000\n",
            "353/353 [==============================] - 0s 921us/step - loss: 0.0086\n",
            "Epoch 304/1000\n",
            "353/353 [==============================] - 0s 939us/step - loss: 0.0088\n",
            "Epoch 305/1000\n",
            "353/353 [==============================] - 0s 956us/step - loss: 0.0087\n",
            "Epoch 306/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0086\n",
            "Epoch 307/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0086\n",
            "Epoch 308/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0086\n",
            "Epoch 309/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0087\n",
            "Epoch 310/1000\n",
            "353/353 [==============================] - 0s 939us/step - loss: 0.0087\n",
            "Epoch 311/1000\n",
            "353/353 [==============================] - 0s 946us/step - loss: 0.0089\n",
            "Epoch 312/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0086\n",
            "Epoch 313/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0087\n",
            "Epoch 314/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0086\n",
            "Epoch 315/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0087\n",
            "Epoch 316/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0086\n",
            "Epoch 317/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0086\n",
            "Epoch 318/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0087\n",
            "Epoch 319/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0091\n",
            "Epoch 320/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0087\n",
            "Epoch 321/1000\n",
            "353/353 [==============================] - 0s 913us/step - loss: 0.0085\n",
            "Epoch 322/1000\n",
            "353/353 [==============================] - 0s 958us/step - loss: 0.0085\n",
            "Epoch 323/1000\n",
            "353/353 [==============================] - 0s 960us/step - loss: 0.0086\n",
            "Epoch 324/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0085\n",
            "Epoch 325/1000\n",
            "353/353 [==============================] - 0s 975us/step - loss: 0.0086\n",
            "Epoch 326/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0087\n",
            "Epoch 327/1000\n",
            "353/353 [==============================] - 0s 951us/step - loss: 0.0087\n",
            "Epoch 328/1000\n",
            "353/353 [==============================] - 0s 918us/step - loss: 0.0087\n",
            "Epoch 329/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0086\n",
            "Epoch 330/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0086\n",
            "Epoch 331/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0085\n",
            "Epoch 332/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0086\n",
            "Epoch 333/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0088\n",
            "Epoch 334/1000\n",
            "353/353 [==============================] - 0s 956us/step - loss: 0.0087\n",
            "Epoch 335/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0086\n",
            "Epoch 336/1000\n",
            "353/353 [==============================] - 0s 894us/step - loss: 0.0088\n",
            "Epoch 337/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0085\n",
            "Epoch 338/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0085\n",
            "Epoch 339/1000\n",
            "353/353 [==============================] - 0s 904us/step - loss: 0.0086\n",
            "Epoch 340/1000\n",
            "353/353 [==============================] - 0s 914us/step - loss: 0.0087\n",
            "Epoch 341/1000\n",
            "353/353 [==============================] - 0s 946us/step - loss: 0.0087\n",
            "Epoch 342/1000\n",
            "353/353 [==============================] - 0s 949us/step - loss: 0.0086\n",
            "Epoch 343/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0086\n",
            "Epoch 344/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0086\n",
            "Epoch 345/1000\n",
            "353/353 [==============================] - 0s 906us/step - loss: 0.0088\n",
            "Epoch 346/1000\n",
            "353/353 [==============================] - 0s 915us/step - loss: 0.0086\n",
            "Epoch 347/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0086\n",
            "Epoch 348/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0085\n",
            "Epoch 349/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0085\n",
            "Epoch 350/1000\n",
            "353/353 [==============================] - 0s 946us/step - loss: 0.0086\n",
            "Epoch 351/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0086\n",
            "Epoch 352/1000\n",
            "353/353 [==============================] - 0s 920us/step - loss: 0.0086\n",
            "Epoch 353/1000\n",
            "353/353 [==============================] - 0s 924us/step - loss: 0.0086\n",
            "Epoch 354/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0085\n",
            "Epoch 355/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0086\n",
            "Epoch 356/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0084\n",
            "Epoch 357/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0086\n",
            "Epoch 358/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0085\n",
            "Epoch 359/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0086\n",
            "Epoch 360/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0086\n",
            "Epoch 361/1000\n",
            "353/353 [==============================] - 0s 906us/step - loss: 0.0086\n",
            "Epoch 362/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0085\n",
            "Epoch 363/1000\n",
            "353/353 [==============================] - 0s 951us/step - loss: 0.0085\n",
            "Epoch 364/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0086\n",
            "Epoch 365/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0085\n",
            "Epoch 366/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0085\n",
            "Epoch 367/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0085\n",
            "Epoch 368/1000\n",
            "353/353 [==============================] - 0s 927us/step - loss: 0.0084\n",
            "Epoch 369/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0085\n",
            "Epoch 370/1000\n",
            "353/353 [==============================] - 0s 915us/step - loss: 0.0085\n",
            "Epoch 371/1000\n",
            "353/353 [==============================] - 0s 919us/step - loss: 0.0086\n",
            "Epoch 372/1000\n",
            "353/353 [==============================] - 0s 924us/step - loss: 0.0086\n",
            "Epoch 373/1000\n",
            "353/353 [==============================] - 0s 892us/step - loss: 0.0086\n",
            "Epoch 374/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0085\n",
            "Epoch 375/1000\n",
            "353/353 [==============================] - 0s 956us/step - loss: 0.0085\n",
            "Epoch 376/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0085\n",
            "Epoch 377/1000\n",
            "353/353 [==============================] - 0s 954us/step - loss: 0.0085\n",
            "Epoch 378/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0086\n",
            "Epoch 379/1000\n",
            "353/353 [==============================] - 0s 943us/step - loss: 0.0085\n",
            "Epoch 380/1000\n",
            "353/353 [==============================] - 0s 959us/step - loss: 0.0086\n",
            "Epoch 381/1000\n",
            "353/353 [==============================] - 0s 957us/step - loss: 0.0086\n",
            "Epoch 382/1000\n",
            "353/353 [==============================] - 0s 951us/step - loss: 0.0086\n",
            "Epoch 383/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0085\n",
            "Epoch 384/1000\n",
            "353/353 [==============================] - 0s 918us/step - loss: 0.0085\n",
            "Epoch 385/1000\n",
            "353/353 [==============================] - 0s 902us/step - loss: 0.0085\n",
            "Epoch 386/1000\n",
            "353/353 [==============================] - 0s 903us/step - loss: 0.0085\n",
            "Epoch 387/1000\n",
            "353/353 [==============================] - 0s 917us/step - loss: 0.0085\n",
            "Epoch 388/1000\n",
            "353/353 [==============================] - 0s 908us/step - loss: 0.0083\n",
            "Epoch 389/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0086\n",
            "Epoch 390/1000\n",
            "353/353 [==============================] - 0s 938us/step - loss: 0.0085\n",
            "Epoch 391/1000\n",
            "353/353 [==============================] - 0s 914us/step - loss: 0.0086\n",
            "Epoch 392/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0085\n",
            "Epoch 393/1000\n",
            "353/353 [==============================] - 0s 905us/step - loss: 0.0085\n",
            "Epoch 394/1000\n",
            "353/353 [==============================] - 0s 900us/step - loss: 0.0085\n",
            "Epoch 395/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0085\n",
            "Epoch 396/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0084\n",
            "Epoch 397/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0085\n",
            "Epoch 398/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0085\n",
            "Epoch 399/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0086\n",
            "Epoch 400/1000\n",
            "353/353 [==============================] - 0s 899us/step - loss: 0.0085\n",
            "Epoch 401/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0086\n",
            "Epoch 402/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0085\n",
            "Epoch 403/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0084\n",
            "Epoch 404/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0085\n",
            "Epoch 405/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0084\n",
            "Epoch 406/1000\n",
            "353/353 [==============================] - 0s 909us/step - loss: 0.0085\n",
            "Epoch 407/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0085\n",
            "Epoch 408/1000\n",
            "353/353 [==============================] - 0s 959us/step - loss: 0.0084\n",
            "Epoch 409/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0085\n",
            "Epoch 410/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0086\n",
            "Epoch 411/1000\n",
            "353/353 [==============================] - 0s 962us/step - loss: 0.0085\n",
            "Epoch 412/1000\n",
            "353/353 [==============================] - 0s 949us/step - loss: 0.0084\n",
            "Epoch 413/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0085\n",
            "Epoch 414/1000\n",
            "353/353 [==============================] - 0s 959us/step - loss: 0.0085\n",
            "Epoch 415/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0085\n",
            "Epoch 416/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0084\n",
            "Epoch 417/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0084\n",
            "Epoch 418/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0085\n",
            "Epoch 419/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0084\n",
            "Epoch 420/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0084\n",
            "Epoch 421/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0084\n",
            "Epoch 422/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0084\n",
            "Epoch 423/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0085\n",
            "Epoch 424/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0085\n",
            "Epoch 425/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0084\n",
            "Epoch 426/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0084\n",
            "Epoch 427/1000\n",
            "353/353 [==============================] - 0s 910us/step - loss: 0.0084\n",
            "Epoch 428/1000\n",
            "353/353 [==============================] - 0s 913us/step - loss: 0.0084\n",
            "Epoch 429/1000\n",
            "353/353 [==============================] - 0s 951us/step - loss: 0.0085\n",
            "Epoch 430/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0085\n",
            "Epoch 431/1000\n",
            "353/353 [==============================] - 0s 939us/step - loss: 0.0085\n",
            "Epoch 432/1000\n",
            "353/353 [==============================] - 0s 949us/step - loss: 0.0085\n",
            "Epoch 433/1000\n",
            "353/353 [==============================] - 0s 912us/step - loss: 0.0085\n",
            "Epoch 434/1000\n",
            "353/353 [==============================] - 0s 904us/step - loss: 0.0086\n",
            "Epoch 435/1000\n",
            "353/353 [==============================] - 0s 946us/step - loss: 0.0084\n",
            "Epoch 436/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0084\n",
            "Epoch 437/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0085\n",
            "Epoch 438/1000\n",
            "353/353 [==============================] - 0s 917us/step - loss: 0.0085\n",
            "Epoch 439/1000\n",
            "353/353 [==============================] - 0s 888us/step - loss: 0.0085\n",
            "Epoch 440/1000\n",
            "353/353 [==============================] - 0s 935us/step - loss: 0.0085\n",
            "Epoch 441/1000\n",
            "353/353 [==============================] - 0s 963us/step - loss: 0.0085\n",
            "Epoch 442/1000\n",
            "353/353 [==============================] - 0s 938us/step - loss: 0.0085\n",
            "Epoch 443/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0083\n",
            "Epoch 444/1000\n",
            "353/353 [==============================] - 0s 927us/step - loss: 0.0085\n",
            "Epoch 445/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0084\n",
            "Epoch 446/1000\n",
            "353/353 [==============================] - 0s 913us/step - loss: 0.0084\n",
            "Epoch 447/1000\n",
            "353/353 [==============================] - 0s 948us/step - loss: 0.0084\n",
            "Epoch 448/1000\n",
            "353/353 [==============================] - 0s 978us/step - loss: 0.0084\n",
            "Epoch 449/1000\n",
            "353/353 [==============================] - 0s 966us/step - loss: 0.0084\n",
            "Epoch 450/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0083\n",
            "Epoch 451/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0085\n",
            "Epoch 452/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0085\n",
            "Epoch 453/1000\n",
            "353/353 [==============================] - 0s 938us/step - loss: 0.0085\n",
            "Epoch 454/1000\n",
            "353/353 [==============================] - 0s 957us/step - loss: 0.0085\n",
            "Epoch 455/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0084\n",
            "Epoch 456/1000\n",
            "353/353 [==============================] - 0s 951us/step - loss: 0.0085\n",
            "Epoch 457/1000\n",
            "353/353 [==============================] - 0s 921us/step - loss: 0.0085\n",
            "Epoch 458/1000\n",
            "353/353 [==============================] - 0s 917us/step - loss: 0.0084\n",
            "Epoch 459/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0083\n",
            "Epoch 460/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0084\n",
            "Epoch 461/1000\n",
            "353/353 [==============================] - 0s 909us/step - loss: 0.0084\n",
            "Epoch 462/1000\n",
            "353/353 [==============================] - 0s 951us/step - loss: 0.0084\n",
            "Epoch 463/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0084\n",
            "Epoch 464/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0084\n",
            "Epoch 465/1000\n",
            "353/353 [==============================] - 0s 918us/step - loss: 0.0085\n",
            "Epoch 466/1000\n",
            "353/353 [==============================] - 0s 903us/step - loss: 0.0084\n",
            "Epoch 467/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0084\n",
            "Epoch 468/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0084\n",
            "Epoch 469/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0084\n",
            "Epoch 470/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0085\n",
            "Epoch 471/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0084\n",
            "Epoch 472/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0085\n",
            "Epoch 473/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0085\n",
            "Epoch 474/1000\n",
            "353/353 [==============================] - 0s 960us/step - loss: 0.0084\n",
            "Epoch 475/1000\n",
            "353/353 [==============================] - 0s 956us/step - loss: 0.0083\n",
            "Epoch 476/1000\n",
            "353/353 [==============================] - 0s 951us/step - loss: 0.0084\n",
            "Epoch 477/1000\n",
            "353/353 [==============================] - 0s 950us/step - loss: 0.0086\n",
            "Epoch 478/1000\n",
            "353/353 [==============================] - 0s 919us/step - loss: 0.0084\n",
            "Epoch 479/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0085\n",
            "Epoch 480/1000\n",
            "353/353 [==============================] - 0s 916us/step - loss: 0.0083\n",
            "Epoch 481/1000\n",
            "353/353 [==============================] - 0s 918us/step - loss: 0.0084\n",
            "Epoch 482/1000\n",
            "353/353 [==============================] - 0s 908us/step - loss: 0.0083\n",
            "Epoch 483/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0085\n",
            "Epoch 484/1000\n",
            "353/353 [==============================] - 0s 963us/step - loss: 0.0086\n",
            "Epoch 485/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0086\n",
            "Epoch 486/1000\n",
            "353/353 [==============================] - 0s 947us/step - loss: 0.0084\n",
            "Epoch 487/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0084\n",
            "Epoch 488/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0084\n",
            "Epoch 489/1000\n",
            "353/353 [==============================] - 0s 954us/step - loss: 0.0084\n",
            "Epoch 490/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0084\n",
            "Epoch 491/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0085\n",
            "Epoch 492/1000\n",
            "353/353 [==============================] - 0s 970us/step - loss: 0.0084\n",
            "Epoch 493/1000\n",
            "353/353 [==============================] - 0s 973us/step - loss: 0.0084\n",
            "Epoch 494/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0084\n",
            "Epoch 495/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0084\n",
            "Epoch 496/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0083\n",
            "Epoch 497/1000\n",
            "353/353 [==============================] - 0s 959us/step - loss: 0.0084\n",
            "Epoch 498/1000\n",
            "353/353 [==============================] - 0s 953us/step - loss: 0.0084\n",
            "Epoch 499/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0085\n",
            "Epoch 500/1000\n",
            "353/353 [==============================] - 0s 913us/step - loss: 0.0083\n",
            "Epoch 501/1000\n",
            "353/353 [==============================] - 0s 911us/step - loss: 0.0083\n",
            "Epoch 502/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0084\n",
            "Epoch 503/1000\n",
            "353/353 [==============================] - 0s 901us/step - loss: 0.0084\n",
            "Epoch 504/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0084\n",
            "Epoch 505/1000\n",
            "353/353 [==============================] - 0s 943us/step - loss: 0.0083\n",
            "Epoch 506/1000\n",
            "353/353 [==============================] - 0s 939us/step - loss: 0.0084\n",
            "Epoch 507/1000\n",
            "353/353 [==============================] - 0s 938us/step - loss: 0.0084\n",
            "Epoch 508/1000\n",
            "353/353 [==============================] - 0s 903us/step - loss: 0.0085\n",
            "Epoch 509/1000\n",
            "353/353 [==============================] - 0s 904us/step - loss: 0.0083\n",
            "Epoch 510/1000\n",
            "353/353 [==============================] - 0s 915us/step - loss: 0.0083\n",
            "Epoch 511/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0082\n",
            "Epoch 512/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0084\n",
            "Epoch 513/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0084\n",
            "Epoch 514/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0083\n",
            "Epoch 515/1000\n",
            "353/353 [==============================] - 0s 920us/step - loss: 0.0084\n",
            "Epoch 516/1000\n",
            "353/353 [==============================] - 0s 918us/step - loss: 0.0084\n",
            "Epoch 517/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0083\n",
            "Epoch 518/1000\n",
            "353/353 [==============================] - 0s 915us/step - loss: 0.0085\n",
            "Epoch 519/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0082\n",
            "Epoch 520/1000\n",
            "353/353 [==============================] - 0s 939us/step - loss: 0.0084\n",
            "Epoch 521/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0083\n",
            "Epoch 522/1000\n",
            "353/353 [==============================] - 0s 921us/step - loss: 0.0082\n",
            "Epoch 523/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0084\n",
            "Epoch 524/1000\n",
            "353/353 [==============================] - 0s 906us/step - loss: 0.0084\n",
            "Epoch 525/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0084\n",
            "Epoch 526/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0083\n",
            "Epoch 527/1000\n",
            "353/353 [==============================] - 0s 911us/step - loss: 0.0085\n",
            "Epoch 528/1000\n",
            "353/353 [==============================] - 0s 919us/step - loss: 0.0083\n",
            "Epoch 529/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0082\n",
            "Epoch 530/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0083\n",
            "Epoch 531/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0082\n",
            "Epoch 532/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0083\n",
            "Epoch 533/1000\n",
            "353/353 [==============================] - 0s 943us/step - loss: 0.0083\n",
            "Epoch 534/1000\n",
            "353/353 [==============================] - 0s 901us/step - loss: 0.0083\n",
            "Epoch 535/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0083\n",
            "Epoch 536/1000\n",
            "353/353 [==============================] - 0s 971us/step - loss: 0.0083\n",
            "Epoch 537/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0083\n",
            "Epoch 538/1000\n",
            "353/353 [==============================] - 0s 935us/step - loss: 0.0083\n",
            "Epoch 539/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0085\n",
            "Epoch 540/1000\n",
            "353/353 [==============================] - 0s 909us/step - loss: 0.0084\n",
            "Epoch 541/1000\n",
            "353/353 [==============================] - 0s 938us/step - loss: 0.0084\n",
            "Epoch 542/1000\n",
            "353/353 [==============================] - 0s 917us/step - loss: 0.0084\n",
            "Epoch 543/1000\n",
            "353/353 [==============================] - 0s 935us/step - loss: 0.0084\n",
            "Epoch 544/1000\n",
            "353/353 [==============================] - 0s 905us/step - loss: 0.0084\n",
            "Epoch 545/1000\n",
            "353/353 [==============================] - 0s 991us/step - loss: 0.0083\n",
            "Epoch 546/1000\n",
            "353/353 [==============================] - 0s 961us/step - loss: 0.0083\n",
            "Epoch 547/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0083\n",
            "Epoch 548/1000\n",
            "353/353 [==============================] - 0s 974us/step - loss: 0.0083\n",
            "Epoch 549/1000\n",
            "353/353 [==============================] - 0s 943us/step - loss: 0.0083\n",
            "Epoch 550/1000\n",
            "353/353 [==============================] - 0s 956us/step - loss: 0.0082\n",
            "Epoch 551/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0082\n",
            "Epoch 552/1000\n",
            "353/353 [==============================] - 0s 924us/step - loss: 0.0083\n",
            "Epoch 553/1000\n",
            "353/353 [==============================] - 0s 920us/step - loss: 0.0083\n",
            "Epoch 554/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0082\n",
            "Epoch 555/1000\n",
            "353/353 [==============================] - 0s 915us/step - loss: 0.0083\n",
            "Epoch 556/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0084\n",
            "Epoch 557/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0083\n",
            "Epoch 558/1000\n",
            "353/353 [==============================] - 0s 951us/step - loss: 0.0083\n",
            "Epoch 559/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0083\n",
            "Epoch 560/1000\n",
            "353/353 [==============================] - 0s 939us/step - loss: 0.0083\n",
            "Epoch 561/1000\n",
            "353/353 [==============================] - 0s 959us/step - loss: 0.0083\n",
            "Epoch 562/1000\n",
            "353/353 [==============================] - 0s 976us/step - loss: 0.0084\n",
            "Epoch 563/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0083\n",
            "Epoch 564/1000\n",
            "353/353 [==============================] - 0s 971us/step - loss: 0.0084\n",
            "Epoch 565/1000\n",
            "353/353 [==============================] - 0s 938us/step - loss: 0.0082\n",
            "Epoch 566/1000\n",
            "353/353 [==============================] - 0s 948us/step - loss: 0.0083\n",
            "Epoch 567/1000\n",
            "353/353 [==============================] - 0s 957us/step - loss: 0.0083\n",
            "Epoch 568/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0083\n",
            "Epoch 569/1000\n",
            "353/353 [==============================] - 0s 896us/step - loss: 0.0082\n",
            "Epoch 570/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0083\n",
            "Epoch 571/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0082\n",
            "Epoch 572/1000\n",
            "353/353 [==============================] - 0s 909us/step - loss: 0.0082\n",
            "Epoch 573/1000\n",
            "353/353 [==============================] - 0s 949us/step - loss: 0.0085\n",
            "Epoch 574/1000\n",
            "353/353 [==============================] - 0s 953us/step - loss: 0.0082\n",
            "Epoch 575/1000\n",
            "353/353 [==============================] - 0s 924us/step - loss: 0.0083\n",
            "Epoch 576/1000\n",
            "353/353 [==============================] - 0s 913us/step - loss: 0.0084\n",
            "Epoch 577/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0083\n",
            "Epoch 578/1000\n",
            "353/353 [==============================] - 0s 939us/step - loss: 0.0084\n",
            "Epoch 579/1000\n",
            "353/353 [==============================] - 0s 946us/step - loss: 0.0084\n",
            "Epoch 580/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0082\n",
            "Epoch 581/1000\n",
            "353/353 [==============================] - 0s 896us/step - loss: 0.0083\n",
            "Epoch 582/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0083\n",
            "Epoch 583/1000\n",
            "353/353 [==============================] - 0s 969us/step - loss: 0.0083\n",
            "Epoch 584/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0082\n",
            "Epoch 585/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0083\n",
            "Epoch 586/1000\n",
            "353/353 [==============================] - 0s 962us/step - loss: 0.0083\n",
            "Epoch 587/1000\n",
            "353/353 [==============================] - 0s 924us/step - loss: 0.0083\n",
            "Epoch 588/1000\n",
            "353/353 [==============================] - 0s 963us/step - loss: 0.0083\n",
            "Epoch 589/1000\n",
            "353/353 [==============================] - 0s 973us/step - loss: 0.0084\n",
            "Epoch 590/1000\n",
            "353/353 [==============================] - 0s 968us/step - loss: 0.0082\n",
            "Epoch 591/1000\n",
            "353/353 [==============================] - 0s 956us/step - loss: 0.0084\n",
            "Epoch 592/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0084\n",
            "Epoch 593/1000\n",
            "353/353 [==============================] - 0s 917us/step - loss: 0.0083\n",
            "Epoch 594/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0083\n",
            "Epoch 595/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0083\n",
            "Epoch 596/1000\n",
            "353/353 [==============================] - 0s 927us/step - loss: 0.0083\n",
            "Epoch 597/1000\n",
            "353/353 [==============================] - 0s 954us/step - loss: 0.0082\n",
            "Epoch 598/1000\n",
            "353/353 [==============================] - 0s 964us/step - loss: 0.0084\n",
            "Epoch 599/1000\n",
            "353/353 [==============================] - 0s 984us/step - loss: 0.0082\n",
            "Epoch 600/1000\n",
            "353/353 [==============================] - 0s 953us/step - loss: 0.0083\n",
            "Epoch 601/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0083\n",
            "Epoch 602/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0083\n",
            "Epoch 603/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0083\n",
            "Epoch 604/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0083\n",
            "Epoch 605/1000\n",
            "353/353 [==============================] - 0s 960us/step - loss: 0.0083\n",
            "Epoch 606/1000\n",
            "353/353 [==============================] - 0s 950us/step - loss: 0.0082\n",
            "Epoch 607/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0083\n",
            "Epoch 608/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0083\n",
            "Epoch 609/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0083\n",
            "Epoch 610/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0083\n",
            "Epoch 611/1000\n",
            "353/353 [==============================] - 0s 921us/step - loss: 0.0083\n",
            "Epoch 612/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0082\n",
            "Epoch 613/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0084\n",
            "Epoch 614/1000\n",
            "353/353 [==============================] - 0s 953us/step - loss: 0.0082\n",
            "Epoch 615/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0082\n",
            "Epoch 616/1000\n",
            "353/353 [==============================] - 0s 972us/step - loss: 0.0083\n",
            "Epoch 617/1000\n",
            "353/353 [==============================] - 0s 946us/step - loss: 0.0083\n",
            "Epoch 618/1000\n",
            "353/353 [==============================] - 0s 943us/step - loss: 0.0082\n",
            "Epoch 619/1000\n",
            "353/353 [==============================] - 0s 943us/step - loss: 0.0082\n",
            "Epoch 620/1000\n",
            "353/353 [==============================] - 0s 916us/step - loss: 0.0082\n",
            "Epoch 621/1000\n",
            "353/353 [==============================] - 0s 903us/step - loss: 0.0083\n",
            "Epoch 622/1000\n",
            "353/353 [==============================] - 0s 916us/step - loss: 0.0083\n",
            "Epoch 623/1000\n",
            "353/353 [==============================] - 0s 948us/step - loss: 0.0082\n",
            "Epoch 624/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0083\n",
            "Epoch 625/1000\n",
            "353/353 [==============================] - 0s 971us/step - loss: 0.0083\n",
            "Epoch 626/1000\n",
            "353/353 [==============================] - 0s 938us/step - loss: 0.0083\n",
            "Epoch 627/1000\n",
            "353/353 [==============================] - 0s 961us/step - loss: 0.0082\n",
            "Epoch 628/1000\n",
            "353/353 [==============================] - 0s 958us/step - loss: 0.0082\n",
            "Epoch 629/1000\n",
            "353/353 [==============================] - 0s 939us/step - loss: 0.0082\n",
            "Epoch 630/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0084\n",
            "Epoch 631/1000\n",
            "353/353 [==============================] - 0s 957us/step - loss: 0.0083\n",
            "Epoch 632/1000\n",
            "353/353 [==============================] - 0s 950us/step - loss: 0.0083\n",
            "Epoch 633/1000\n",
            "353/353 [==============================] - 0s 968us/step - loss: 0.0083\n",
            "Epoch 634/1000\n",
            "353/353 [==============================] - 0s 972us/step - loss: 0.0082\n",
            "Epoch 635/1000\n",
            "353/353 [==============================] - 0s 960us/step - loss: 0.0082\n",
            "Epoch 636/1000\n",
            "353/353 [==============================] - 0s 963us/step - loss: 0.0082\n",
            "Epoch 637/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0084\n",
            "Epoch 638/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0082\n",
            "Epoch 639/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0082\n",
            "Epoch 640/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0083\n",
            "Epoch 641/1000\n",
            "353/353 [==============================] - 0s 964us/step - loss: 0.0082\n",
            "Epoch 642/1000\n",
            "353/353 [==============================] - 0s 954us/step - loss: 0.0082\n",
            "Epoch 643/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0083\n",
            "Epoch 644/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0081\n",
            "Epoch 645/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0084\n",
            "Epoch 646/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0084\n",
            "Epoch 647/1000\n",
            "353/353 [==============================] - 0s 943us/step - loss: 0.0082\n",
            "Epoch 648/1000\n",
            "353/353 [==============================] - 0s 950us/step - loss: 0.0082\n",
            "Epoch 649/1000\n",
            "353/353 [==============================] - 0s 981us/step - loss: 0.0083\n",
            "Epoch 650/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0082\n",
            "Epoch 651/1000\n",
            "353/353 [==============================] - 0s 957us/step - loss: 0.0082\n",
            "Epoch 652/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0082\n",
            "Epoch 653/1000\n",
            "353/353 [==============================] - 0s 958us/step - loss: 0.0082\n",
            "Epoch 654/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0081\n",
            "Epoch 655/1000\n",
            "353/353 [==============================] - 0s 915us/step - loss: 0.0082\n",
            "Epoch 656/1000\n",
            "353/353 [==============================] - 0s 924us/step - loss: 0.0082\n",
            "Epoch 657/1000\n",
            "353/353 [==============================] - 0s 968us/step - loss: 0.0082\n",
            "Epoch 658/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0083\n",
            "Epoch 659/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0083\n",
            "Epoch 660/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0082\n",
            "Epoch 661/1000\n",
            "353/353 [==============================] - 0s 938us/step - loss: 0.0083\n",
            "Epoch 662/1000\n",
            "353/353 [==============================] - 0s 956us/step - loss: 0.0083\n",
            "Epoch 663/1000\n",
            "353/353 [==============================] - 0s 948us/step - loss: 0.0082\n",
            "Epoch 664/1000\n",
            "353/353 [==============================] - 0s 943us/step - loss: 0.0082\n",
            "Epoch 665/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0082\n",
            "Epoch 666/1000\n",
            "353/353 [==============================] - 0s 947us/step - loss: 0.0083\n",
            "Epoch 667/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0081\n",
            "Epoch 668/1000\n",
            "353/353 [==============================] - 0s 968us/step - loss: 0.0082\n",
            "Epoch 669/1000\n",
            "353/353 [==============================] - 0s 961us/step - loss: 0.0082\n",
            "Epoch 670/1000\n",
            "353/353 [==============================] - 0s 938us/step - loss: 0.0081\n",
            "Epoch 671/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0082\n",
            "Epoch 672/1000\n",
            "353/353 [==============================] - 0s 906us/step - loss: 0.0082\n",
            "Epoch 673/1000\n",
            "353/353 [==============================] - 0s 905us/step - loss: 0.0083\n",
            "Epoch 674/1000\n",
            "353/353 [==============================] - 0s 920us/step - loss: 0.0083\n",
            "Epoch 675/1000\n",
            "353/353 [==============================] - 0s 915us/step - loss: 0.0082\n",
            "Epoch 676/1000\n",
            "353/353 [==============================] - 0s 924us/step - loss: 0.0081\n",
            "Epoch 677/1000\n",
            "353/353 [==============================] - 0s 901us/step - loss: 0.0082\n",
            "Epoch 678/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0082\n",
            "Epoch 679/1000\n",
            "353/353 [==============================] - 0s 973us/step - loss: 0.0082\n",
            "Epoch 680/1000\n",
            "353/353 [==============================] - 0s 951us/step - loss: 0.0082\n",
            "Epoch 681/1000\n",
            "353/353 [==============================] - 0s 939us/step - loss: 0.0082\n",
            "Epoch 682/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0083\n",
            "Epoch 683/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0083\n",
            "Epoch 684/1000\n",
            "353/353 [==============================] - 0s 957us/step - loss: 0.0082\n",
            "Epoch 685/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0084\n",
            "Epoch 686/1000\n",
            "353/353 [==============================] - 0s 950us/step - loss: 0.0082\n",
            "Epoch 687/1000\n",
            "353/353 [==============================] - 0s 968us/step - loss: 0.0083\n",
            "Epoch 688/1000\n",
            "353/353 [==============================] - 0s 914us/step - loss: 0.0082\n",
            "Epoch 689/1000\n",
            "353/353 [==============================] - 0s 914us/step - loss: 0.0081\n",
            "Epoch 690/1000\n",
            "353/353 [==============================] - 0s 935us/step - loss: 0.0082\n",
            "Epoch 691/1000\n",
            "353/353 [==============================] - 0s 938us/step - loss: 0.0082\n",
            "Epoch 692/1000\n",
            "353/353 [==============================] - 0s 903us/step - loss: 0.0081\n",
            "Epoch 693/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0082\n",
            "Epoch 694/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0082\n",
            "Epoch 695/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0082\n",
            "Epoch 696/1000\n",
            "353/353 [==============================] - 0s 943us/step - loss: 0.0082\n",
            "Epoch 697/1000\n",
            "353/353 [==============================] - 0s 990us/step - loss: 0.0082\n",
            "Epoch 698/1000\n",
            "353/353 [==============================] - 0s 947us/step - loss: 0.0082\n",
            "Epoch 699/1000\n",
            "353/353 [==============================] - 0s 960us/step - loss: 0.0081\n",
            "Epoch 700/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0082\n",
            "Epoch 701/1000\n",
            "353/353 [==============================] - 0s 948us/step - loss: 0.0081\n",
            "Epoch 702/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0080\n",
            "Epoch 703/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0081\n",
            "Epoch 704/1000\n",
            "353/353 [==============================] - 0s 960us/step - loss: 0.0084\n",
            "Epoch 705/1000\n",
            "353/353 [==============================] - 0s 938us/step - loss: 0.0082\n",
            "Epoch 706/1000\n",
            "353/353 [==============================] - 0s 935us/step - loss: 0.0084\n",
            "Epoch 707/1000\n",
            "353/353 [==============================] - 0s 918us/step - loss: 0.0083\n",
            "Epoch 708/1000\n",
            "353/353 [==============================] - 0s 919us/step - loss: 0.0081\n",
            "Epoch 709/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0081\n",
            "Epoch 710/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0082\n",
            "Epoch 711/1000\n",
            "353/353 [==============================] - 0s 924us/step - loss: 0.0085\n",
            "Epoch 712/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0084\n",
            "Epoch 713/1000\n",
            "353/353 [==============================] - 0s 920us/step - loss: 0.0082\n",
            "Epoch 714/1000\n",
            "353/353 [==============================] - 0s 920us/step - loss: 0.0082\n",
            "Epoch 715/1000\n",
            "353/353 [==============================] - 0s 948us/step - loss: 0.0082\n",
            "Epoch 716/1000\n",
            "353/353 [==============================] - 0s 918us/step - loss: 0.0083\n",
            "Epoch 717/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0083\n",
            "Epoch 718/1000\n",
            "353/353 [==============================] - 0s 920us/step - loss: 0.0083\n",
            "Epoch 719/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0083\n",
            "Epoch 720/1000\n",
            "353/353 [==============================] - 0s 920us/step - loss: 0.0082\n",
            "Epoch 721/1000\n",
            "353/353 [==============================] - 0s 924us/step - loss: 0.0081\n",
            "Epoch 722/1000\n",
            "353/353 [==============================] - 0s 947us/step - loss: 0.0082\n",
            "Epoch 723/1000\n",
            "353/353 [==============================] - 0s 954us/step - loss: 0.0083\n",
            "Epoch 724/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0081\n",
            "Epoch 725/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0082\n",
            "Epoch 726/1000\n",
            "353/353 [==============================] - 0s 963us/step - loss: 0.0081\n",
            "Epoch 727/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0083\n",
            "Epoch 728/1000\n",
            "353/353 [==============================] - 0s 946us/step - loss: 0.0082\n",
            "Epoch 729/1000\n",
            "353/353 [==============================] - 0s 965us/step - loss: 0.0082\n",
            "Epoch 730/1000\n",
            "353/353 [==============================] - 0s 964us/step - loss: 0.0081\n",
            "Epoch 731/1000\n",
            "353/353 [==============================] - 0s 950us/step - loss: 0.0082\n",
            "Epoch 732/1000\n",
            "353/353 [==============================] - 0s 959us/step - loss: 0.0081\n",
            "Epoch 733/1000\n",
            "353/353 [==============================] - 0s 954us/step - loss: 0.0081\n",
            "Epoch 734/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0082\n",
            "Epoch 735/1000\n",
            "353/353 [==============================] - 0s 975us/step - loss: 0.0081\n",
            "Epoch 736/1000\n",
            "353/353 [==============================] - 0s 956us/step - loss: 0.0081\n",
            "Epoch 737/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0082\n",
            "Epoch 738/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0081\n",
            "Epoch 739/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0081\n",
            "Epoch 740/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0083\n",
            "Epoch 741/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0081\n",
            "Epoch 742/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0082\n",
            "Epoch 743/1000\n",
            "353/353 [==============================] - 0s 950us/step - loss: 0.0082\n",
            "Epoch 744/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0081\n",
            "Epoch 745/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0081\n",
            "Epoch 746/1000\n",
            "353/353 [==============================] - 0s 927us/step - loss: 0.0082\n",
            "Epoch 747/1000\n",
            "353/353 [==============================] - 0s 956us/step - loss: 0.0082\n",
            "Epoch 748/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0082\n",
            "Epoch 749/1000\n",
            "353/353 [==============================] - 0s 966us/step - loss: 0.0081\n",
            "Epoch 750/1000\n",
            "353/353 [==============================] - 0s 957us/step - loss: 0.0081\n",
            "Epoch 751/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0081\n",
            "Epoch 752/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0081\n",
            "Epoch 753/1000\n",
            "353/353 [==============================] - 0s 977us/step - loss: 0.0081\n",
            "Epoch 754/1000\n",
            "353/353 [==============================] - 0s 946us/step - loss: 0.0081\n",
            "Epoch 755/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0082\n",
            "Epoch 756/1000\n",
            "353/353 [==============================] - 0s 956us/step - loss: 0.0082\n",
            "Epoch 757/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0081\n",
            "Epoch 758/1000\n",
            "353/353 [==============================] - 0s 935us/step - loss: 0.0081\n",
            "Epoch 759/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0081\n",
            "Epoch 760/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0082\n",
            "Epoch 761/1000\n",
            "353/353 [==============================] - 0s 954us/step - loss: 0.0082\n",
            "Epoch 762/1000\n",
            "353/353 [==============================] - 0s 950us/step - loss: 0.0081\n",
            "Epoch 763/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0081\n",
            "Epoch 764/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0081\n",
            "Epoch 765/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0081\n",
            "Epoch 766/1000\n",
            "353/353 [==============================] - 0s 919us/step - loss: 0.0081\n",
            "Epoch 767/1000\n",
            "353/353 [==============================] - 0s 939us/step - loss: 0.0083\n",
            "Epoch 768/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0080\n",
            "Epoch 769/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0081\n",
            "Epoch 770/1000\n",
            "353/353 [==============================] - 0s 964us/step - loss: 0.0081\n",
            "Epoch 771/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0081\n",
            "Epoch 772/1000\n",
            "353/353 [==============================] - 0s 919us/step - loss: 0.0081\n",
            "Epoch 773/1000\n",
            "353/353 [==============================] - 0s 899us/step - loss: 0.0081\n",
            "Epoch 774/1000\n",
            "353/353 [==============================] - 0s 912us/step - loss: 0.0082\n",
            "Epoch 775/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0081\n",
            "Epoch 776/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0081\n",
            "Epoch 777/1000\n",
            "353/353 [==============================] - 0s 927us/step - loss: 0.0082\n",
            "Epoch 778/1000\n",
            "353/353 [==============================] - 0s 960us/step - loss: 0.0081\n",
            "Epoch 779/1000\n",
            "353/353 [==============================] - 0s 916us/step - loss: 0.0081\n",
            "Epoch 780/1000\n",
            "353/353 [==============================] - 0s 908us/step - loss: 0.0082\n",
            "Epoch 781/1000\n",
            "353/353 [==============================] - 0s 907us/step - loss: 0.0081\n",
            "Epoch 782/1000\n",
            "353/353 [==============================] - 0s 911us/step - loss: 0.0083\n",
            "Epoch 783/1000\n",
            "353/353 [==============================] - 0s 892us/step - loss: 0.0081\n",
            "Epoch 784/1000\n",
            "353/353 [==============================] - 0s 947us/step - loss: 0.0081\n",
            "Epoch 785/1000\n",
            "353/353 [==============================] - 0s 959us/step - loss: 0.0082\n",
            "Epoch 786/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0081\n",
            "Epoch 787/1000\n",
            "353/353 [==============================] - 0s 962us/step - loss: 0.0082\n",
            "Epoch 788/1000\n",
            "353/353 [==============================] - 0s 947us/step - loss: 0.0080\n",
            "Epoch 789/1000\n",
            "353/353 [==============================] - 0s 903us/step - loss: 0.0081\n",
            "Epoch 790/1000\n",
            "353/353 [==============================] - 0s 943us/step - loss: 0.0081\n",
            "Epoch 791/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0082\n",
            "Epoch 792/1000\n",
            "353/353 [==============================] - 0s 901us/step - loss: 0.0080\n",
            "Epoch 793/1000\n",
            "353/353 [==============================] - 0s 908us/step - loss: 0.0082\n",
            "Epoch 794/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0081\n",
            "Epoch 795/1000\n",
            "353/353 [==============================] - 0s 888us/step - loss: 0.0081\n",
            "Epoch 796/1000\n",
            "353/353 [==============================] - 0s 946us/step - loss: 0.0081\n",
            "Epoch 797/1000\n",
            "353/353 [==============================] - 0s 971us/step - loss: 0.0081\n",
            "Epoch 798/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0080\n",
            "Epoch 799/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0081\n",
            "Epoch 800/1000\n",
            "353/353 [==============================] - 0s 964us/step - loss: 0.0080\n",
            "Epoch 801/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0082\n",
            "Epoch 802/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0081\n",
            "Epoch 803/1000\n",
            "353/353 [==============================] - 0s 953us/step - loss: 0.0081\n",
            "Epoch 804/1000\n",
            "353/353 [==============================] - 0s 961us/step - loss: 0.0080\n",
            "Epoch 805/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "Epoch 806/1000\n",
            "353/353 [==============================] - 0s 981us/step - loss: 0.0082\n",
            "Epoch 807/1000\n",
            "353/353 [==============================] - 0s 986us/step - loss: 0.0081\n",
            "Epoch 808/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "Epoch 809/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "Epoch 810/1000\n",
            "353/353 [==============================] - 0s 987us/step - loss: 0.0082\n",
            "Epoch 811/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "Epoch 812/1000\n",
            "353/353 [==============================] - 0s 984us/step - loss: 0.0082\n",
            "Epoch 813/1000\n",
            "353/353 [==============================] - 0s 984us/step - loss: 0.0081\n",
            "Epoch 814/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0080\n",
            "Epoch 815/1000\n",
            "353/353 [==============================] - 0s 981us/step - loss: 0.0080\n",
            "Epoch 816/1000\n",
            "353/353 [==============================] - 0s 993us/step - loss: 0.0081\n",
            "Epoch 817/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "Epoch 818/1000\n",
            "353/353 [==============================] - 0s 982us/step - loss: 0.0082\n",
            "Epoch 819/1000\n",
            "353/353 [==============================] - 0s 960us/step - loss: 0.0082\n",
            "Epoch 820/1000\n",
            "353/353 [==============================] - 0s 967us/step - loss: 0.0080\n",
            "Epoch 821/1000\n",
            "353/353 [==============================] - 0s 959us/step - loss: 0.0081\n",
            "Epoch 822/1000\n",
            "353/353 [==============================] - 0s 979us/step - loss: 0.0081\n",
            "Epoch 823/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0081\n",
            "Epoch 824/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0081\n",
            "Epoch 825/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0082\n",
            "Epoch 826/1000\n",
            "353/353 [==============================] - 0s 954us/step - loss: 0.0080\n",
            "Epoch 827/1000\n",
            "353/353 [==============================] - 0s 918us/step - loss: 0.0082\n",
            "Epoch 828/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0081\n",
            "Epoch 829/1000\n",
            "353/353 [==============================] - 0s 910us/step - loss: 0.0081\n",
            "Epoch 830/1000\n",
            "353/353 [==============================] - 0s 893us/step - loss: 0.0082\n",
            "Epoch 831/1000\n",
            "353/353 [==============================] - 0s 921us/step - loss: 0.0082\n",
            "Epoch 832/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0080\n",
            "Epoch 833/1000\n",
            "353/353 [==============================] - 0s 895us/step - loss: 0.0080\n",
            "Epoch 834/1000\n",
            "353/353 [==============================] - 0s 926us/step - loss: 0.0081\n",
            "Epoch 835/1000\n",
            "353/353 [==============================] - 0s 989us/step - loss: 0.0080\n",
            "Epoch 836/1000\n",
            "353/353 [==============================] - 0s 971us/step - loss: 0.0080\n",
            "Epoch 837/1000\n",
            "353/353 [==============================] - 0s 979us/step - loss: 0.0081\n",
            "Epoch 838/1000\n",
            "353/353 [==============================] - 0s 967us/step - loss: 0.0081\n",
            "Epoch 839/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0081\n",
            "Epoch 840/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0083\n",
            "Epoch 841/1000\n",
            "353/353 [==============================] - 0s 964us/step - loss: 0.0080\n",
            "Epoch 842/1000\n",
            "353/353 [==============================] - 0s 962us/step - loss: 0.0081\n",
            "Epoch 843/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0081\n",
            "Epoch 844/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0081\n",
            "Epoch 845/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0081\n",
            "Epoch 846/1000\n",
            "353/353 [==============================] - 0s 963us/step - loss: 0.0081\n",
            "Epoch 847/1000\n",
            "353/353 [==============================] - 0s 997us/step - loss: 0.0080\n",
            "Epoch 848/1000\n",
            "353/353 [==============================] - 0s 971us/step - loss: 0.0081\n",
            "Epoch 849/1000\n",
            "353/353 [==============================] - 0s 904us/step - loss: 0.0081\n",
            "Epoch 850/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0080\n",
            "Epoch 851/1000\n",
            "353/353 [==============================] - 0s 909us/step - loss: 0.0079\n",
            "Epoch 852/1000\n",
            "353/353 [==============================] - 0s 899us/step - loss: 0.0080\n",
            "Epoch 853/1000\n",
            "353/353 [==============================] - 0s 901us/step - loss: 0.0081\n",
            "Epoch 854/1000\n",
            "353/353 [==============================] - 0s 917us/step - loss: 0.0081\n",
            "Epoch 855/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0081\n",
            "Epoch 856/1000\n",
            "353/353 [==============================] - 0s 949us/step - loss: 0.0081\n",
            "Epoch 857/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0082\n",
            "Epoch 858/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0080\n",
            "Epoch 859/1000\n",
            "353/353 [==============================] - 0s 949us/step - loss: 0.0082\n",
            "Epoch 860/1000\n",
            "353/353 [==============================] - 0s 917us/step - loss: 0.0080\n",
            "Epoch 861/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0080\n",
            "Epoch 862/1000\n",
            "353/353 [==============================] - 0s 963us/step - loss: 0.0081\n",
            "Epoch 863/1000\n",
            "353/353 [==============================] - 0s 951us/step - loss: 0.0080\n",
            "Epoch 864/1000\n",
            "353/353 [==============================] - 0s 995us/step - loss: 0.0082\n",
            "Epoch 865/1000\n",
            "353/353 [==============================] - 0s 985us/step - loss: 0.0081\n",
            "Epoch 866/1000\n",
            "353/353 [==============================] - 0s 974us/step - loss: 0.0082\n",
            "Epoch 867/1000\n",
            "353/353 [==============================] - 0s 981us/step - loss: 0.0080\n",
            "Epoch 868/1000\n",
            "353/353 [==============================] - 0s 948us/step - loss: 0.0079\n",
            "Epoch 869/1000\n",
            "353/353 [==============================] - 0s 924us/step - loss: 0.0080\n",
            "Epoch 870/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0080\n",
            "Epoch 871/1000\n",
            "353/353 [==============================] - 0s 947us/step - loss: 0.0081\n",
            "Epoch 872/1000\n",
            "353/353 [==============================] - 0s 920us/step - loss: 0.0080\n",
            "Epoch 873/1000\n",
            "353/353 [==============================] - 0s 954us/step - loss: 0.0080\n",
            "Epoch 874/1000\n",
            "353/353 [==============================] - 0s 939us/step - loss: 0.0081\n",
            "Epoch 875/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0082\n",
            "Epoch 876/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0081\n",
            "Epoch 877/1000\n",
            "353/353 [==============================] - 0s 918us/step - loss: 0.0080\n",
            "Epoch 878/1000\n",
            "353/353 [==============================] - 0s 935us/step - loss: 0.0080\n",
            "Epoch 879/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0080\n",
            "Epoch 880/1000\n",
            "353/353 [==============================] - 0s 901us/step - loss: 0.0080\n",
            "Epoch 881/1000\n",
            "353/353 [==============================] - 0s 911us/step - loss: 0.0080\n",
            "Epoch 882/1000\n",
            "353/353 [==============================] - 0s 919us/step - loss: 0.0082\n",
            "Epoch 883/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0081\n",
            "Epoch 884/1000\n",
            "353/353 [==============================] - 0s 943us/step - loss: 0.0081\n",
            "Epoch 885/1000\n",
            "353/353 [==============================] - 0s 950us/step - loss: 0.0080\n",
            "Epoch 886/1000\n",
            "353/353 [==============================] - 0s 966us/step - loss: 0.0080\n",
            "Epoch 887/1000\n",
            "353/353 [==============================] - 0s 920us/step - loss: 0.0080\n",
            "Epoch 888/1000\n",
            "353/353 [==============================] - 0s 961us/step - loss: 0.0081\n",
            "Epoch 889/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0080\n",
            "Epoch 890/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0081\n",
            "Epoch 891/1000\n",
            "353/353 [==============================] - 0s 943us/step - loss: 0.0081\n",
            "Epoch 892/1000\n",
            "353/353 [==============================] - 0s 949us/step - loss: 0.0081\n",
            "Epoch 893/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0080\n",
            "Epoch 894/1000\n",
            "353/353 [==============================] - 0s 920us/step - loss: 0.0080\n",
            "Epoch 895/1000\n",
            "353/353 [==============================] - 0s 969us/step - loss: 0.0081\n",
            "Epoch 896/1000\n",
            "353/353 [==============================] - 0s 975us/step - loss: 0.0081\n",
            "Epoch 897/1000\n",
            "353/353 [==============================] - 0s 980us/step - loss: 0.0080\n",
            "Epoch 898/1000\n",
            "353/353 [==============================] - 0s 990us/step - loss: 0.0080\n",
            "Epoch 899/1000\n",
            "353/353 [==============================] - 0s 1000us/step - loss: 0.0081\n",
            "Epoch 900/1000\n",
            "353/353 [==============================] - 0s 980us/step - loss: 0.0081\n",
            "Epoch 901/1000\n",
            "353/353 [==============================] - 0s 988us/step - loss: 0.0080\n",
            "Epoch 902/1000\n",
            "353/353 [==============================] - 0s 958us/step - loss: 0.0079\n",
            "Epoch 903/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0080\n",
            "Epoch 904/1000\n",
            "353/353 [==============================] - 0s 975us/step - loss: 0.0082\n",
            "Epoch 905/1000\n",
            "353/353 [==============================] - 0s 998us/step - loss: 0.0080\n",
            "Epoch 906/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0080\n",
            "Epoch 907/1000\n",
            "353/353 [==============================] - 0s 919us/step - loss: 0.0079\n",
            "Epoch 908/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0082\n",
            "Epoch 909/1000\n",
            "353/353 [==============================] - 0s 924us/step - loss: 0.0081\n",
            "Epoch 910/1000\n",
            "353/353 [==============================] - 0s 908us/step - loss: 0.0081\n",
            "Epoch 911/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0081\n",
            "Epoch 912/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0080\n",
            "Epoch 913/1000\n",
            "353/353 [==============================] - 0s 957us/step - loss: 0.0081\n",
            "Epoch 914/1000\n",
            "353/353 [==============================] - 0s 913us/step - loss: 0.0080\n",
            "Epoch 915/1000\n",
            "353/353 [==============================] - 0s 927us/step - loss: 0.0080\n",
            "Epoch 916/1000\n",
            "353/353 [==============================] - 0s 958us/step - loss: 0.0080\n",
            "Epoch 917/1000\n",
            "353/353 [==============================] - 0s 980us/step - loss: 0.0079\n",
            "Epoch 918/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0080\n",
            "Epoch 919/1000\n",
            "353/353 [==============================] - 0s 963us/step - loss: 0.0081\n",
            "Epoch 920/1000\n",
            "353/353 [==============================] - 0s 965us/step - loss: 0.0080\n",
            "Epoch 921/1000\n",
            "353/353 [==============================] - 0s 905us/step - loss: 0.0081\n",
            "Epoch 922/1000\n",
            "353/353 [==============================] - 0s 904us/step - loss: 0.0081\n",
            "Epoch 923/1000\n",
            "353/353 [==============================] - 0s 901us/step - loss: 0.0079\n",
            "Epoch 924/1000\n",
            "353/353 [==============================] - 0s 953us/step - loss: 0.0081\n",
            "Epoch 925/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0079\n",
            "Epoch 926/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0081\n",
            "Epoch 927/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0080\n",
            "Epoch 928/1000\n",
            "353/353 [==============================] - 0s 946us/step - loss: 0.0080\n",
            "Epoch 929/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0081\n",
            "Epoch 930/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0080\n",
            "Epoch 931/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0081\n",
            "Epoch 932/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0080\n",
            "Epoch 933/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0079\n",
            "Epoch 934/1000\n",
            "353/353 [==============================] - 0s 919us/step - loss: 0.0079\n",
            "Epoch 935/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0080\n",
            "Epoch 936/1000\n",
            "353/353 [==============================] - 0s 915us/step - loss: 0.0080\n",
            "Epoch 937/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0080\n",
            "Epoch 938/1000\n",
            "353/353 [==============================] - 0s 911us/step - loss: 0.0078\n",
            "Epoch 939/1000\n",
            "353/353 [==============================] - 0s 921us/step - loss: 0.0082\n",
            "Epoch 940/1000\n",
            "353/353 [==============================] - 0s 921us/step - loss: 0.0080\n",
            "Epoch 941/1000\n",
            "353/353 [==============================] - 0s 893us/step - loss: 0.0081\n",
            "Epoch 942/1000\n",
            "353/353 [==============================] - 0s 914us/step - loss: 0.0080\n",
            "Epoch 943/1000\n",
            "353/353 [==============================] - 0s 920us/step - loss: 0.0080\n",
            "Epoch 944/1000\n",
            "353/353 [==============================] - 0s 929us/step - loss: 0.0080\n",
            "Epoch 945/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0079\n",
            "Epoch 946/1000\n",
            "353/353 [==============================] - 0s 959us/step - loss: 0.0081\n",
            "Epoch 947/1000\n",
            "353/353 [==============================] - 0s 937us/step - loss: 0.0080\n",
            "Epoch 948/1000\n",
            "353/353 [==============================] - 0s 954us/step - loss: 0.0080\n",
            "Epoch 949/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0079\n",
            "Epoch 950/1000\n",
            "353/353 [==============================] - 0s 924us/step - loss: 0.0080\n",
            "Epoch 951/1000\n",
            "353/353 [==============================] - 0s 919us/step - loss: 0.0080\n",
            "Epoch 952/1000\n",
            "353/353 [==============================] - 0s 983us/step - loss: 0.0080\n",
            "Epoch 953/1000\n",
            "353/353 [==============================] - 0s 960us/step - loss: 0.0080\n",
            "Epoch 954/1000\n",
            "353/353 [==============================] - 0s 954us/step - loss: 0.0081\n",
            "Epoch 955/1000\n",
            "353/353 [==============================] - 0s 938us/step - loss: 0.0080\n",
            "Epoch 956/1000\n",
            "353/353 [==============================] - 0s 974us/step - loss: 0.0080\n",
            "Epoch 957/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0079\n",
            "Epoch 958/1000\n",
            "353/353 [==============================] - 0s 951us/step - loss: 0.0080\n",
            "Epoch 959/1000\n",
            "353/353 [==============================] - 0s 924us/step - loss: 0.0081\n",
            "Epoch 960/1000\n",
            "353/353 [==============================] - 0s 933us/step - loss: 0.0080\n",
            "Epoch 961/1000\n",
            "353/353 [==============================] - 0s 917us/step - loss: 0.0079\n",
            "Epoch 962/1000\n",
            "353/353 [==============================] - 0s 949us/step - loss: 0.0080\n",
            "Epoch 963/1000\n",
            "353/353 [==============================] - 0s 925us/step - loss: 0.0080\n",
            "Epoch 964/1000\n",
            "353/353 [==============================] - 0s 940us/step - loss: 0.0081\n",
            "Epoch 965/1000\n",
            "353/353 [==============================] - 0s 923us/step - loss: 0.0080\n",
            "Epoch 966/1000\n",
            "353/353 [==============================] - 0s 950us/step - loss: 0.0079\n",
            "Epoch 967/1000\n",
            "353/353 [==============================] - 0s 943us/step - loss: 0.0081\n",
            "Epoch 968/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0079\n",
            "Epoch 969/1000\n",
            "353/353 [==============================] - 0s 939us/step - loss: 0.0081\n",
            "Epoch 970/1000\n",
            "353/353 [==============================] - 0s 948us/step - loss: 0.0080\n",
            "Epoch 971/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0081\n",
            "Epoch 972/1000\n",
            "353/353 [==============================] - 0s 930us/step - loss: 0.0080\n",
            "Epoch 973/1000\n",
            "353/353 [==============================] - 0s 927us/step - loss: 0.0080\n",
            "Epoch 974/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0079\n",
            "Epoch 975/1000\n",
            "353/353 [==============================] - 0s 991us/step - loss: 0.0081\n",
            "Epoch 976/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0079\n",
            "Epoch 977/1000\n",
            "353/353 [==============================] - 0s 913us/step - loss: 0.0081\n",
            "Epoch 978/1000\n",
            "353/353 [==============================] - 0s 917us/step - loss: 0.0081\n",
            "Epoch 979/1000\n",
            "353/353 [==============================] - 0s 935us/step - loss: 0.0080\n",
            "Epoch 980/1000\n",
            "353/353 [==============================] - 0s 915us/step - loss: 0.0079\n",
            "Epoch 981/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0080\n",
            "Epoch 982/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0079\n",
            "Epoch 983/1000\n",
            "353/353 [==============================] - 0s 924us/step - loss: 0.0080\n",
            "Epoch 984/1000\n",
            "353/353 [==============================] - 0s 950us/step - loss: 0.0079\n",
            "Epoch 985/1000\n",
            "353/353 [==============================] - 0s 976us/step - loss: 0.0080\n",
            "Epoch 986/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0081\n",
            "Epoch 987/1000\n",
            "353/353 [==============================] - 0s 954us/step - loss: 0.0079\n",
            "Epoch 988/1000\n",
            "353/353 [==============================] - 0s 957us/step - loss: 0.0080\n",
            "Epoch 989/1000\n",
            "353/353 [==============================] - 0s 927us/step - loss: 0.0080\n",
            "Epoch 990/1000\n",
            "353/353 [==============================] - 0s 912us/step - loss: 0.0080\n",
            "Epoch 991/1000\n",
            "353/353 [==============================] - 0s 916us/step - loss: 0.0080\n",
            "Epoch 992/1000\n",
            "353/353 [==============================] - 0s 936us/step - loss: 0.0080\n",
            "Epoch 993/1000\n",
            "353/353 [==============================] - 0s 957us/step - loss: 0.0080\n",
            "Epoch 994/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0080\n",
            "Epoch 995/1000\n",
            "353/353 [==============================] - 0s 935us/step - loss: 0.0081\n",
            "Epoch 996/1000\n",
            "353/353 [==============================] - 0s 911us/step - loss: 0.0081\n",
            "Epoch 997/1000\n",
            "353/353 [==============================] - 0s 947us/step - loss: 0.0080\n",
            "Epoch 998/1000\n",
            "353/353 [==============================] - 0s 964us/step - loss: 0.0079\n",
            "Epoch 999/1000\n",
            "353/353 [==============================] - 0s 965us/step - loss: 0.0080\n",
            "Epoch 1000/1000\n",
            "353/353 [==============================] - 0s 931us/step - loss: 0.0079\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping \n",
        "early_stopping = EarlyStopping(monitor = 'loss', min_delta = 0, patience = 100, mode = 'auto')\n",
        "\n",
        "history1 = reg_model1.fit(X1_train_scaled, y1_train_scaled, epochs=1000, callbacks = [early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9efdd6d",
      "metadata": {
        "id": "e9efdd6d",
        "outputId": "72329a24-2bde-408d-f5f4-ac3acc0efaee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "89/89 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "y1= reg_model1.predict(X1_test_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cf94e56",
      "metadata": {
        "id": "2cf94e56"
      },
      "source": [
        "- 예측한 y1 데이터를 X2에 추가를 해보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c9abf2c",
      "metadata": {
        "id": "6c9abf2c",
        "outputId": "1bf4ea3b-7488-45b7-a94f-efb5db7fb8a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "353/353 [==============================] - 0s 831us/step\n"
          ]
        }
      ],
      "source": [
        "y1_train = reg_model1.predict(X1_train_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d63b3ff",
      "metadata": {
        "id": "3d63b3ff"
      },
      "outputs": [],
      "source": [
        "y1_train_df = pd.DataFrame()\n",
        "y1_train_df = pd.DataFrame(data = y1_train, columns = ['y1_1','y1_2','y1_3','y1_4','y1_5','y1_6','y1_7','y1_8','y1_9','y1_10','y1_11','y1_12','y1_13','y1_14','y1_15'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aeac91b",
      "metadata": {
        "id": "0aeac91b"
      },
      "outputs": [],
      "source": [
        "y1_train_df.index = X1_train_scaled_df.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbae2405",
      "metadata": {
        "id": "fbae2405"
      },
      "outputs": [],
      "source": [
        "X2_train_scaled_df_new = pd.concat([X2_train_scaled_df, y1_train_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4651077f",
      "metadata": {
        "id": "4651077f",
        "outputId": "73e1ed6c-16cd-42c4-b499-a35de7e47fbd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Machine4.Pressure.C.Actual</th>\n",
              "      <th>Machine4.Temperature4.C.Actual</th>\n",
              "      <th>Machine4.ExitTemperature.U.Actual</th>\n",
              "      <th>Machine5.Temperature2.C.Actual</th>\n",
              "      <th>Machine5.Temperature3.C.Actual</th>\n",
              "      <th>Machine5.Temperature4.C.Actual</th>\n",
              "      <th>Machine5.Temperature6.C.Actual</th>\n",
              "      <th>Machine5.ExitTemperature.U.Actual</th>\n",
              "      <th>y1_1</th>\n",
              "      <th>y1_2</th>\n",
              "      <th>y1_3</th>\n",
              "      <th>y1_4</th>\n",
              "      <th>y1_5</th>\n",
              "      <th>y1_6</th>\n",
              "      <th>y1_7</th>\n",
              "      <th>y1_8</th>\n",
              "      <th>y1_9</th>\n",
              "      <th>y1_10</th>\n",
              "      <th>y1_11</th>\n",
              "      <th>y1_12</th>\n",
              "      <th>y1_13</th>\n",
              "      <th>y1_14</th>\n",
              "      <th>y1_15</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-03-06 10:52:34</th>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.038664</td>\n",
              "      <td>0.605044</td>\n",
              "      <td>0.556236</td>\n",
              "      <td>0.636248</td>\n",
              "      <td>0.807720</td>\n",
              "      <td>0.899325</td>\n",
              "      <td>0.100458</td>\n",
              "      <td>0.603486</td>\n",
              "      <td>0.607030</td>\n",
              "      <td>0.900405</td>\n",
              "      <td>0.884486</td>\n",
              "      <td>0.592520</td>\n",
              "      <td>0.686200</td>\n",
              "      <td>0.316883</td>\n",
              "      <td>0.531578</td>\n",
              "      <td>0.781817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 10:52:35</th>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.032513</td>\n",
              "      <td>0.608544</td>\n",
              "      <td>0.650340</td>\n",
              "      <td>0.638175</td>\n",
              "      <td>0.828777</td>\n",
              "      <td>0.900626</td>\n",
              "      <td>0.099670</td>\n",
              "      <td>0.621429</td>\n",
              "      <td>0.624192</td>\n",
              "      <td>0.928578</td>\n",
              "      <td>0.899012</td>\n",
              "      <td>0.623350</td>\n",
              "      <td>0.716205</td>\n",
              "      <td>0.274848</td>\n",
              "      <td>0.504295</td>\n",
              "      <td>0.789495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 10:52:36</th>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.036907</td>\n",
              "      <td>0.605044</td>\n",
              "      <td>0.556236</td>\n",
              "      <td>0.636248</td>\n",
              "      <td>0.807720</td>\n",
              "      <td>0.899325</td>\n",
              "      <td>0.100458</td>\n",
              "      <td>0.603486</td>\n",
              "      <td>0.607030</td>\n",
              "      <td>0.900405</td>\n",
              "      <td>0.884486</td>\n",
              "      <td>0.592520</td>\n",
              "      <td>0.686200</td>\n",
              "      <td>0.316883</td>\n",
              "      <td>0.531578</td>\n",
              "      <td>0.781817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 10:52:37</th>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.036028</td>\n",
              "      <td>0.611623</td>\n",
              "      <td>0.585229</td>\n",
              "      <td>0.640763</td>\n",
              "      <td>0.825834</td>\n",
              "      <td>0.908472</td>\n",
              "      <td>0.099809</td>\n",
              "      <td>0.610920</td>\n",
              "      <td>0.620119</td>\n",
              "      <td>0.922440</td>\n",
              "      <td>0.898072</td>\n",
              "      <td>0.608907</td>\n",
              "      <td>0.705683</td>\n",
              "      <td>0.315153</td>\n",
              "      <td>0.523632</td>\n",
              "      <td>0.787384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 10:52:39</th>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.037786</td>\n",
              "      <td>0.607093</td>\n",
              "      <td>0.594298</td>\n",
              "      <td>0.635562</td>\n",
              "      <td>0.818555</td>\n",
              "      <td>0.900662</td>\n",
              "      <td>0.099449</td>\n",
              "      <td>0.613201</td>\n",
              "      <td>0.611084</td>\n",
              "      <td>0.925057</td>\n",
              "      <td>0.900386</td>\n",
              "      <td>0.605069</td>\n",
              "      <td>0.691160</td>\n",
              "      <td>0.310195</td>\n",
              "      <td>0.525933</td>\n",
              "      <td>0.782554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 14:46:57</th>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.878453</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.968366</td>\n",
              "      <td>0.624452</td>\n",
              "      <td>0.152551</td>\n",
              "      <td>0.626267</td>\n",
              "      <td>0.810222</td>\n",
              "      <td>0.981243</td>\n",
              "      <td>0.100984</td>\n",
              "      <td>0.109610</td>\n",
              "      <td>0.145183</td>\n",
              "      <td>0.914137</td>\n",
              "      <td>0.923026</td>\n",
              "      <td>0.578962</td>\n",
              "      <td>-0.007520</td>\n",
              "      <td>0.363850</td>\n",
              "      <td>0.560339</td>\n",
              "      <td>0.237012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 14:47:09</th>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.883978</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.959578</td>\n",
              "      <td>0.622163</td>\n",
              "      <td>0.135497</td>\n",
              "      <td>0.623294</td>\n",
              "      <td>0.812070</td>\n",
              "      <td>0.980642</td>\n",
              "      <td>0.104151</td>\n",
              "      <td>0.146232</td>\n",
              "      <td>0.183880</td>\n",
              "      <td>0.939204</td>\n",
              "      <td>0.940840</td>\n",
              "      <td>0.575218</td>\n",
              "      <td>0.031060</td>\n",
              "      <td>0.377471</td>\n",
              "      <td>0.578175</td>\n",
              "      <td>0.311322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 14:47:14</th>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.889503</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.965729</td>\n",
              "      <td>0.617928</td>\n",
              "      <td>0.114489</td>\n",
              "      <td>0.617261</td>\n",
              "      <td>0.811297</td>\n",
              "      <td>0.965943</td>\n",
              "      <td>0.100304</td>\n",
              "      <td>0.170859</td>\n",
              "      <td>0.211557</td>\n",
              "      <td>0.957586</td>\n",
              "      <td>0.952263</td>\n",
              "      <td>0.570561</td>\n",
              "      <td>0.062910</td>\n",
              "      <td>0.383648</td>\n",
              "      <td>0.596105</td>\n",
              "      <td>0.359032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 14:47:15</th>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.883978</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.964851</td>\n",
              "      <td>0.611645</td>\n",
              "      <td>0.098705</td>\n",
              "      <td>0.619906</td>\n",
              "      <td>0.812523</td>\n",
              "      <td>0.917288</td>\n",
              "      <td>0.095979</td>\n",
              "      <td>0.172200</td>\n",
              "      <td>0.234255</td>\n",
              "      <td>0.970090</td>\n",
              "      <td>0.954176</td>\n",
              "      <td>0.574013</td>\n",
              "      <td>0.083448</td>\n",
              "      <td>0.382154</td>\n",
              "      <td>0.584855</td>\n",
              "      <td>0.329735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 14:47:19</th>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.883978</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.966608</td>\n",
              "      <td>0.611807</td>\n",
              "      <td>0.133681</td>\n",
              "      <td>0.631969</td>\n",
              "      <td>0.804068</td>\n",
              "      <td>0.872477</td>\n",
              "      <td>0.103463</td>\n",
              "      <td>0.142886</td>\n",
              "      <td>0.229153</td>\n",
              "      <td>0.941825</td>\n",
              "      <td>0.933615</td>\n",
              "      <td>0.581729</td>\n",
              "      <td>0.072278</td>\n",
              "      <td>0.371127</td>\n",
              "      <td>0.547437</td>\n",
              "      <td>0.260532</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2818 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Machine4.Pressure.C.Actual  \\\n",
              "Date                                              \n",
              "2019-03-06 10:52:34                    0.818182   \n",
              "2019-03-06 10:52:35                    0.727273   \n",
              "2019-03-06 10:52:36                    0.818182   \n",
              "2019-03-06 10:52:37                    0.909091   \n",
              "2019-03-06 10:52:39                    0.727273   \n",
              "...                                         ...   \n",
              "2019-03-06 14:46:57                    0.454545   \n",
              "2019-03-06 14:47:09                    0.363636   \n",
              "2019-03-06 14:47:14                    0.454545   \n",
              "2019-03-06 14:47:15                    0.363636   \n",
              "2019-03-06 14:47:19                    0.363636   \n",
              "\n",
              "                     Machine4.Temperature4.C.Actual  \\\n",
              "Date                                                  \n",
              "2019-03-06 10:52:34                        0.818182   \n",
              "2019-03-06 10:52:35                        0.727273   \n",
              "2019-03-06 10:52:36                        0.818182   \n",
              "2019-03-06 10:52:37                        0.909091   \n",
              "2019-03-06 10:52:39                        0.727273   \n",
              "...                                             ...   \n",
              "2019-03-06 14:46:57                        0.454545   \n",
              "2019-03-06 14:47:09                        0.363636   \n",
              "2019-03-06 14:47:14                        0.454545   \n",
              "2019-03-06 14:47:15                        0.363636   \n",
              "2019-03-06 14:47:19                        0.363636   \n",
              "\n",
              "                     Machine4.ExitTemperature.U.Actual  \\\n",
              "Date                                                     \n",
              "2019-03-06 10:52:34                           0.000000   \n",
              "2019-03-06 10:52:35                           0.000000   \n",
              "2019-03-06 10:52:36                           0.000000   \n",
              "2019-03-06 10:52:37                           0.000000   \n",
              "2019-03-06 10:52:39                           0.000000   \n",
              "...                                                ...   \n",
              "2019-03-06 14:46:57                           0.878453   \n",
              "2019-03-06 14:47:09                           0.883978   \n",
              "2019-03-06 14:47:14                           0.889503   \n",
              "2019-03-06 14:47:15                           0.883978   \n",
              "2019-03-06 14:47:19                           0.883978   \n",
              "\n",
              "                     Machine5.Temperature2.C.Actual  \\\n",
              "Date                                                  \n",
              "2019-03-06 10:52:34                        0.333333   \n",
              "2019-03-06 10:52:35                        0.333333   \n",
              "2019-03-06 10:52:36                        0.333333   \n",
              "2019-03-06 10:52:37                        0.333333   \n",
              "2019-03-06 10:52:39                        0.166667   \n",
              "...                                             ...   \n",
              "2019-03-06 14:46:57                        0.500000   \n",
              "2019-03-06 14:47:09                        0.500000   \n",
              "2019-03-06 14:47:14                        0.500000   \n",
              "2019-03-06 14:47:15                        0.333333   \n",
              "2019-03-06 14:47:19                        0.333333   \n",
              "\n",
              "                     Machine5.Temperature3.C.Actual  \\\n",
              "Date                                                  \n",
              "2019-03-06 10:52:34                        0.016129   \n",
              "2019-03-06 10:52:35                        0.016129   \n",
              "2019-03-06 10:52:36                        0.016129   \n",
              "2019-03-06 10:52:37                        0.016129   \n",
              "2019-03-06 10:52:39                        0.016129   \n",
              "...                                             ...   \n",
              "2019-03-06 14:46:57                        1.000000   \n",
              "2019-03-06 14:47:09                        1.000000   \n",
              "2019-03-06 14:47:14                        1.000000   \n",
              "2019-03-06 14:47:15                        1.000000   \n",
              "2019-03-06 14:47:19                        1.000000   \n",
              "\n",
              "                     Machine5.Temperature4.C.Actual  \\\n",
              "Date                                                  \n",
              "2019-03-06 10:52:34                        0.135135   \n",
              "2019-03-06 10:52:35                        0.135135   \n",
              "2019-03-06 10:52:36                        0.135135   \n",
              "2019-03-06 10:52:37                        0.135135   \n",
              "2019-03-06 10:52:39                        0.135135   \n",
              "...                                             ...   \n",
              "2019-03-06 14:46:57                        0.959459   \n",
              "2019-03-06 14:47:09                        0.959459   \n",
              "2019-03-06 14:47:14                        0.959459   \n",
              "2019-03-06 14:47:15                        0.959459   \n",
              "2019-03-06 14:47:19                        0.959459   \n",
              "\n",
              "                     Machine5.Temperature6.C.Actual  \\\n",
              "Date                                                  \n",
              "2019-03-06 10:52:34                        1.000000   \n",
              "2019-03-06 10:52:35                        1.000000   \n",
              "2019-03-06 10:52:36                        1.000000   \n",
              "2019-03-06 10:52:37                        1.000000   \n",
              "2019-03-06 10:52:39                        1.000000   \n",
              "...                                             ...   \n",
              "2019-03-06 14:46:57                        0.272727   \n",
              "2019-03-06 14:47:09                        0.272727   \n",
              "2019-03-06 14:47:14                        0.272727   \n",
              "2019-03-06 14:47:15                        0.272727   \n",
              "2019-03-06 14:47:19                        0.272727   \n",
              "\n",
              "                     Machine5.ExitTemperature.U.Actual      y1_1      y1_2  \\\n",
              "Date                                                                         \n",
              "2019-03-06 10:52:34                           0.038664  0.605044  0.556236   \n",
              "2019-03-06 10:52:35                           0.032513  0.608544  0.650340   \n",
              "2019-03-06 10:52:36                           0.036907  0.605044  0.556236   \n",
              "2019-03-06 10:52:37                           0.036028  0.611623  0.585229   \n",
              "2019-03-06 10:52:39                           0.037786  0.607093  0.594298   \n",
              "...                                                ...       ...       ...   \n",
              "2019-03-06 14:46:57                           0.968366  0.624452  0.152551   \n",
              "2019-03-06 14:47:09                           0.959578  0.622163  0.135497   \n",
              "2019-03-06 14:47:14                           0.965729  0.617928  0.114489   \n",
              "2019-03-06 14:47:15                           0.964851  0.611645  0.098705   \n",
              "2019-03-06 14:47:19                           0.966608  0.611807  0.133681   \n",
              "\n",
              "                         y1_3      y1_4      y1_5      y1_6      y1_7  \\\n",
              "Date                                                                    \n",
              "2019-03-06 10:52:34  0.636248  0.807720  0.899325  0.100458  0.603486   \n",
              "2019-03-06 10:52:35  0.638175  0.828777  0.900626  0.099670  0.621429   \n",
              "2019-03-06 10:52:36  0.636248  0.807720  0.899325  0.100458  0.603486   \n",
              "2019-03-06 10:52:37  0.640763  0.825834  0.908472  0.099809  0.610920   \n",
              "2019-03-06 10:52:39  0.635562  0.818555  0.900662  0.099449  0.613201   \n",
              "...                       ...       ...       ...       ...       ...   \n",
              "2019-03-06 14:46:57  0.626267  0.810222  0.981243  0.100984  0.109610   \n",
              "2019-03-06 14:47:09  0.623294  0.812070  0.980642  0.104151  0.146232   \n",
              "2019-03-06 14:47:14  0.617261  0.811297  0.965943  0.100304  0.170859   \n",
              "2019-03-06 14:47:15  0.619906  0.812523  0.917288  0.095979  0.172200   \n",
              "2019-03-06 14:47:19  0.631969  0.804068  0.872477  0.103463  0.142886   \n",
              "\n",
              "                         y1_8      y1_9     y1_10     y1_11     y1_12  \\\n",
              "Date                                                                    \n",
              "2019-03-06 10:52:34  0.607030  0.900405  0.884486  0.592520  0.686200   \n",
              "2019-03-06 10:52:35  0.624192  0.928578  0.899012  0.623350  0.716205   \n",
              "2019-03-06 10:52:36  0.607030  0.900405  0.884486  0.592520  0.686200   \n",
              "2019-03-06 10:52:37  0.620119  0.922440  0.898072  0.608907  0.705683   \n",
              "2019-03-06 10:52:39  0.611084  0.925057  0.900386  0.605069  0.691160   \n",
              "...                       ...       ...       ...       ...       ...   \n",
              "2019-03-06 14:46:57  0.145183  0.914137  0.923026  0.578962 -0.007520   \n",
              "2019-03-06 14:47:09  0.183880  0.939204  0.940840  0.575218  0.031060   \n",
              "2019-03-06 14:47:14  0.211557  0.957586  0.952263  0.570561  0.062910   \n",
              "2019-03-06 14:47:15  0.234255  0.970090  0.954176  0.574013  0.083448   \n",
              "2019-03-06 14:47:19  0.229153  0.941825  0.933615  0.581729  0.072278   \n",
              "\n",
              "                        y1_13     y1_14     y1_15  \n",
              "Date                                               \n",
              "2019-03-06 10:52:34  0.316883  0.531578  0.781817  \n",
              "2019-03-06 10:52:35  0.274848  0.504295  0.789495  \n",
              "2019-03-06 10:52:36  0.316883  0.531578  0.781817  \n",
              "2019-03-06 10:52:37  0.315153  0.523632  0.787384  \n",
              "2019-03-06 10:52:39  0.310195  0.525933  0.782554  \n",
              "...                       ...       ...       ...  \n",
              "2019-03-06 14:46:57  0.363850  0.560339  0.237012  \n",
              "2019-03-06 14:47:09  0.377471  0.578175  0.311322  \n",
              "2019-03-06 14:47:14  0.383648  0.596105  0.359032  \n",
              "2019-03-06 14:47:15  0.382154  0.584855  0.329735  \n",
              "2019-03-06 14:47:19  0.371127  0.547437  0.260532  \n",
              "\n",
              "[2818 rows x 23 columns]"
            ]
          },
          "execution_count": 369,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X2_test_scaled_df_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84217868",
      "metadata": {
        "id": "84217868",
        "outputId": "11d99d14-3361-4716-dd0c-4fd29cdd7999"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Machine4.Pressure.C.Actual</th>\n",
              "      <th>Machine4.Temperature4.C.Actual</th>\n",
              "      <th>Machine4.ExitTemperature.U.Actual</th>\n",
              "      <th>Machine5.Temperature2.C.Actual</th>\n",
              "      <th>Machine5.Temperature3.C.Actual</th>\n",
              "      <th>Machine5.Temperature4.C.Actual</th>\n",
              "      <th>Machine5.Temperature6.C.Actual</th>\n",
              "      <th>Machine5.ExitTemperature.U.Actual</th>\n",
              "      <th>y1_1</th>\n",
              "      <th>y1_2</th>\n",
              "      <th>y1_3</th>\n",
              "      <th>y1_4</th>\n",
              "      <th>y1_5</th>\n",
              "      <th>y1_6</th>\n",
              "      <th>y1_7</th>\n",
              "      <th>y1_8</th>\n",
              "      <th>y1_9</th>\n",
              "      <th>y1_10</th>\n",
              "      <th>y1_11</th>\n",
              "      <th>y1_12</th>\n",
              "      <th>y1_13</th>\n",
              "      <th>y1_14</th>\n",
              "      <th>y1_15</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-03-06 10:52:33</th>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.040422</td>\n",
              "      <td>0.579786</td>\n",
              "      <td>0.519164</td>\n",
              "      <td>0.615703</td>\n",
              "      <td>0.748030</td>\n",
              "      <td>0.861546</td>\n",
              "      <td>0.100708</td>\n",
              "      <td>0.583930</td>\n",
              "      <td>0.578993</td>\n",
              "      <td>0.833625</td>\n",
              "      <td>0.842966</td>\n",
              "      <td>0.558600</td>\n",
              "      <td>0.664400</td>\n",
              "      <td>0.326115</td>\n",
              "      <td>0.525660</td>\n",
              "      <td>0.752081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 10:52:38</th>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.032513</td>\n",
              "      <td>0.610799</td>\n",
              "      <td>0.592381</td>\n",
              "      <td>0.639640</td>\n",
              "      <td>0.826379</td>\n",
              "      <td>0.907209</td>\n",
              "      <td>0.099758</td>\n",
              "      <td>0.613201</td>\n",
              "      <td>0.626154</td>\n",
              "      <td>0.928254</td>\n",
              "      <td>0.901984</td>\n",
              "      <td>0.610876</td>\n",
              "      <td>0.712618</td>\n",
              "      <td>0.311979</td>\n",
              "      <td>0.522207</td>\n",
              "      <td>0.791797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 10:52:40</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.035149</td>\n",
              "      <td>0.567716</td>\n",
              "      <td>0.500276</td>\n",
              "      <td>0.605186</td>\n",
              "      <td>0.712187</td>\n",
              "      <td>0.842149</td>\n",
              "      <td>0.099669</td>\n",
              "      <td>0.579199</td>\n",
              "      <td>0.558780</td>\n",
              "      <td>0.791249</td>\n",
              "      <td>0.820224</td>\n",
              "      <td>0.541238</td>\n",
              "      <td>0.647242</td>\n",
              "      <td>0.339551</td>\n",
              "      <td>0.523474</td>\n",
              "      <td>0.729437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 10:52:42</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.005525</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.035149</td>\n",
              "      <td>0.610691</td>\n",
              "      <td>0.601784</td>\n",
              "      <td>0.639058</td>\n",
              "      <td>0.825555</td>\n",
              "      <td>0.907049</td>\n",
              "      <td>0.099546</td>\n",
              "      <td>0.610313</td>\n",
              "      <td>0.626647</td>\n",
              "      <td>0.922789</td>\n",
              "      <td>0.897832</td>\n",
              "      <td>0.617277</td>\n",
              "      <td>0.722980</td>\n",
              "      <td>0.318109</td>\n",
              "      <td>0.514408</td>\n",
              "      <td>0.787326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 10:52:43</th>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.011050</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.027241</td>\n",
              "      <td>0.609986</td>\n",
              "      <td>0.604039</td>\n",
              "      <td>0.638582</td>\n",
              "      <td>0.826910</td>\n",
              "      <td>0.905587</td>\n",
              "      <td>0.099660</td>\n",
              "      <td>0.614990</td>\n",
              "      <td>0.628586</td>\n",
              "      <td>0.931657</td>\n",
              "      <td>0.903816</td>\n",
              "      <td>0.613898</td>\n",
              "      <td>0.716935</td>\n",
              "      <td>0.307264</td>\n",
              "      <td>0.518758</td>\n",
              "      <td>0.792821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 14:47:13</th>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.889503</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.964851</td>\n",
              "      <td>0.619227</td>\n",
              "      <td>0.122349</td>\n",
              "      <td>0.619154</td>\n",
              "      <td>0.810432</td>\n",
              "      <td>0.972666</td>\n",
              "      <td>0.102759</td>\n",
              "      <td>0.164565</td>\n",
              "      <td>0.205074</td>\n",
              "      <td>0.951743</td>\n",
              "      <td>0.949354</td>\n",
              "      <td>0.571533</td>\n",
              "      <td>0.053674</td>\n",
              "      <td>0.382829</td>\n",
              "      <td>0.589888</td>\n",
              "      <td>0.346803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 14:47:16</th>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.883978</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.966608</td>\n",
              "      <td>0.611264</td>\n",
              "      <td>0.096224</td>\n",
              "      <td>0.623071</td>\n",
              "      <td>0.812152</td>\n",
              "      <td>0.901973</td>\n",
              "      <td>0.096423</td>\n",
              "      <td>0.167346</td>\n",
              "      <td>0.240007</td>\n",
              "      <td>0.970154</td>\n",
              "      <td>0.953425</td>\n",
              "      <td>0.578037</td>\n",
              "      <td>0.086974</td>\n",
              "      <td>0.382318</td>\n",
              "      <td>0.575443</td>\n",
              "      <td>0.311506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 14:47:17</th>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.883978</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.963972</td>\n",
              "      <td>0.612719</td>\n",
              "      <td>0.106224</td>\n",
              "      <td>0.627075</td>\n",
              "      <td>0.810944</td>\n",
              "      <td>0.903191</td>\n",
              "      <td>0.097770</td>\n",
              "      <td>0.154584</td>\n",
              "      <td>0.234818</td>\n",
              "      <td>0.961365</td>\n",
              "      <td>0.947995</td>\n",
              "      <td>0.581371</td>\n",
              "      <td>0.080270</td>\n",
              "      <td>0.379518</td>\n",
              "      <td>0.564630</td>\n",
              "      <td>0.279402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 14:47:18</th>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.883978</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.963972</td>\n",
              "      <td>0.613425</td>\n",
              "      <td>0.125136</td>\n",
              "      <td>0.627415</td>\n",
              "      <td>0.809070</td>\n",
              "      <td>0.907052</td>\n",
              "      <td>0.097384</td>\n",
              "      <td>0.149917</td>\n",
              "      <td>0.228323</td>\n",
              "      <td>0.952549</td>\n",
              "      <td>0.942824</td>\n",
              "      <td>0.580186</td>\n",
              "      <td>0.077989</td>\n",
              "      <td>0.375309</td>\n",
              "      <td>0.564461</td>\n",
              "      <td>0.270283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-03-06 14:47:20</th>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.889503</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.959459</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.964851</td>\n",
              "      <td>0.615225</td>\n",
              "      <td>0.128979</td>\n",
              "      <td>0.626122</td>\n",
              "      <td>0.807285</td>\n",
              "      <td>0.949252</td>\n",
              "      <td>0.105925</td>\n",
              "      <td>0.146275</td>\n",
              "      <td>0.204151</td>\n",
              "      <td>0.944222</td>\n",
              "      <td>0.940468</td>\n",
              "      <td>0.575513</td>\n",
              "      <td>0.047639</td>\n",
              "      <td>0.378834</td>\n",
              "      <td>0.566007</td>\n",
              "      <td>0.284348</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11270 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Machine4.Pressure.C.Actual  \\\n",
              "Date                                              \n",
              "2019-03-06 10:52:33                    0.636364   \n",
              "2019-03-06 10:52:38                    0.727273   \n",
              "2019-03-06 10:52:40                    1.000000   \n",
              "2019-03-06 10:52:42                    1.000000   \n",
              "2019-03-06 10:52:43                    0.909091   \n",
              "...                                         ...   \n",
              "2019-03-06 14:47:13                    0.363636   \n",
              "2019-03-06 14:47:16                    0.363636   \n",
              "2019-03-06 14:47:17                    0.454545   \n",
              "2019-03-06 14:47:18                    0.272727   \n",
              "2019-03-06 14:47:20                    0.454545   \n",
              "\n",
              "                     Machine4.Temperature4.C.Actual  \\\n",
              "Date                                                  \n",
              "2019-03-06 10:52:33                        0.636364   \n",
              "2019-03-06 10:52:38                        0.727273   \n",
              "2019-03-06 10:52:40                        1.000000   \n",
              "2019-03-06 10:52:42                        1.000000   \n",
              "2019-03-06 10:52:43                        0.909091   \n",
              "...                                             ...   \n",
              "2019-03-06 14:47:13                        0.363636   \n",
              "2019-03-06 14:47:16                        0.363636   \n",
              "2019-03-06 14:47:17                        0.454545   \n",
              "2019-03-06 14:47:18                        0.272727   \n",
              "2019-03-06 14:47:20                        0.454545   \n",
              "\n",
              "                     Machine4.ExitTemperature.U.Actual  \\\n",
              "Date                                                     \n",
              "2019-03-06 10:52:33                           0.000000   \n",
              "2019-03-06 10:52:38                           0.000000   \n",
              "2019-03-06 10:52:40                           0.000000   \n",
              "2019-03-06 10:52:42                           0.005525   \n",
              "2019-03-06 10:52:43                           0.011050   \n",
              "...                                                ...   \n",
              "2019-03-06 14:47:13                           0.889503   \n",
              "2019-03-06 14:47:16                           0.883978   \n",
              "2019-03-06 14:47:17                           0.883978   \n",
              "2019-03-06 14:47:18                           0.883978   \n",
              "2019-03-06 14:47:20                           0.889503   \n",
              "\n",
              "                     Machine5.Temperature2.C.Actual  \\\n",
              "Date                                                  \n",
              "2019-03-06 10:52:33                        0.333333   \n",
              "2019-03-06 10:52:38                        0.166667   \n",
              "2019-03-06 10:52:40                        0.166667   \n",
              "2019-03-06 10:52:42                        0.166667   \n",
              "2019-03-06 10:52:43                        0.166667   \n",
              "...                                             ...   \n",
              "2019-03-06 14:47:13                        0.500000   \n",
              "2019-03-06 14:47:16                        0.333333   \n",
              "2019-03-06 14:47:17                        0.333333   \n",
              "2019-03-06 14:47:18                        0.333333   \n",
              "2019-03-06 14:47:20                        0.333333   \n",
              "\n",
              "                     Machine5.Temperature3.C.Actual  \\\n",
              "Date                                                  \n",
              "2019-03-06 10:52:33                        0.016129   \n",
              "2019-03-06 10:52:38                        0.016129   \n",
              "2019-03-06 10:52:40                        0.016129   \n",
              "2019-03-06 10:52:42                        0.016129   \n",
              "2019-03-06 10:52:43                        0.016129   \n",
              "...                                             ...   \n",
              "2019-03-06 14:47:13                        1.000000   \n",
              "2019-03-06 14:47:16                        1.000000   \n",
              "2019-03-06 14:47:17                        1.000000   \n",
              "2019-03-06 14:47:18                        1.000000   \n",
              "2019-03-06 14:47:20                        1.000000   \n",
              "\n",
              "                     Machine5.Temperature4.C.Actual  \\\n",
              "Date                                                  \n",
              "2019-03-06 10:52:33                        0.135135   \n",
              "2019-03-06 10:52:38                        0.135135   \n",
              "2019-03-06 10:52:40                        0.135135   \n",
              "2019-03-06 10:52:42                        0.135135   \n",
              "2019-03-06 10:52:43                        0.135135   \n",
              "...                                             ...   \n",
              "2019-03-06 14:47:13                        0.959459   \n",
              "2019-03-06 14:47:16                        0.959459   \n",
              "2019-03-06 14:47:17                        0.959459   \n",
              "2019-03-06 14:47:18                        0.959459   \n",
              "2019-03-06 14:47:20                        0.959459   \n",
              "\n",
              "                     Machine5.Temperature6.C.Actual  \\\n",
              "Date                                                  \n",
              "2019-03-06 10:52:33                        1.000000   \n",
              "2019-03-06 10:52:38                        1.000000   \n",
              "2019-03-06 10:52:40                        0.969697   \n",
              "2019-03-06 10:52:42                        0.969697   \n",
              "2019-03-06 10:52:43                        0.969697   \n",
              "...                                             ...   \n",
              "2019-03-06 14:47:13                        0.272727   \n",
              "2019-03-06 14:47:16                        0.272727   \n",
              "2019-03-06 14:47:17                        0.272727   \n",
              "2019-03-06 14:47:18                        0.272727   \n",
              "2019-03-06 14:47:20                        0.272727   \n",
              "\n",
              "                     Machine5.ExitTemperature.U.Actual      y1_1      y1_2  \\\n",
              "Date                                                                         \n",
              "2019-03-06 10:52:33                           0.040422  0.579786  0.519164   \n",
              "2019-03-06 10:52:38                           0.032513  0.610799  0.592381   \n",
              "2019-03-06 10:52:40                           0.035149  0.567716  0.500276   \n",
              "2019-03-06 10:52:42                           0.035149  0.610691  0.601784   \n",
              "2019-03-06 10:52:43                           0.027241  0.609986  0.604039   \n",
              "...                                                ...       ...       ...   \n",
              "2019-03-06 14:47:13                           0.964851  0.619227  0.122349   \n",
              "2019-03-06 14:47:16                           0.966608  0.611264  0.096224   \n",
              "2019-03-06 14:47:17                           0.963972  0.612719  0.106224   \n",
              "2019-03-06 14:47:18                           0.963972  0.613425  0.125136   \n",
              "2019-03-06 14:47:20                           0.964851  0.615225  0.128979   \n",
              "\n",
              "                         y1_3      y1_4      y1_5      y1_6      y1_7  \\\n",
              "Date                                                                    \n",
              "2019-03-06 10:52:33  0.615703  0.748030  0.861546  0.100708  0.583930   \n",
              "2019-03-06 10:52:38  0.639640  0.826379  0.907209  0.099758  0.613201   \n",
              "2019-03-06 10:52:40  0.605186  0.712187  0.842149  0.099669  0.579199   \n",
              "2019-03-06 10:52:42  0.639058  0.825555  0.907049  0.099546  0.610313   \n",
              "2019-03-06 10:52:43  0.638582  0.826910  0.905587  0.099660  0.614990   \n",
              "...                       ...       ...       ...       ...       ...   \n",
              "2019-03-06 14:47:13  0.619154  0.810432  0.972666  0.102759  0.164565   \n",
              "2019-03-06 14:47:16  0.623071  0.812152  0.901973  0.096423  0.167346   \n",
              "2019-03-06 14:47:17  0.627075  0.810944  0.903191  0.097770  0.154584   \n",
              "2019-03-06 14:47:18  0.627415  0.809070  0.907052  0.097384  0.149917   \n",
              "2019-03-06 14:47:20  0.626122  0.807285  0.949252  0.105925  0.146275   \n",
              "\n",
              "                         y1_8      y1_9     y1_10     y1_11     y1_12  \\\n",
              "Date                                                                    \n",
              "2019-03-06 10:52:33  0.578993  0.833625  0.842966  0.558600  0.664400   \n",
              "2019-03-06 10:52:38  0.626154  0.928254  0.901984  0.610876  0.712618   \n",
              "2019-03-06 10:52:40  0.558780  0.791249  0.820224  0.541238  0.647242   \n",
              "2019-03-06 10:52:42  0.626647  0.922789  0.897832  0.617277  0.722980   \n",
              "2019-03-06 10:52:43  0.628586  0.931657  0.903816  0.613898  0.716935   \n",
              "...                       ...       ...       ...       ...       ...   \n",
              "2019-03-06 14:47:13  0.205074  0.951743  0.949354  0.571533  0.053674   \n",
              "2019-03-06 14:47:16  0.240007  0.970154  0.953425  0.578037  0.086974   \n",
              "2019-03-06 14:47:17  0.234818  0.961365  0.947995  0.581371  0.080270   \n",
              "2019-03-06 14:47:18  0.228323  0.952549  0.942824  0.580186  0.077989   \n",
              "2019-03-06 14:47:20  0.204151  0.944222  0.940468  0.575513  0.047639   \n",
              "\n",
              "                        y1_13     y1_14     y1_15  \n",
              "Date                                               \n",
              "2019-03-06 10:52:33  0.326115  0.525660  0.752081  \n",
              "2019-03-06 10:52:38  0.311979  0.522207  0.791797  \n",
              "2019-03-06 10:52:40  0.339551  0.523474  0.729437  \n",
              "2019-03-06 10:52:42  0.318109  0.514408  0.787326  \n",
              "2019-03-06 10:52:43  0.307264  0.518758  0.792821  \n",
              "...                       ...       ...       ...  \n",
              "2019-03-06 14:47:13  0.382829  0.589888  0.346803  \n",
              "2019-03-06 14:47:16  0.382318  0.575443  0.311506  \n",
              "2019-03-06 14:47:17  0.379518  0.564630  0.279402  \n",
              "2019-03-06 14:47:18  0.375309  0.564461  0.270283  \n",
              "2019-03-06 14:47:20  0.378834  0.566007  0.284348  \n",
              "\n",
              "[11270 rows x 23 columns]"
            ]
          },
          "execution_count": 374,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X2_train_scaled_df_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9d24788",
      "metadata": {
        "id": "a9d24788"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "reg_model2 = Sequential()\n",
        "reg_model2.add(Dense(120, activation=\"relu\", input_shape=[X2_train_scaled_df_new.shape[1],]))\n",
        "reg_model2.add(Dense(60, activation=\"relu\"))\n",
        "reg_model2.add(Dense(30, activation=\"relu\"))\n",
        "reg_model2.add(Dense(15))\n",
        "\n",
        "reg_model2.compile(optimizer='adam', loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ed40987",
      "metadata": {
        "id": "7ed40987",
        "outputId": "73483b8f-d325-4114-9b7a-8d84d61ad9e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "353/353 [==============================] - 1s 1ms/step - loss: 0.0410\n",
            "Epoch 2/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0140\n",
            "Epoch 3/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0128\n",
            "Epoch 4/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0121\n",
            "Epoch 5/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0117\n",
            "Epoch 6/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0113\n",
            "Epoch 7/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0110\n",
            "Epoch 8/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0108\n",
            "Epoch 9/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0106\n",
            "Epoch 10/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0103\n",
            "Epoch 11/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0101\n",
            "Epoch 12/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0099\n",
            "Epoch 13/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0097\n",
            "Epoch 14/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0097\n",
            "Epoch 15/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0095\n",
            "Epoch 16/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0093\n",
            "Epoch 17/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0092\n",
            "Epoch 18/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0092\n",
            "Epoch 19/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0091\n",
            "Epoch 20/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0090\n",
            "Epoch 21/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0089\n",
            "Epoch 22/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0090\n",
            "Epoch 23/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0089\n",
            "Epoch 24/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0089\n",
            "Epoch 25/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0089\n",
            "Epoch 26/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0088\n",
            "Epoch 27/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0088\n",
            "Epoch 28/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0089\n",
            "Epoch 29/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0087\n",
            "Epoch 30/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0086\n",
            "Epoch 31/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0086\n",
            "Epoch 32/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0087\n",
            "Epoch 33/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0086\n",
            "Epoch 34/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0086\n",
            "Epoch 35/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0085\n",
            "Epoch 36/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0085\n",
            "Epoch 37/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0086\n",
            "Epoch 38/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0084\n",
            "Epoch 39/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0085\n",
            "Epoch 40/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0084\n",
            "Epoch 41/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0084\n",
            "Epoch 42/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0084\n",
            "Epoch 43/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0084\n",
            "Epoch 44/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0084\n",
            "Epoch 45/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0083\n",
            "Epoch 46/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0083\n",
            "Epoch 47/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0082\n",
            "Epoch 48/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0082\n",
            "Epoch 49/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0083\n",
            "Epoch 50/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0083\n",
            "Epoch 51/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0083\n",
            "Epoch 52/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0082\n",
            "Epoch 53/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0082\n",
            "Epoch 54/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "Epoch 55/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "Epoch 56/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0082\n",
            "Epoch 57/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "Epoch 58/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "Epoch 59/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "Epoch 60/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0080\n",
            "Epoch 61/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "Epoch 62/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "Epoch 63/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "Epoch 64/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0080\n",
            "Epoch 65/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0082\n",
            "Epoch 66/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0080\n",
            "Epoch 67/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0080\n",
            "Epoch 68/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0080\n",
            "Epoch 69/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "Epoch 70/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0080\n",
            "Epoch 71/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0082\n",
            "Epoch 72/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0080\n",
            "Epoch 73/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0080\n",
            "Epoch 74/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0079\n",
            "Epoch 75/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0080\n",
            "Epoch 76/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0079\n",
            "Epoch 77/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0080\n",
            "Epoch 78/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0079\n",
            "Epoch 79/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 80/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0079\n",
            "Epoch 81/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0079\n",
            "Epoch 82/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0079\n",
            "Epoch 83/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 84/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 85/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0079\n",
            "Epoch 86/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 87/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 88/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0079\n",
            "Epoch 89/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 90/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 91/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 92/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 93/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0079\n",
            "Epoch 94/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Epoch 95/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Epoch 96/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Epoch 97/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 98/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 99/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 100/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Epoch 101/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 102/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 103/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 104/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Epoch 105/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Epoch 106/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Epoch 107/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 108/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Epoch 109/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Epoch 110/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 111/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 112/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Epoch 113/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 114/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Epoch 115/1000\n",
            "353/353 [==============================] - 0s 1000us/step - loss: 0.0076\n",
            "Epoch 116/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 117/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Epoch 118/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 119/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 120/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 121/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Epoch 122/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 123/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Epoch 124/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 125/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0078\n",
            "Epoch 126/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 127/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 128/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Epoch 129/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 130/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 131/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 132/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 133/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 134/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 135/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 136/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 137/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 138/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 139/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Epoch 140/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 141/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 142/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 143/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 144/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 145/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 146/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 147/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 148/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 149/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 150/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 151/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 152/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 153/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 154/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 155/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 156/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 157/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 158/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 159/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 160/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 161/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 162/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 163/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 164/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 165/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 166/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 167/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 168/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 169/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 170/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 171/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 172/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 173/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 174/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 175/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 176/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 177/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 178/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 179/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 180/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 181/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 182/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 183/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 184/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 185/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 186/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 187/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 188/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 189/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 190/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 191/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 192/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 193/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 194/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 195/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 196/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 197/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 198/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 199/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 200/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 201/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0075\n",
            "Epoch 202/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 203/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 204/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 205/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 206/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 207/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 208/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 209/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0076\n",
            "Epoch 210/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 211/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 212/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 213/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 214/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 215/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 216/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 217/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 218/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 219/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 220/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 221/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 222/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 223/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 224/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 225/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 226/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 227/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 228/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 229/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 230/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 231/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 232/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 233/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 234/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 235/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 236/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 237/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 238/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 239/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 240/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0074\n",
            "Epoch 241/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 242/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 243/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 244/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 245/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 246/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 247/1000\n",
            "353/353 [==============================] - 0s 995us/step - loss: 0.0073\n",
            "Epoch 248/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0072\n",
            "Epoch 249/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 250/1000\n",
            "353/353 [==============================] - 0s 979us/step - loss: 0.0072\n",
            "Epoch 251/1000\n",
            "353/353 [==============================] - 0s 963us/step - loss: 0.0072\n",
            "Epoch 252/1000\n",
            "353/353 [==============================] - 0s 970us/step - loss: 0.0073\n",
            "Epoch 253/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0072\n",
            "Epoch 254/1000\n",
            "353/353 [==============================] - 0s 971us/step - loss: 0.0072\n",
            "Epoch 255/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 256/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 257/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 258/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 259/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 260/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 261/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 262/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 263/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 264/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 265/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 266/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 267/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 268/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 269/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 270/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 271/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 272/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 273/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 274/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 275/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 276/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 277/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 278/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 279/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 280/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 281/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 282/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 283/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 284/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 285/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 286/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 287/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 288/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 289/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 290/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 291/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 292/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 293/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 294/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 295/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 296/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 297/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 298/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 299/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 300/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 301/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 302/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 303/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 304/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 305/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 306/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 307/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 308/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 309/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 310/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 311/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 312/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0073\n",
            "Epoch 313/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 314/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 315/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 316/1000\n",
            "353/353 [==============================] - 0s 944us/step - loss: 0.0072\n",
            "Epoch 317/1000\n",
            "353/353 [==============================] - 0s 935us/step - loss: 0.0072\n",
            "Epoch 318/1000\n",
            "353/353 [==============================] - 0s 956us/step - loss: 0.0070\n",
            "Epoch 319/1000\n",
            "353/353 [==============================] - 0s 912us/step - loss: 0.0071\n",
            "Epoch 320/1000\n",
            "353/353 [==============================] - 0s 905us/step - loss: 0.0071\n",
            "Epoch 321/1000\n",
            "353/353 [==============================] - 0s 919us/step - loss: 0.0072\n",
            "Epoch 322/1000\n",
            "353/353 [==============================] - 0s 903us/step - loss: 0.0071\n",
            "Epoch 323/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 324/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 325/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 326/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 327/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 328/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 329/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 330/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 331/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 332/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 333/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 334/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 335/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 336/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 337/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 338/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 339/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 340/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 341/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 342/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 343/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 344/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 345/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 346/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 347/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 348/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 349/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 350/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 351/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 352/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 353/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 354/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 355/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 356/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 357/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 358/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 359/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 360/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 361/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 362/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 363/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 364/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 365/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 366/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 367/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 368/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 369/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 370/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 371/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 372/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 373/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 374/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 375/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 376/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 377/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 378/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 379/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 380/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 381/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 382/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 383/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 384/1000\n",
            "353/353 [==============================] - 0s 982us/step - loss: 0.0071\n",
            "Epoch 385/1000\n",
            "353/353 [==============================] - 0s 953us/step - loss: 0.0070\n",
            "Epoch 386/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 387/1000\n",
            "353/353 [==============================] - 0s 982us/step - loss: 0.0070\n",
            "Epoch 388/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 389/1000\n",
            "353/353 [==============================] - 0s 972us/step - loss: 0.0070\n",
            "Epoch 390/1000\n",
            "353/353 [==============================] - 0s 968us/step - loss: 0.0070\n",
            "Epoch 391/1000\n",
            "353/353 [==============================] - 0s 934us/step - loss: 0.0070\n",
            "Epoch 392/1000\n",
            "353/353 [==============================] - 0s 948us/step - loss: 0.0071\n",
            "Epoch 393/1000\n",
            "353/353 [==============================] - 0s 986us/step - loss: 0.0070\n",
            "Epoch 394/1000\n",
            "353/353 [==============================] - 0s 962us/step - loss: 0.0070\n",
            "Epoch 395/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 396/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 397/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 398/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 399/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 400/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 401/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 402/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 403/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 404/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 405/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 406/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 407/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 408/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 409/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 410/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 411/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 412/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 413/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 414/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 415/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 416/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 417/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 418/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 419/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 420/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 421/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 422/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 423/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 424/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 425/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 426/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 427/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 428/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 429/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 430/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 431/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 432/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 433/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 434/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 435/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 436/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 437/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 438/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 439/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 440/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 441/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 442/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 443/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 444/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 445/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 446/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 447/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 448/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 449/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 450/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 451/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 452/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 453/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 454/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 455/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 456/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 457/1000\n",
            "353/353 [==============================] - 0s 959us/step - loss: 0.0070\n",
            "Epoch 458/1000\n",
            "353/353 [==============================] - 0s 972us/step - loss: 0.0070\n",
            "Epoch 459/1000\n",
            "353/353 [==============================] - 0s 969us/step - loss: 0.0069\n",
            "Epoch 460/1000\n",
            "353/353 [==============================] - 0s 977us/step - loss: 0.0069\n",
            "Epoch 461/1000\n",
            "353/353 [==============================] - 0s 993us/step - loss: 0.0070\n",
            "Epoch 462/1000\n",
            "353/353 [==============================] - 0s 987us/step - loss: 0.0071\n",
            "Epoch 463/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 464/1000\n",
            "353/353 [==============================] - 0s 996us/step - loss: 0.0070\n",
            "Epoch 465/1000\n",
            "353/353 [==============================] - 0s 961us/step - loss: 0.0069\n",
            "Epoch 466/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 467/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 468/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 469/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 470/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 471/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0072\n",
            "Epoch 472/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 473/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 474/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 475/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 476/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 477/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 478/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 479/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 480/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 481/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 482/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 483/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 484/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 485/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 486/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 487/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 488/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 489/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 490/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 491/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 492/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 493/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 494/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 495/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 496/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 497/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 498/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 499/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 500/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 501/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 502/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 503/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 504/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 505/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 506/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 507/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 508/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 509/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 510/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 511/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 512/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 513/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 514/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 515/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 516/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 517/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 518/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 519/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 520/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 521/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 522/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 523/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 524/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 525/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 526/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 527/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 528/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0071\n",
            "Epoch 529/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 530/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 531/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 532/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 533/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 534/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 535/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 536/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 537/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 538/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 539/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 540/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 541/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 542/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 543/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 544/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 545/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 546/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 547/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 548/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 549/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 550/1000\n",
            "353/353 [==============================] - 1s 2ms/step - loss: 0.0069\n",
            "Epoch 551/1000\n",
            "353/353 [==============================] - 1s 2ms/step - loss: 0.0068\n",
            "Epoch 552/1000\n",
            "353/353 [==============================] - 1s 2ms/step - loss: 0.0069\n",
            "Epoch 553/1000\n",
            "353/353 [==============================] - 1s 1ms/step - loss: 0.0068\n",
            "Epoch 554/1000\n",
            "353/353 [==============================] - 1s 2ms/step - loss: 0.0067\n",
            "Epoch 555/1000\n",
            "353/353 [==============================] - 1s 1ms/step - loss: 0.0067\n",
            "Epoch 556/1000\n",
            "353/353 [==============================] - 1s 2ms/step - loss: 0.0068\n",
            "Epoch 557/1000\n",
            "353/353 [==============================] - 1s 2ms/step - loss: 0.0068\n",
            "Epoch 558/1000\n",
            "353/353 [==============================] - 1s 2ms/step - loss: 0.0067\n",
            "Epoch 559/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 560/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 561/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 562/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 563/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 564/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 565/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 566/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 567/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 568/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0070\n",
            "Epoch 569/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 570/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 571/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 572/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 573/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 574/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 575/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 576/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 577/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 578/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 579/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 580/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 581/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 582/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 583/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 584/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 585/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 586/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 587/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 588/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 589/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 590/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 591/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 592/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 593/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 594/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 595/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 596/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 597/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 598/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 599/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 600/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 601/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 602/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 603/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 604/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 605/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 606/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 607/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 608/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 609/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 610/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 611/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 612/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 613/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 614/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 615/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 616/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 617/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 618/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 619/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 620/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 621/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 622/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 623/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 624/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 625/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 626/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 627/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 628/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 629/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 630/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 631/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 632/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 633/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 634/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 635/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 636/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 637/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 638/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 639/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 640/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 641/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 642/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 643/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 644/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 645/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 646/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 647/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 648/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 649/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 650/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 651/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 652/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 653/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 654/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 655/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 656/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 657/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 658/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 659/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 660/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 661/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 662/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 663/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 664/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 665/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 666/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 667/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 668/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 669/1000\n",
            "353/353 [==============================] - 0s 988us/step - loss: 0.0067\n",
            "Epoch 670/1000\n",
            "353/353 [==============================] - 0s 979us/step - loss: 0.0068\n",
            "Epoch 671/1000\n",
            "353/353 [==============================] - 0s 991us/step - loss: 0.0067\n",
            "Epoch 672/1000\n",
            "353/353 [==============================] - 0s 955us/step - loss: 0.0066\n",
            "Epoch 673/1000\n",
            "353/353 [==============================] - 0s 976us/step - loss: 0.0067\n",
            "Epoch 674/1000\n",
            "353/353 [==============================] - 0s 959us/step - loss: 0.0066\n",
            "Epoch 675/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 676/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 677/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 678/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 679/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 680/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 681/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 682/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 683/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 684/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 685/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 686/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 687/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 688/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 689/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 690/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 691/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 692/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 693/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 694/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 695/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 696/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 697/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 698/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 699/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 700/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 701/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 702/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 703/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 704/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 705/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 706/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 707/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 708/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 709/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 710/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 711/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 712/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 713/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 714/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 715/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 716/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 717/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 718/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 719/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 720/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 721/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 722/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 723/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 724/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 725/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 726/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 727/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 728/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 729/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 730/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 731/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 732/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 733/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 734/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 735/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 736/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 737/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 738/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 739/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 740/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 741/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 742/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 743/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 744/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 745/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 746/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 747/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 748/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 749/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 750/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 751/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 752/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 753/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 754/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 755/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 756/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 757/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 758/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 759/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 760/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 761/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 762/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 763/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 764/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 765/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 766/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 767/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 768/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 769/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 770/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 771/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 772/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 773/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 774/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 775/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 776/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 777/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 778/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 779/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 780/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 781/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 782/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 783/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 784/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 785/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 786/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 787/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 788/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 789/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 790/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 791/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 792/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 793/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 794/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 795/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 796/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 797/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 798/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 799/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 800/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 801/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 802/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 803/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 804/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 805/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 806/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 807/1000\n",
            "353/353 [==============================] - 0s 968us/step - loss: 0.0065\n",
            "Epoch 808/1000\n",
            "353/353 [==============================] - 0s 968us/step - loss: 0.0068\n",
            "Epoch 809/1000\n",
            "353/353 [==============================] - 0s 981us/step - loss: 0.0067\n",
            "Epoch 810/1000\n",
            "353/353 [==============================] - 0s 967us/step - loss: 0.0066\n",
            "Epoch 811/1000\n",
            "353/353 [==============================] - 0s 941us/step - loss: 0.0066\n",
            "Epoch 812/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0067\n",
            "Epoch 813/1000\n",
            "353/353 [==============================] - 0s 952us/step - loss: 0.0065\n",
            "Epoch 814/1000\n",
            "353/353 [==============================] - 0s 960us/step - loss: 0.0066\n",
            "Epoch 815/1000\n",
            "353/353 [==============================] - 0s 957us/step - loss: 0.0065\n",
            "Epoch 816/1000\n",
            "353/353 [==============================] - 0s 974us/step - loss: 0.0066\n",
            "Epoch 817/1000\n",
            "353/353 [==============================] - 0s 979us/step - loss: 0.0064\n",
            "Epoch 818/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 819/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 820/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 821/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 822/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 823/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 824/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 825/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 826/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 827/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 828/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 829/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 830/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 831/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 832/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 833/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 834/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 835/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0069\n",
            "Epoch 836/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 837/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 838/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 839/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 840/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 841/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 842/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 843/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 844/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 845/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 846/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 847/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 848/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 849/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 850/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 851/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 852/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 853/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 854/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 855/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 856/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 857/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 858/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 859/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 860/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 861/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 862/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 863/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 864/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 865/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 866/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 867/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 868/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 869/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 870/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 871/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 872/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 873/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 874/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 875/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 876/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 877/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 878/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 879/1000\n",
            "353/353 [==============================] - 0s 999us/step - loss: 0.0065\n",
            "Epoch 880/1000\n",
            "353/353 [==============================] - 0s 943us/step - loss: 0.0064\n",
            "Epoch 881/1000\n",
            "353/353 [==============================] - 0s 953us/step - loss: 0.0065\n",
            "Epoch 882/1000\n",
            "353/353 [==============================] - 0s 970us/step - loss: 0.0065\n",
            "Epoch 883/1000\n",
            "353/353 [==============================] - 0s 942us/step - loss: 0.0065\n",
            "Epoch 884/1000\n",
            "353/353 [==============================] - 0s 928us/step - loss: 0.0066\n",
            "Epoch 885/1000\n",
            "353/353 [==============================] - 0s 968us/step - loss: 0.0064\n",
            "Epoch 886/1000\n",
            "353/353 [==============================] - 0s 979us/step - loss: 0.0066\n",
            "Epoch 887/1000\n",
            "353/353 [==============================] - 0s 968us/step - loss: 0.0065\n",
            "Epoch 888/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 889/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 890/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 891/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 892/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 893/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 894/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 895/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 896/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 897/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 898/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 899/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 900/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 901/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 902/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 903/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 904/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 905/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 906/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 907/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 908/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 909/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 910/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 911/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 912/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 913/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 914/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 915/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 916/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 917/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 918/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 919/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 920/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 921/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 922/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 923/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 924/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 925/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 926/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 927/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 928/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 929/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 930/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 931/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 932/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 933/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 934/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 935/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 936/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 937/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 938/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 939/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 940/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 941/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 942/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 943/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 944/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 945/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 946/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 947/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 948/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 949/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 950/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 951/1000\n",
            "353/353 [==============================] - 0s 971us/step - loss: 0.0065\n",
            "Epoch 952/1000\n",
            "353/353 [==============================] - 0s 932us/step - loss: 0.0065\n",
            "Epoch 953/1000\n",
            "353/353 [==============================] - 0s 972us/step - loss: 0.0068\n",
            "Epoch 954/1000\n",
            "353/353 [==============================] - 0s 965us/step - loss: 0.0064\n",
            "Epoch 955/1000\n",
            "353/353 [==============================] - 0s 969us/step - loss: 0.0066\n",
            "Epoch 956/1000\n",
            "353/353 [==============================] - 0s 983us/step - loss: 0.0065\n",
            "Epoch 957/1000\n",
            "353/353 [==============================] - 0s 945us/step - loss: 0.0064\n",
            "Epoch 958/1000\n",
            "353/353 [==============================] - 0s 922us/step - loss: 0.0065\n",
            "Epoch 959/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 960/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 961/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 962/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 963/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 964/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 965/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 966/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 967/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 968/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 969/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 970/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 971/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 972/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 973/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 974/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 975/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0067\n",
            "Epoch 976/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 977/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 978/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 979/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 980/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 981/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 982/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 983/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 984/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 985/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 986/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 987/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 988/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 989/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 990/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 991/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 992/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0068\n",
            "Epoch 993/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 994/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 995/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0065\n",
            "Epoch 996/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 997/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 998/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0066\n",
            "Epoch 999/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n",
            "Epoch 1000/1000\n",
            "353/353 [==============================] - 0s 1ms/step - loss: 0.0064\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping \n",
        "early_stopping = EarlyStopping(monitor = 'loss', min_delta = 0, patience = 100, mode = 'auto')\n",
        "\n",
        "history2 = reg_model2.fit(X2_train_scaled_df_new, y2_train_scaled, epochs=1000, callbacks = [early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95628f30",
      "metadata": {
        "id": "95628f30",
        "outputId": "9c2b2a6e-7326-4dde-ea3f-8f43cb4870b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "89/89 [==============================] - 0s 674us/step\n"
          ]
        }
      ],
      "source": [
        "y2= reg_model2.predict(X2_test_scaled_df_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ac9462a",
      "metadata": {
        "id": "8ac9462a",
        "outputId": "6d937a87-8cb1-4aee-9dc7-24287223234d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2818, 15), (2818, 41))"
            ]
          },
          "execution_count": 381,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y1.shape, X1_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cf7c2bf",
      "metadata": {
        "id": "7cf7c2bf"
      },
      "outputs": [],
      "source": [
        "y1_real = y1scaler.inverse_transform(y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c9f681b",
      "metadata": {
        "id": "7c9f681b"
      },
      "outputs": [],
      "source": [
        "y2_real = y2scaler.inverse_transform(y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65d762ce",
      "metadata": {
        "id": "65d762ce"
      },
      "outputs": [],
      "source": [
        "stage1_sub_pred = y1_real # stage1의 예측값\n",
        "stage2_sub_pred = y2_real # stage2의 예측값"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67af536a-6cd1-4c49-9943-b71c52448437",
      "metadata": {
        "id": "67af536a-6cd1-4c49-9943-b71c52448437"
      },
      "source": [
        "## 채점\n",
        "\n",
        "결과로 제출할 파일을 저장 후, 아래 코드를 실행하면 채점을 수행합니다.\n",
        "\n",
        "**아래 코드를 수정하면 정상적으로 채점이 이루어지지 않을 수 있습니다.**\n",
        "\n",
        "### 주의: 코드 파일도 채점 코드로 전달하기 때문에 아래 코드를 실행하기 전에 반드시 저장 버튼 혹은 <kbd>Ctrl</kbd> + <kbd>S</kbd>를 눌러 변경사항을 모두 저장하시길 바랍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcb6b466",
      "metadata": {
        "id": "bcb6b466"
      },
      "outputs": [],
      "source": [
        "result_dict = {\n",
        "    'stage1': stage1_sub_pred.tolist(), # stage1의 예측값\n",
        "    'stage2': stage2_sub_pred.tolist(), # stage2의 예측값\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e266492-fc46-42af-881e-75ff77388357",
      "metadata": {
        "id": "8e266492-fc46-42af-881e-75ff77388357",
        "outputId": "652a72b5-b86b-4649-a5e3-0da69157a0af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "send files ['result.json', 'time_series_regression.ipynb'] for grade...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Compressed 2355200 bytes into 1520641 bytes ==> 64.57%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "waiting result...\n",
            "done!\n",
            "\n",
            "Score: 64.826373\n",
            "Duration: 2.147477388381958 seconds\n",
            "=== Message ===\n",
            "제출 완료되었습니다.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 386,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "with open(\"result.json\", \"w\") as f:\n",
        "    json.dump(result_dict, f)\n",
        "\n",
        "os.system(\"elice_grade result.json time_series_regression.ipynb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd8e7a5f",
      "metadata": {
        "id": "fd8e7a5f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.14"
    },
    "vscode": {
      "interpreter": {
        "hash": "212ed7ce1297a39c9fbf5ca85e06406b93631cc7f04eebf2647cdd4c558781fa"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}